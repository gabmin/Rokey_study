{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8장 적대적 생성 신경망 (Generative adversarial network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"부록3 매트플롯립 입문\"에서 한글 폰트를 올바르게 출력하기 위한 설치 방법을 설명했다. 설치 방법은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 설치\n",
    "\n",
    "!sudo apt-get install -y fonts-nanum* | tail -n 1\n",
    "!sudo fc-cache -fv\n",
    "!rm -rf ~/.cache/matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 설치가 끝나면 한글 폰트를 바르게 출력하기 위해 **[런타임]** -> **[런타임 다시시작]**을 클릭한 다음, 아래 셀부터 코드를 실행해 주십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from IPython.display import display\n",
    "\n",
    "# 폰트 관련 용도\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# Colab, Linux\n",
    "# 나눔 고딕 폰트의 경로 명시\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
    "\n",
    "# Window\n",
    "# font_name = \"NanumBarunGothic\"\n",
    "\n",
    "# Mac\n",
    "# font_name = \"AppleGothic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 폰트 설정\n",
    "plt.rcParams['font.family'] = font_name  # window font\n",
    "\n",
    "# 기본 폰트 사이즈 변경\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# 기본 그래프 사이즈 변경\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# 기본 그리드 표시\n",
    "# 필요에 따라 설정할 때는, plt.grid()\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams[\"grid.linestyle\"] = \":\"\n",
    "\n",
    "# 마이너스 기호 정상 출력\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 넘파이 부동소수점 자릿수 표시\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla GAN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters & Variables setting\n",
    "num_epoch = 1000\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "img_size = 28 * 28\n",
    "num_channel = 1\n",
    "dir_name = \"GAN_results\"\n",
    "\n",
    "noise_size = 100\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 512\n",
    "# hidden_size3 = 1024\n",
    "\n",
    "# Create a directory for saving samples\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset transform setting\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.46MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 164kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.51MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset setting\n",
    "MNIST_dataset = datasets.MNIST(root='./',\n",
    "                                train=True,\n",
    "                                transform=transform,\n",
    "                                download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = DataLoader(dataset=MNIST_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 판별기 (Discriminator) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(img_size, hidden_size2)\n",
    "        self.linear2 = nn.Linear(hidden_size2, hidden_size1)\n",
    "        self.linear3 = nn.Linear(hidden_size1, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.linear1(x))\n",
    "        x = self.leaky_relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성기 (Generator) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(noise_size, hidden_size1)\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.linear3 = nn.Linear(hidden_size2, img_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        x = self.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator/Discriminator\n",
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla GAN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function & Optimizer setting\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(data_loader))[0].shape  # torch.Size([100, 1, 28, 28])\n",
    "# batch_size # 100\n",
    "img_test = next(iter(data_loader))[0]\n",
    "img_test.reshape(100, -1).shape\n",
    "# print(len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training part\n",
    "\"\"\"\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, label) in enumerate(data_loader):\n",
    "\n",
    "        # make ground truth (labels) -> 1 for real, 0 for fake\n",
    "        real_label = torch.full((batch_size, 1), 1, dtype=torch.float32).to(device) # batch_size  100\n",
    "        fake_label = torch.full((batch_size, 1), 0, dtype=torch.float32).to(device)\n",
    "\n",
    "        # reshape real images from MNIST dataset\n",
    "        real_images = images.reshape(batch_size, -1).to(device) # torch.Size([100, 784])\n",
    "\n",
    "        # +---------------------+\n",
    "        # |   train Generator   |\n",
    "        # +---------------------+\n",
    "\n",
    "        # Initialize grad\n",
    "        g_optimizer.zero_grad()\n",
    "        # d_optimizer.zero_grad()\n",
    "\n",
    "        # make fake images with generator & noise vector 'z'\n",
    "        z = torch.randn(batch_size, noise_size).to(device)\n",
    "        fake_images = generator(z)\n",
    "        \n",
    "        # Compare result of discriminator with fake images & real labels\n",
    "        # If generator deceives discriminator, g_loss will decrease\n",
    "        # discriminator should be freezing\n",
    "        g_loss = criterion(discriminator(fake_images), real_label)\n",
    "\n",
    "        # Train generator with backpropagation\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # +---------------------+\n",
    "        # | train Discriminator |\n",
    "        # +---------------------+\n",
    "\n",
    "        # Initialize grad\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        # make fake images with generator & noise vector 'z'\n",
    "        z = torch.randn(batch_size, noise_size).to(device)\n",
    "        fake_images = generator(z)\n",
    "\n",
    "        # Calculate fake & real loss with generated images above & real images\n",
    "        fake_loss = criterion(discriminator(fake_images), fake_label)\n",
    "        real_loss = criterion(discriminator(real_images), real_label)\n",
    "        d_loss = (fake_loss + real_loss) / 2\n",
    "\n",
    "        # Train discriminator with backpropagation\n",
    "        # In this part, we don't train generator\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        d_performance = discriminator(real_images).mean()\n",
    "        g_performance = discriminator(fake_images).mean()\n",
    "\n",
    "        if (i + 1) % 150 == 0:\n",
    "            print(\"Epoch [ {}/{} ]  Step [ {}/{} ]  d_loss : {:.5f}  g_loss : {:.5f}\"\n",
    "                  .format(epoch, num_epoch, i+1, len(data_loader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "    # print discriminator & generator's performance\n",
    "    print(\" Epock {}'s discriminator performance : {:.2f}  generator performance : {:.2f}\"\n",
    "          .format(epoch, d_performance, g_performance))\n",
    "\n",
    "    # Save fake images in each epoch\n",
    "    samples = fake_images.reshape(batch_size, 1, 28, 28)\n",
    "    save_image(samples, os.path.join(dir_name, 'GAN_fake_samples{}.png'.format(epoch + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eps=10      # num_epoch\n",
    "bsize=32        # batch_size \n",
    "lrate=0.001     # learning_rate\n",
    "noise_size=64 # noise_size\n",
    "img_size=64     # img_size\n",
    "num_channel=1         # num_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN 생성기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANGenerator, self).__init__()\n",
    "        self.inp_sz = img_size // 4\n",
    "        self.lin = nn.Linear(noise_size, 128 * self.inp_sz ** 2)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode ='nearest')\n",
    "        self.cn1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.rl1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.up2 = nn.Upsample(scale_factor=2)\n",
    "        self.cn2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.rl2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.cn3 = nn.Conv2d(64, num_channel, 3, stride=1, padding=1)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = x.view(x.shape[0], 128, self.inp_sz, self.inp_sz)\n",
    "        x = self.bn1(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.cn1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.cn2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.rl2(x)\n",
    "        x = self.cn3(x)\n",
    "        out = self.act(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_eps=10\n",
    "# bsize=32\n",
    "# lrate=0.001\n",
    "# lat_dimension=64\n",
    "# image_sz=64\n",
    "# chnls=1\n",
    "# logging_intv=200\n",
    "\n",
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANDiscriminator, self).__init__()\n",
    "\n",
    "        def disc_module(ip_chnls, op_chnls, bnorm=True):\n",
    "            mod = [nn.Conv2d(ip_chnls, op_chnls, 3, 2, 1), \n",
    "                   nn.LeakyReLU(0.2, inplace=True), \n",
    "                   nn.Dropout2d(0.25)]\n",
    "            if bnorm:\n",
    "                mod += [nn.BatchNorm2d(op_chnls, 0.8)]\n",
    "            return mod\n",
    "\n",
    "        self.disc_model = nn.Sequential(\n",
    "            *disc_module(num_channel, 16, bnorm=False),\n",
    "            *disc_module(16, 32),\n",
    "            *disc_module(32, 64),\n",
    "            *disc_module(64, 128),\n",
    "        )\n",
    "\n",
    "        # width and height of the down-sized image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adverse_lyr = nn.Sequential(\n",
    "            nn.Linear(128 * ds_size ** 2, 1), \n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.disc_model(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        out = self.adverse_lyr(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the discriminator and generator models\n",
    "gen = GANGenerator().to(device)\n",
    "disc = GANDiscriminator().to(device)\n",
    "\n",
    "# define the loss metric\n",
    "adv_loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset and corresponding dataloader\n",
    "data_loader = DataLoader(\n",
    "    datasets.MNIST(\n",
    "        root=\"./\",\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((img_size, img_size)), \n",
    "             transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=bsize,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# define the optimization schedule for both G and D\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lrate)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0 | batch number 0 | generator loss = 3.9545516967773438 | discriminator loss = 0.2782806158065796\n",
      "epoch number 0 | batch number 200 | generator loss = 3.554192304611206 | discriminator loss = 0.03740197420120239\n",
      "epoch number 0 | batch number 400 | generator loss = 1.8775991201400757 | discriminator loss = 0.13742583990097046\n",
      "epoch number 0 | batch number 600 | generator loss = 4.771371841430664 | discriminator loss = 0.0422741174697876\n",
      "epoch number 0 | batch number 800 | generator loss = 6.1848835945129395 | discriminator loss = 0.06815836578607559\n",
      "epoch number 0 | batch number 1000 | generator loss = 6.0200371742248535 | discriminator loss = 0.012616288848221302\n",
      "epoch number 0 | batch number 1200 | generator loss = 3.3388099670410156 | discriminator loss = 0.20030230283737183\n",
      "epoch number 0 | batch number 1400 | generator loss = 3.468569755554199 | discriminator loss = 0.05986403673887253\n",
      "epoch number 0 | batch number 1600 | generator loss = 4.02747106552124 | discriminator loss = 0.15941214561462402\n",
      "epoch number 0 | batch number 1800 | generator loss = 1.9418367147445679 | discriminator loss = 0.19932261109352112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:49<07:22, 49.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 1 | batch number 125 | generator loss = 4.23289680480957 | discriminator loss = 0.04313182458281517\n",
      "epoch number 1 | batch number 325 | generator loss = 3.6431376934051514 | discriminator loss = 0.25708135962486267\n",
      "epoch number 1 | batch number 525 | generator loss = 3.278818368911743 | discriminator loss = 0.08988559246063232\n",
      "epoch number 1 | batch number 725 | generator loss = 2.4317989349365234 | discriminator loss = 0.05262760818004608\n",
      "epoch number 1 | batch number 925 | generator loss = 2.1540660858154297 | discriminator loss = 0.19819074869155884\n",
      "epoch number 1 | batch number 1125 | generator loss = 4.866243362426758 | discriminator loss = 0.07104020565748215\n",
      "epoch number 1 | batch number 1325 | generator loss = 4.817590713500977 | discriminator loss = 0.03069155663251877\n",
      "epoch number 1 | batch number 1525 | generator loss = 5.30476188659668 | discriminator loss = 0.1353522092103958\n",
      "epoch number 1 | batch number 1725 | generator loss = 3.282376766204834 | discriminator loss = 0.07071726024150848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:37<06:30, 48.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 2 | batch number 50 | generator loss = 5.153894424438477 | discriminator loss = 0.04896470159292221\n",
      "epoch number 2 | batch number 250 | generator loss = 4.530649185180664 | discriminator loss = 0.3270239531993866\n",
      "epoch number 2 | batch number 450 | generator loss = 8.000043869018555 | discriminator loss = 0.10126665979623795\n",
      "epoch number 2 | batch number 650 | generator loss = 6.198918342590332 | discriminator loss = 0.010016540065407753\n",
      "epoch number 2 | batch number 850 | generator loss = 5.983379364013672 | discriminator loss = 0.3273736536502838\n",
      "epoch number 2 | batch number 1050 | generator loss = 4.024206161499023 | discriminator loss = 0.038508810102939606\n",
      "epoch number 2 | batch number 1250 | generator loss = 0.7392721176147461 | discriminator loss = 0.15315017104148865\n",
      "epoch number 2 | batch number 1450 | generator loss = 3.7891921997070312 | discriminator loss = 0.1695229858160019\n",
      "epoch number 2 | batch number 1650 | generator loss = 4.046806335449219 | discriminator loss = 0.10749366879463196\n",
      "epoch number 2 | batch number 1850 | generator loss = 4.57669734954834 | discriminator loss = 0.12455864250659943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [02:27<05:44, 49.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 3 | batch number 175 | generator loss = 5.730733871459961 | discriminator loss = 0.12807787954807281\n",
      "epoch number 3 | batch number 375 | generator loss = 4.793088912963867 | discriminator loss = 0.37881994247436523\n",
      "epoch number 3 | batch number 575 | generator loss = 6.7368974685668945 | discriminator loss = 0.016468007117509842\n",
      "epoch number 3 | batch number 775 | generator loss = 5.118185997009277 | discriminator loss = 0.034300170838832855\n",
      "epoch number 3 | batch number 975 | generator loss = 5.057310581207275 | discriminator loss = 0.10720119625329971\n",
      "epoch number 3 | batch number 1175 | generator loss = 6.804218769073486 | discriminator loss = 0.008177373558282852\n",
      "epoch number 3 | batch number 1375 | generator loss = 3.3641469478607178 | discriminator loss = 0.10269354283809662\n",
      "epoch number 3 | batch number 1575 | generator loss = 5.981612205505371 | discriminator loss = 0.021350819617509842\n",
      "epoch number 3 | batch number 1775 | generator loss = 5.107820510864258 | discriminator loss = 0.2083660066127777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [03:16<04:55, 49.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 4 | batch number 100 | generator loss = 8.087093353271484 | discriminator loss = 0.09759678691625595\n",
      "epoch number 4 | batch number 300 | generator loss = 1.7739126682281494 | discriminator loss = 0.6854257583618164\n",
      "epoch number 4 | batch number 500 | generator loss = 8.029947280883789 | discriminator loss = 0.045721717178821564\n",
      "epoch number 4 | batch number 700 | generator loss = 3.9087915420532227 | discriminator loss = 0.16519811749458313\n",
      "epoch number 4 | batch number 900 | generator loss = 5.707446575164795 | discriminator loss = 0.08258886635303497\n",
      "epoch number 4 | batch number 1100 | generator loss = 1.5349751710891724 | discriminator loss = 0.53525710105896\n",
      "epoch number 4 | batch number 1300 | generator loss = 3.1992595195770264 | discriminator loss = 0.004317648708820343\n",
      "epoch number 4 | batch number 1500 | generator loss = 7.143947601318359 | discriminator loss = 0.0162322036921978\n",
      "epoch number 4 | batch number 1700 | generator loss = 4.835370063781738 | discriminator loss = 0.33377426862716675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [04:12<04:18, 51.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 5 | batch number 25 | generator loss = 2.1899523735046387 | discriminator loss = 0.16276304423809052\n",
      "epoch number 5 | batch number 225 | generator loss = 5.253238677978516 | discriminator loss = 0.3563573360443115\n",
      "epoch number 5 | batch number 425 | generator loss = 7.449577808380127 | discriminator loss = 0.12209033966064453\n",
      "epoch number 5 | batch number 625 | generator loss = 3.859504222869873 | discriminator loss = 0.17049042880535126\n",
      "epoch number 5 | batch number 825 | generator loss = 4.514573574066162 | discriminator loss = 0.06178569048643112\n",
      "epoch number 5 | batch number 1025 | generator loss = 5.278169631958008 | discriminator loss = 0.027951447293162346\n",
      "epoch number 5 | batch number 1225 | generator loss = 6.560893535614014 | discriminator loss = 0.08444608002901077\n",
      "epoch number 5 | batch number 1425 | generator loss = 7.850395202636719 | discriminator loss = 0.25208404660224915\n",
      "epoch number 5 | batch number 1625 | generator loss = 4.836728096008301 | discriminator loss = 0.0652989074587822\n",
      "epoch number 5 | batch number 1825 | generator loss = 8.25395679473877 | discriminator loss = 0.03623552992939949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [05:01<03:23, 50.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 6 | batch number 150 | generator loss = 11.474748611450195 | discriminator loss = 0.4834703803062439\n",
      "epoch number 6 | batch number 350 | generator loss = 4.103691101074219 | discriminator loss = 0.18094411492347717\n",
      "epoch number 6 | batch number 550 | generator loss = 5.099274635314941 | discriminator loss = 0.08729465305805206\n",
      "epoch number 6 | batch number 750 | generator loss = 3.8545188903808594 | discriminator loss = 0.06430787593126297\n",
      "epoch number 6 | batch number 950 | generator loss = 1.6146601438522339 | discriminator loss = 0.004101771395653486\n",
      "epoch number 6 | batch number 1150 | generator loss = 1.69037926197052 | discriminator loss = 0.0950821042060852\n",
      "epoch number 6 | batch number 1350 | generator loss = 3.2029476165771484 | discriminator loss = 0.01881629414856434\n",
      "epoch number 6 | batch number 1550 | generator loss = 6.5531840324401855 | discriminator loss = 0.05114094167947769\n",
      "epoch number 6 | batch number 1750 | generator loss = 8.155012130737305 | discriminator loss = 0.37255942821502686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [05:51<02:31, 50.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 7 | batch number 75 | generator loss = 5.89101505279541 | discriminator loss = 0.029376033693552017\n",
      "epoch number 7 | batch number 275 | generator loss = 3.817337989807129 | discriminator loss = 0.02690809778869152\n",
      "epoch number 7 | batch number 475 | generator loss = 10.73667049407959 | discriminator loss = 0.1453002542257309\n",
      "epoch number 7 | batch number 675 | generator loss = 3.355811595916748 | discriminator loss = 0.22888179123401642\n",
      "epoch number 7 | batch number 875 | generator loss = 2.42566180229187 | discriminator loss = 0.4170704782009125\n",
      "epoch number 7 | batch number 1075 | generator loss = 4.84708833694458 | discriminator loss = 0.16885662078857422\n",
      "epoch number 7 | batch number 1275 | generator loss = 5.702351093292236 | discriminator loss = 0.03158178552985191\n",
      "epoch number 7 | batch number 1475 | generator loss = 6.083104133605957 | discriminator loss = 0.008439648896455765\n",
      "epoch number 7 | batch number 1675 | generator loss = 7.070625305175781 | discriminator loss = 0.25249427556991577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [06:40<01:39, 49.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 8 | batch number 0 | generator loss = 4.203941822052002 | discriminator loss = 0.18343289196491241\n",
      "epoch number 8 | batch number 200 | generator loss = 2.7548460960388184 | discriminator loss = 0.017191078513860703\n",
      "epoch number 8 | batch number 400 | generator loss = 5.153848171234131 | discriminator loss = 0.2126798778772354\n",
      "epoch number 8 | batch number 600 | generator loss = 2.4082131385803223 | discriminator loss = 0.7340734004974365\n",
      "epoch number 8 | batch number 800 | generator loss = 1.9588088989257812 | discriminator loss = 0.7638360857963562\n",
      "epoch number 8 | batch number 1000 | generator loss = 3.1427531242370605 | discriminator loss = 0.04076611250638962\n",
      "epoch number 8 | batch number 1200 | generator loss = 9.426302909851074 | discriminator loss = 0.0671580359339714\n",
      "epoch number 8 | batch number 1400 | generator loss = 4.568195343017578 | discriminator loss = 0.2781957983970642\n",
      "epoch number 8 | batch number 1600 | generator loss = 3.1912214756011963 | discriminator loss = 0.04164225980639458\n",
      "epoch number 8 | batch number 1800 | generator loss = 4.669330596923828 | discriminator loss = 0.0010130235459655523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [07:28<00:49, 49.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 9 | batch number 125 | generator loss = 2.847745895385742 | discriminator loss = 0.2367047667503357\n",
      "epoch number 9 | batch number 325 | generator loss = 8.497081756591797 | discriminator loss = 0.6592368483543396\n",
      "epoch number 9 | batch number 525 | generator loss = 5.124856948852539 | discriminator loss = 0.05494079366326332\n",
      "epoch number 9 | batch number 725 | generator loss = 2.808432102203369 | discriminator loss = 0.08962322771549225\n",
      "epoch number 9 | batch number 925 | generator loss = 3.5111680030822754 | discriminator loss = 0.177422434091568\n",
      "epoch number 9 | batch number 1125 | generator loss = 4.133440017700195 | discriminator loss = 0.12160167098045349\n",
      "epoch number 9 | batch number 1325 | generator loss = 6.491473197937012 | discriminator loss = 0.011363385245203972\n",
      "epoch number 9 | batch number 1525 | generator loss = 1.895836591720581 | discriminator loss = 0.25524279475212097\n",
      "epoch number 9 | batch number 1725 | generator loss = 3.693697690963745 | discriminator loss = 0.03281675651669502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:16<00:00, 49.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "os.makedirs(\"./DCGAN_results\", exist_ok=True)\n",
    "\n",
    "for ep in tqdm(range(num_eps)):\n",
    "    for idx, (images, _) in enumerate(data_loader):\n",
    "\n",
    "        # generate grounnd truths for real and fake images\n",
    "        real_label = torch.full((images.shape[0], 1), 1, dtype = torch.float32).to(device)\n",
    "        fake_label = torch.full((images.shape[0], 1), 0, dtype = torch.float32).to(device)\n",
    "\n",
    "        # get a real image\n",
    "        real_images = images.to(device)\n",
    "\n",
    "        # train the generator model\n",
    "        opt_gen.zero_grad()\n",
    "\n",
    "        # generate a batch of images based on random noise as input\n",
    "        noise = torch.randn(images.shape[0], noise_size).to(device)\n",
    "        fake_images = gen(noise)\n",
    "\n",
    "        # generator model optimization - how well can it fool the discriminator\n",
    "        generator_loss = adv_loss_func(disc(fake_images), real_label)\n",
    "        generator_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # train the discriminator model\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        # calculate discriminator loss as average of mistakes(losses) in confusing real images as fake and vice versa\n",
    "        actual_image_loss = adv_loss_func(disc(real_images), real_label)\n",
    "        fake_image_loss = adv_loss_func(disc(fake_images.detach()), fake_label)\n",
    "        discriminator_loss = (actual_image_loss + fake_image_loss) / 2\n",
    "\n",
    "        # discriminator model optimization\n",
    "        discriminator_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        batches_completed = ep * len(dloader) + idx\n",
    "        if batches_completed % 200 == 0:\n",
    "            print(f\"epoch number {ep} | batch number {idx} | generator loss = {generator_loss.item()} | discriminator loss = {discriminator_loss.item()}\")\n",
    "            save_image(fake_images.data[:25], f\"DCGAN_results/{batches_completed}.png\", nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu_py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
