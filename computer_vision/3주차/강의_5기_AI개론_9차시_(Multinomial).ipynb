{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장 다중 분류 (Mulitnomial classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"부록3 매트플롯립 입문\"에서 한글 폰트를 올바르게 출력하기 위한 설치 방법을 설명했다. 설치 방법은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트 설치\n",
    "\n",
    "!sudo apt-get install -y fonts-nanum* | tail -n 1\n",
    "!sudo fc-cache -fv\n",
    "!rm -rf ~/.cache/matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 설치\n",
    "\n",
    "!pip install torchviz | tail -n 1\n",
    "!pip install torchinfo | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모든 설치가 끝나면 한글 폰트를 바르게 출력하기 위해 **[런타임]** -> **[런타임 다시시작]**을 클릭한 다음, 아래 셀부터 코드를 실행해 주십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# 폰트 관련 용도\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# Colab, Linux\n",
    "# 나눔 고딕 폰트의 경로 명시\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
    "\n",
    "# Window \n",
    "# font_name = \"NanumBarunGothic\"\n",
    "\n",
    "# Mac\n",
    "# font_name = \"AppleGothic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 관련 라이브러리\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot\n",
    "from torchinfo import summary\n",
    "\n",
    "# Iris dataset\n",
    "import pandas  as pd\n",
    "# from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 폰트 설정\n",
    "plt.rcParams['font.family'] = font_name\n",
    "\n",
    "# 기본 폰트 사이즈 변경\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# 기본 그래프 사이즈 변경\n",
    "plt.rcParams['figure.figsize'] = (6,6)\n",
    "\n",
    "# 기본 그리드 표시\n",
    "# 필요에 따라 설정할 때는, plt.grid()\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams[\"grid.linestyle\"] = \":\"\n",
    "\n",
    "# 마이너스 기호 정상 출력\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 넘파이 부동소수점 자릿수 표시\n",
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning 표시 끄기\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris = \n",
      " {'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n",
      "iris keys = \n",
      " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "target_names = \n",
      " ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 준비\n",
    "\n",
    "# 라이브러리 임포트\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "# 데이터 불러오기\n",
    "iris = load_iris()\n",
    "print(\"iris = \\n\", iris)\n",
    "print('iris keys = \\n', iris.keys())\n",
    "print(\"target_names = \\n\", iris[\"target_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 타입 : <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "원본 데이터 크기 : (150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터와 정답 데이터\n",
    "x_org, y_org = iris.data, iris.target\n",
    "\n",
    "# 결과 확인\n",
    "print('원본 데이터 타입 :', type(x_org), type(y_org))\n",
    "print('원본 데이터 크기 :', x_org.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 (150, 2) (150,)\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터로 sepal(꽃받침) length(0)와 petal(꽃잎) length(2)를 추출\n",
    "x_select = x_org[:,[0,2]]\n",
    "\n",
    "# 결과 확인\n",
    "print('원본 데이터', x_select.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 검증 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2) (75, 2) (75,) (75,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 검증 데이터로 분할(셔플도 동시에 실시함)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_select, y_org, train_size=75, test_size=75, \n",
    "    random_state=123)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터의 산포도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 정답별로 분할\n",
    "\n",
    "x_t0 = x_train[y_train == 0]\n",
    "x_t1 = x_train[y_train == 1]\n",
    "x_t2 = x_train[y_train == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 산포도 출력\n",
    "\n",
    "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='k', s=50, label='0 (setosa)')\n",
    "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='b', s=50, label='1 (versicolor)')\n",
    "plt.scatter(x_t2[:,0], x_t2[:,1], marker='^', c='r', s=50, label='2 (virginica)')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('petal_length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_input: 2  n_output: 3\n"
     ]
    }
   ],
   "source": [
    "# 학습용 파라미터 설정\n",
    "\n",
    "# 입력 차원수\n",
    "n_input = x_train.shape[1]\n",
    "\n",
    "# 출력 차원수\n",
    "# 분류 클래스 수, 여기서는 3\n",
    "n_output = len(list(set(y_train)))\n",
    "\n",
    "# 결과 확인\n",
    "print(f'n_input: {n_input}  n_output: {n_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "# 2입력 3출력 로지스틱 회귀 모델\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "                \n",
    "        # 초깃값을 모두 1로 함\n",
    "        # \"딥러닝을 위한 수학\"과 조건을 맞추기 위한 목적        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        return x1\n",
    "    \n",
    "# 인스턴스 생성\n",
    "net = Net(n_input, n_output)\n",
    "# list(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('l1.weight', Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True))\n",
      "('l1.bias', Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# 모델 내부 파라미터 확인\n",
    "# l1.weight는 행렬, l1.bias는 벡터\n",
    "\n",
    "for parameter in net.named_parameters():\n",
    "    print(parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 개요 표시 1\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Net                                      [3]                       --\n",
       "├─Linear: 1-1                            [3]                       9\n",
       "==========================================================================================\n",
       "Total params: 9\n",
       "Trainable params: 9\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 개요 표시 2\n",
    "\n",
    "summary(net, (2,), device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 알고리즘과 손실 함수의 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수： 교차 엔트로피 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 학습률\n",
    "lr = 0.01\n",
    "\n",
    "# 최적화 함수: 경사 하강법\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 x_train과 정답 데이터 y_train의 텐서 변수화\n",
    "\n",
    "inputs = torch.tensor(x_train).float()\n",
    "labels = torch.tensor(y_train).long() \n",
    "\n",
    "# 검증 데이터의 텐서 변수화\n",
    "\n",
    "inputs_test = torch.tensor(x_test).float()\n",
    "labels_test = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실의 계산 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.0 (20240811.2233)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"214pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 214.00 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 210,-402.75 210,4 -4,4\"/>\n",
       "<!-- 2250189258976 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2250189258976</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"130,-32.75 76,-32.75 76,0 130,0 130,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 2250209513088 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2250209513088</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"159,-89.5 47,-89.5 47,-68.75 159,-68.75 159,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">NllLossBackward0</text>\n",
       "</g>\n",
       "<!-- 2250209513088&#45;&gt;2250189258976 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2250209513088&#45;&gt;2250189258976</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-68.36C103,-61.89 103,-53.05 103,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-44.55 103,-34.55 99.5,-44.55 106.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 2250209513136 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2250209513136</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168,-146.25 38,-146.25 38,-125.5 168,-125.5 168,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n",
       "</g>\n",
       "<!-- 2250209513136&#45;&gt;2250209513088 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2250209513136&#45;&gt;2250209513088</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-125.09C103,-118.47 103,-109.47 103,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-101.34 103,-91.34 99.5,-101.34 106.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 2250209511504 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2250209511504</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-203 53,-203 53,-182.25 153,-182.25 153,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 2250209511504&#45;&gt;2250209513136 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2250209511504&#45;&gt;2250209513136</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-181.84C103,-175.22 103,-166.22 103,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-158.09 103,-148.09 99.5,-158.09 106.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 2250209512464 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2250209512464</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-259.75 0,-259.75 0,-239 100,-239 100,-259.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2250209512464&#45;&gt;2250209511504 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2250209512464&#45;&gt;2250209511504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.48,-238.59C66.79,-231.03 77.09,-220.39 85.84,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.11,-214.04 92.55,-204.42 83.08,-209.17 88.11,-214.04\"/>\n",
       "</g>\n",
       "<!-- 2249763587632 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2249763587632</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"79,-329.25 21,-329.25 21,-295.75 79,-295.75 79,-329.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-315.75\" font-family=\"monospace\" font-size=\"10.00\">l1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 2249763587632&#45;&gt;2250209512464 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2249763587632&#45;&gt;2250209512464</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-295.44C50,-288.1 50,-279.32 50,-271.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.73 50,-261.73 46.5,-271.73 53.5,-271.73\"/>\n",
       "</g>\n",
       "<!-- 2250209509776 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2250209509776</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"194,-259.75 118,-259.75 118,-239 194,-239 194,-259.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 2250209509776&#45;&gt;2250209511504 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2250209509776&#45;&gt;2250209511504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.52,-238.59C139.21,-231.03 128.91,-220.39 120.16,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.92,-209.17 113.45,-204.42 117.89,-214.04 122.92,-209.17\"/>\n",
       "</g>\n",
       "<!-- 2250209510256 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2250209510256</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"206,-322.88 106,-322.88 106,-302.12 206,-302.12 206,-322.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-309.38\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2250209510256&#45;&gt;2250209509776 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2250209510256&#45;&gt;2250209509776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156,-301.68C156,-293.52 156,-281.63 156,-271.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.5,-271.48 156,-261.48 152.5,-271.48 159.5,-271.48\"/>\n",
       "</g>\n",
       "<!-- 2249763587472 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2249763587472</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"191,-398.75 121,-398.75 121,-365.25 191,-365.25 191,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-385.25\" font-family=\"monospace\" font-size=\"10.00\">l1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-372.5\" font-family=\"monospace\" font-size=\"10.00\"> (3, 2)</text>\n",
       "</g>\n",
       "<!-- 2249763587472&#45;&gt;2250209510256 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2249763587472&#45;&gt;2250209510256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156,-365C156,-355.9 156,-344.39 156,-334.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.5,-334.84 156,-324.84 152.5,-334.84 159.5,-334.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x20beaf04790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측 계산\n",
    "outputs = net(inputs)\n",
    "\n",
    "# 손실 계산\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# 손실의 계산 그래프 시각화\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 라벨을 얻는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([12.0000, 12.7000,  7.6000, 13.0000, 12.3000,  7.6000,  7.3000, 11.1000,\n",
      "        12.1000, 13.3000,  8.0000,  7.0000, 10.3000,  7.6000, 11.7000, 13.3000,\n",
      "         7.4000, 13.5000,  8.2000,  8.4000, 12.7000,  6.6000,  7.9000, 12.2000,\n",
      "        14.6000, 12.0000, 10.2000, 10.5000,  7.1000,  7.3000, 12.6000, 12.7000,\n",
      "         7.4000,  7.7000, 10.8000, 11.5000, 11.5000, 14.0000, 12.8000, 10.8000,\n",
      "        10.8000, 15.2000,  7.5000,  7.8000, 11.1000, 13.6000, 12.9000, 14.2000,\n",
      "        12.7000,  7.6000, 10.9000,  7.0000, 10.9000, 11.2000,  7.4000, 11.7000,\n",
      "        13.3000, 11.5000, 13.4000, 12.7000,  7.7000, 11.8000,  7.0000, 12.6000,\n",
      "        11.7000, 10.9000,  9.2000, 12.2000, 10.4000, 12.1000,  7.5000,  9.1000,\n",
      "        11.1000, 12.0000, 14.3000], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.max 함수 호출\n",
    "# 2번째 인수는 축을 의미함. 1이면 행별로 집계\n",
    "print(torch.max(outputs, 1))\n",
    "# print(torch.argmax(outputs, 1))\n",
    "\n",
    "# 예측 라벨 리스트를 취득\n",
    "torch.max(outputs, 1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "lr = 0.01\n",
    "\n",
    "# 초기화\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 손실 함수： 교차 엔트로피 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 함수: 경사 하강법\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 반복 횟수\n",
    "num_epochs = 10000\n",
    "\n",
    "# 평가 결과 기록\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09263, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.03580 acc: 0.40000 val_loss: 1.06403, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 1.00477 acc: 0.40000 val_loss: 1.03347, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.97672 acc: 0.40000 val_loss: 1.00264, val_acc: 0.26667\n",
      "Epoch [40/10000], loss: 0.95057 acc: 0.41333 val_loss: 0.97351, val_acc: 0.26667\n",
      "Epoch [50/10000], loss: 0.92616 acc: 0.48000 val_loss: 0.94631, val_acc: 0.38667\n",
      "Epoch [60/10000], loss: 0.90338 acc: 0.69333 val_loss: 0.92098, val_acc: 0.56000\n",
      "Epoch [70/10000], loss: 0.88212 acc: 0.70667 val_loss: 0.89740, val_acc: 0.60000\n",
      "Epoch [80/10000], loss: 0.86227 acc: 0.70667 val_loss: 0.87545, val_acc: 0.61333\n",
      "Epoch [90/10000], loss: 0.84373 acc: 0.70667 val_loss: 0.85500, val_acc: 0.62667\n",
      "Epoch [100/10000], loss: 0.82640 acc: 0.70667 val_loss: 0.83594, val_acc: 0.62667\n",
      "Epoch [110/10000], loss: 0.81019 acc: 0.72000 val_loss: 0.81815, val_acc: 0.62667\n",
      "Epoch [120/10000], loss: 0.79500 acc: 0.72000 val_loss: 0.80153, val_acc: 0.62667\n",
      "Epoch [130/10000], loss: 0.78077 acc: 0.73333 val_loss: 0.78599, val_acc: 0.62667\n",
      "Epoch [140/10000], loss: 0.76741 acc: 0.74667 val_loss: 0.77142, val_acc: 0.64000\n",
      "Epoch [150/10000], loss: 0.75485 acc: 0.74667 val_loss: 0.75777, val_acc: 0.65333\n",
      "Epoch [160/10000], loss: 0.74303 acc: 0.74667 val_loss: 0.74494, val_acc: 0.68000\n",
      "Epoch [170/10000], loss: 0.73189 acc: 0.76000 val_loss: 0.73288, val_acc: 0.70667\n",
      "Epoch [180/10000], loss: 0.72138 acc: 0.77333 val_loss: 0.72151, val_acc: 0.76000\n",
      "Epoch [190/10000], loss: 0.71145 acc: 0.82667 val_loss: 0.71079, val_acc: 0.78667\n",
      "Epoch [200/10000], loss: 0.70205 acc: 0.82667 val_loss: 0.70067, val_acc: 0.78667\n",
      "Epoch [210/10000], loss: 0.69315 acc: 0.84000 val_loss: 0.69109, val_acc: 0.80000\n",
      "Epoch [220/10000], loss: 0.68470 acc: 0.84000 val_loss: 0.68202, val_acc: 0.80000\n",
      "Epoch [230/10000], loss: 0.67667 acc: 0.86667 val_loss: 0.67341, val_acc: 0.81333\n",
      "Epoch [240/10000], loss: 0.66904 acc: 0.86667 val_loss: 0.66524, val_acc: 0.81333\n",
      "Epoch [250/10000], loss: 0.66176 acc: 0.86667 val_loss: 0.65746, val_acc: 0.82667\n",
      "Epoch [260/10000], loss: 0.65483 acc: 0.85333 val_loss: 0.65005, val_acc: 0.82667\n",
      "Epoch [270/10000], loss: 0.64820 acc: 0.85333 val_loss: 0.64299, val_acc: 0.82667\n",
      "Epoch [280/10000], loss: 0.64187 acc: 0.85333 val_loss: 0.63625, val_acc: 0.82667\n",
      "Epoch [290/10000], loss: 0.63581 acc: 0.86667 val_loss: 0.62980, val_acc: 0.82667\n",
      "Epoch [300/10000], loss: 0.63000 acc: 0.88000 val_loss: 0.62363, val_acc: 0.82667\n",
      "Epoch [310/10000], loss: 0.62443 acc: 0.89333 val_loss: 0.61772, val_acc: 0.82667\n",
      "Epoch [320/10000], loss: 0.61909 acc: 0.89333 val_loss: 0.61205, val_acc: 0.82667\n",
      "Epoch [330/10000], loss: 0.61394 acc: 0.89333 val_loss: 0.60661, val_acc: 0.82667\n",
      "Epoch [340/10000], loss: 0.60900 acc: 0.89333 val_loss: 0.60138, val_acc: 0.84000\n",
      "Epoch [350/10000], loss: 0.60423 acc: 0.89333 val_loss: 0.59635, val_acc: 0.84000\n",
      "Epoch [360/10000], loss: 0.59964 acc: 0.90667 val_loss: 0.59150, val_acc: 0.85333\n",
      "Epoch [370/10000], loss: 0.59521 acc: 0.92000 val_loss: 0.58683, val_acc: 0.86667\n",
      "Epoch [380/10000], loss: 0.59093 acc: 0.92000 val_loss: 0.58232, val_acc: 0.86667\n",
      "Epoch [390/10000], loss: 0.58679 acc: 0.92000 val_loss: 0.57797, val_acc: 0.86667\n",
      "Epoch [400/10000], loss: 0.58279 acc: 0.92000 val_loss: 0.57377, val_acc: 0.86667\n",
      "Epoch [410/10000], loss: 0.57891 acc: 0.92000 val_loss: 0.56970, val_acc: 0.86667\n",
      "Epoch [420/10000], loss: 0.57516 acc: 0.92000 val_loss: 0.56576, val_acc: 0.86667\n",
      "Epoch [430/10000], loss: 0.57152 acc: 0.90667 val_loss: 0.56195, val_acc: 0.86667\n",
      "Epoch [440/10000], loss: 0.56799 acc: 0.90667 val_loss: 0.55825, val_acc: 0.86667\n",
      "Epoch [450/10000], loss: 0.56456 acc: 0.90667 val_loss: 0.55466, val_acc: 0.86667\n",
      "Epoch [460/10000], loss: 0.56123 acc: 0.90667 val_loss: 0.55118, val_acc: 0.86667\n",
      "Epoch [470/10000], loss: 0.55799 acc: 0.90667 val_loss: 0.54779, val_acc: 0.88000\n",
      "Epoch [480/10000], loss: 0.55484 acc: 0.90667 val_loss: 0.54451, val_acc: 0.88000\n",
      "Epoch [490/10000], loss: 0.55177 acc: 0.90667 val_loss: 0.54131, val_acc: 0.88000\n",
      "Epoch [500/10000], loss: 0.54878 acc: 0.90667 val_loss: 0.53819, val_acc: 0.88000\n",
      "Epoch [510/10000], loss: 0.54587 acc: 0.90667 val_loss: 0.53516, val_acc: 0.88000\n",
      "Epoch [520/10000], loss: 0.54303 acc: 0.90667 val_loss: 0.53221, val_acc: 0.88000\n",
      "Epoch [530/10000], loss: 0.54026 acc: 0.90667 val_loss: 0.52933, val_acc: 0.88000\n",
      "Epoch [540/10000], loss: 0.53755 acc: 0.90667 val_loss: 0.52652, val_acc: 0.88000\n",
      "Epoch [550/10000], loss: 0.53491 acc: 0.90667 val_loss: 0.52377, val_acc: 0.88000\n",
      "Epoch [560/10000], loss: 0.53233 acc: 0.90667 val_loss: 0.52110, val_acc: 0.88000\n",
      "Epoch [570/10000], loss: 0.52981 acc: 0.90667 val_loss: 0.51848, val_acc: 0.88000\n",
      "Epoch [580/10000], loss: 0.52734 acc: 0.90667 val_loss: 0.51592, val_acc: 0.88000\n",
      "Epoch [590/10000], loss: 0.52493 acc: 0.90667 val_loss: 0.51342, val_acc: 0.88000\n",
      "Epoch [600/10000], loss: 0.52256 acc: 0.90667 val_loss: 0.51098, val_acc: 0.88000\n",
      "Epoch [610/10000], loss: 0.52025 acc: 0.90667 val_loss: 0.50859, val_acc: 0.88000\n",
      "Epoch [620/10000], loss: 0.51798 acc: 0.90667 val_loss: 0.50624, val_acc: 0.88000\n",
      "Epoch [630/10000], loss: 0.51576 acc: 0.90667 val_loss: 0.50395, val_acc: 0.88000\n",
      "Epoch [640/10000], loss: 0.51358 acc: 0.90667 val_loss: 0.50170, val_acc: 0.88000\n",
      "Epoch [650/10000], loss: 0.51144 acc: 0.90667 val_loss: 0.49949, val_acc: 0.88000\n",
      "Epoch [660/10000], loss: 0.50934 acc: 0.90667 val_loss: 0.49733, val_acc: 0.89333\n",
      "Epoch [670/10000], loss: 0.50728 acc: 0.90667 val_loss: 0.49521, val_acc: 0.90667\n",
      "Epoch [680/10000], loss: 0.50526 acc: 0.90667 val_loss: 0.49313, val_acc: 0.90667\n",
      "Epoch [690/10000], loss: 0.50328 acc: 0.90667 val_loss: 0.49109, val_acc: 0.90667\n",
      "Epoch [700/10000], loss: 0.50133 acc: 0.90667 val_loss: 0.48908, val_acc: 0.90667\n",
      "Epoch [710/10000], loss: 0.49941 acc: 0.90667 val_loss: 0.48711, val_acc: 0.90667\n",
      "Epoch [720/10000], loss: 0.49752 acc: 0.90667 val_loss: 0.48517, val_acc: 0.90667\n",
      "Epoch [730/10000], loss: 0.49567 acc: 0.90667 val_loss: 0.48327, val_acc: 0.90667\n",
      "Epoch [740/10000], loss: 0.49385 acc: 0.90667 val_loss: 0.48140, val_acc: 0.90667\n",
      "Epoch [750/10000], loss: 0.49205 acc: 0.90667 val_loss: 0.47956, val_acc: 0.90667\n",
      "Epoch [760/10000], loss: 0.49029 acc: 0.90667 val_loss: 0.47775, val_acc: 0.90667\n",
      "Epoch [770/10000], loss: 0.48855 acc: 0.90667 val_loss: 0.47597, val_acc: 0.90667\n",
      "Epoch [780/10000], loss: 0.48684 acc: 0.90667 val_loss: 0.47422, val_acc: 0.90667\n",
      "Epoch [790/10000], loss: 0.48515 acc: 0.89333 val_loss: 0.47249, val_acc: 0.92000\n",
      "Epoch [800/10000], loss: 0.48349 acc: 0.89333 val_loss: 0.47079, val_acc: 0.92000\n",
      "Epoch [810/10000], loss: 0.48186 acc: 0.89333 val_loss: 0.46912, val_acc: 0.92000\n",
      "Epoch [820/10000], loss: 0.48024 acc: 0.89333 val_loss: 0.46747, val_acc: 0.92000\n",
      "Epoch [830/10000], loss: 0.47865 acc: 0.89333 val_loss: 0.46585, val_acc: 0.92000\n",
      "Epoch [840/10000], loss: 0.47709 acc: 0.89333 val_loss: 0.46425, val_acc: 0.92000\n",
      "Epoch [850/10000], loss: 0.47554 acc: 0.89333 val_loss: 0.46267, val_acc: 0.92000\n",
      "Epoch [860/10000], loss: 0.47402 acc: 0.89333 val_loss: 0.46111, val_acc: 0.92000\n",
      "Epoch [870/10000], loss: 0.47251 acc: 0.89333 val_loss: 0.45958, val_acc: 0.92000\n",
      "Epoch [880/10000], loss: 0.47103 acc: 0.89333 val_loss: 0.45806, val_acc: 0.92000\n",
      "Epoch [890/10000], loss: 0.46956 acc: 0.89333 val_loss: 0.45657, val_acc: 0.92000\n",
      "Epoch [900/10000], loss: 0.46811 acc: 0.89333 val_loss: 0.45509, val_acc: 0.92000\n",
      "Epoch [910/10000], loss: 0.46668 acc: 0.89333 val_loss: 0.45364, val_acc: 0.92000\n",
      "Epoch [920/10000], loss: 0.46527 acc: 0.89333 val_loss: 0.45220, val_acc: 0.92000\n",
      "Epoch [930/10000], loss: 0.46388 acc: 0.89333 val_loss: 0.45078, val_acc: 0.92000\n",
      "Epoch [940/10000], loss: 0.46250 acc: 0.89333 val_loss: 0.44938, val_acc: 0.92000\n",
      "Epoch [950/10000], loss: 0.46114 acc: 0.89333 val_loss: 0.44800, val_acc: 0.92000\n",
      "Epoch [960/10000], loss: 0.45980 acc: 0.89333 val_loss: 0.44663, val_acc: 0.92000\n",
      "Epoch [970/10000], loss: 0.45847 acc: 0.89333 val_loss: 0.44528, val_acc: 0.92000\n",
      "Epoch [980/10000], loss: 0.45716 acc: 0.89333 val_loss: 0.44395, val_acc: 0.92000\n",
      "Epoch [990/10000], loss: 0.45586 acc: 0.89333 val_loss: 0.44263, val_acc: 0.92000\n",
      "Epoch [1000/10000], loss: 0.45458 acc: 0.89333 val_loss: 0.44133, val_acc: 0.92000\n",
      "Epoch [1010/10000], loss: 0.45331 acc: 0.89333 val_loss: 0.44004, val_acc: 0.92000\n",
      "Epoch [1020/10000], loss: 0.45205 acc: 0.89333 val_loss: 0.43877, val_acc: 0.92000\n",
      "Epoch [1030/10000], loss: 0.45081 acc: 0.89333 val_loss: 0.43751, val_acc: 0.92000\n",
      "Epoch [1040/10000], loss: 0.44958 acc: 0.89333 val_loss: 0.43626, val_acc: 0.92000\n",
      "Epoch [1050/10000], loss: 0.44836 acc: 0.89333 val_loss: 0.43503, val_acc: 0.92000\n",
      "Epoch [1060/10000], loss: 0.44716 acc: 0.89333 val_loss: 0.43381, val_acc: 0.92000\n",
      "Epoch [1070/10000], loss: 0.44597 acc: 0.89333 val_loss: 0.43260, val_acc: 0.92000\n",
      "Epoch [1080/10000], loss: 0.44479 acc: 0.89333 val_loss: 0.43141, val_acc: 0.92000\n",
      "Epoch [1090/10000], loss: 0.44363 acc: 0.89333 val_loss: 0.43023, val_acc: 0.92000\n",
      "Epoch [1100/10000], loss: 0.44247 acc: 0.89333 val_loss: 0.42906, val_acc: 0.92000\n",
      "Epoch [1110/10000], loss: 0.44133 acc: 0.89333 val_loss: 0.42790, val_acc: 0.92000\n",
      "Epoch [1120/10000], loss: 0.44020 acc: 0.89333 val_loss: 0.42676, val_acc: 0.92000\n",
      "Epoch [1130/10000], loss: 0.43908 acc: 0.89333 val_loss: 0.42562, val_acc: 0.92000\n",
      "Epoch [1140/10000], loss: 0.43797 acc: 0.89333 val_loss: 0.42450, val_acc: 0.92000\n",
      "Epoch [1150/10000], loss: 0.43687 acc: 0.89333 val_loss: 0.42339, val_acc: 0.92000\n",
      "Epoch [1160/10000], loss: 0.43578 acc: 0.89333 val_loss: 0.42229, val_acc: 0.92000\n",
      "Epoch [1170/10000], loss: 0.43470 acc: 0.89333 val_loss: 0.42120, val_acc: 0.92000\n",
      "Epoch [1180/10000], loss: 0.43363 acc: 0.89333 val_loss: 0.42012, val_acc: 0.92000\n",
      "Epoch [1190/10000], loss: 0.43257 acc: 0.89333 val_loss: 0.41905, val_acc: 0.92000\n",
      "Epoch [1200/10000], loss: 0.43152 acc: 0.89333 val_loss: 0.41799, val_acc: 0.92000\n",
      "Epoch [1210/10000], loss: 0.43048 acc: 0.89333 val_loss: 0.41694, val_acc: 0.92000\n",
      "Epoch [1220/10000], loss: 0.42945 acc: 0.89333 val_loss: 0.41590, val_acc: 0.92000\n",
      "Epoch [1230/10000], loss: 0.42843 acc: 0.89333 val_loss: 0.41487, val_acc: 0.92000\n",
      "Epoch [1240/10000], loss: 0.42742 acc: 0.89333 val_loss: 0.41384, val_acc: 0.92000\n",
      "Epoch [1250/10000], loss: 0.42641 acc: 0.89333 val_loss: 0.41283, val_acc: 0.92000\n",
      "Epoch [1260/10000], loss: 0.42542 acc: 0.89333 val_loss: 0.41182, val_acc: 0.92000\n",
      "Epoch [1270/10000], loss: 0.42443 acc: 0.89333 val_loss: 0.41083, val_acc: 0.92000\n",
      "Epoch [1280/10000], loss: 0.42345 acc: 0.89333 val_loss: 0.40984, val_acc: 0.92000\n",
      "Epoch [1290/10000], loss: 0.42248 acc: 0.89333 val_loss: 0.40886, val_acc: 0.92000\n",
      "Epoch [1300/10000], loss: 0.42152 acc: 0.89333 val_loss: 0.40789, val_acc: 0.92000\n",
      "Epoch [1310/10000], loss: 0.42056 acc: 0.89333 val_loss: 0.40693, val_acc: 0.92000\n",
      "Epoch [1320/10000], loss: 0.41962 acc: 0.89333 val_loss: 0.40598, val_acc: 0.92000\n",
      "Epoch [1330/10000], loss: 0.41868 acc: 0.89333 val_loss: 0.40503, val_acc: 0.93333\n",
      "Epoch [1340/10000], loss: 0.41775 acc: 0.89333 val_loss: 0.40409, val_acc: 0.93333\n",
      "Epoch [1350/10000], loss: 0.41682 acc: 0.89333 val_loss: 0.40316, val_acc: 0.93333\n",
      "Epoch [1360/10000], loss: 0.41590 acc: 0.89333 val_loss: 0.40224, val_acc: 0.93333\n",
      "Epoch [1370/10000], loss: 0.41499 acc: 0.89333 val_loss: 0.40132, val_acc: 0.93333\n",
      "Epoch [1380/10000], loss: 0.41409 acc: 0.89333 val_loss: 0.40041, val_acc: 0.93333\n",
      "Epoch [1390/10000], loss: 0.41320 acc: 0.89333 val_loss: 0.39951, val_acc: 0.93333\n",
      "Epoch [1400/10000], loss: 0.41231 acc: 0.89333 val_loss: 0.39861, val_acc: 0.93333\n",
      "Epoch [1410/10000], loss: 0.41143 acc: 0.89333 val_loss: 0.39773, val_acc: 0.93333\n",
      "Epoch [1420/10000], loss: 0.41055 acc: 0.89333 val_loss: 0.39685, val_acc: 0.93333\n",
      "Epoch [1430/10000], loss: 0.40968 acc: 0.89333 val_loss: 0.39597, val_acc: 0.93333\n",
      "Epoch [1440/10000], loss: 0.40882 acc: 0.89333 val_loss: 0.39510, val_acc: 0.93333\n",
      "Epoch [1450/10000], loss: 0.40796 acc: 0.89333 val_loss: 0.39424, val_acc: 0.93333\n",
      "Epoch [1460/10000], loss: 0.40711 acc: 0.89333 val_loss: 0.39339, val_acc: 0.93333\n",
      "Epoch [1470/10000], loss: 0.40627 acc: 0.89333 val_loss: 0.39254, val_acc: 0.93333\n",
      "Epoch [1480/10000], loss: 0.40543 acc: 0.90667 val_loss: 0.39170, val_acc: 0.93333\n",
      "Epoch [1490/10000], loss: 0.40460 acc: 0.90667 val_loss: 0.39086, val_acc: 0.93333\n",
      "Epoch [1500/10000], loss: 0.40378 acc: 0.90667 val_loss: 0.39003, val_acc: 0.93333\n",
      "Epoch [1510/10000], loss: 0.40296 acc: 0.90667 val_loss: 0.38921, val_acc: 0.93333\n",
      "Epoch [1520/10000], loss: 0.40214 acc: 0.90667 val_loss: 0.38839, val_acc: 0.93333\n",
      "Epoch [1530/10000], loss: 0.40134 acc: 0.90667 val_loss: 0.38758, val_acc: 0.93333\n",
      "Epoch [1540/10000], loss: 0.40053 acc: 0.90667 val_loss: 0.38677, val_acc: 0.93333\n",
      "Epoch [1550/10000], loss: 0.39974 acc: 0.90667 val_loss: 0.38597, val_acc: 0.93333\n",
      "Epoch [1560/10000], loss: 0.39894 acc: 0.90667 val_loss: 0.38517, val_acc: 0.94667\n",
      "Epoch [1570/10000], loss: 0.39816 acc: 0.90667 val_loss: 0.38438, val_acc: 0.94667\n",
      "Epoch [1580/10000], loss: 0.39738 acc: 0.90667 val_loss: 0.38360, val_acc: 0.94667\n",
      "Epoch [1590/10000], loss: 0.39660 acc: 0.90667 val_loss: 0.38282, val_acc: 0.94667\n",
      "Epoch [1600/10000], loss: 0.39583 acc: 0.90667 val_loss: 0.38204, val_acc: 0.94667\n",
      "Epoch [1610/10000], loss: 0.39507 acc: 0.90667 val_loss: 0.38128, val_acc: 0.94667\n",
      "Epoch [1620/10000], loss: 0.39431 acc: 0.90667 val_loss: 0.38051, val_acc: 0.94667\n",
      "Epoch [1630/10000], loss: 0.39355 acc: 0.90667 val_loss: 0.37975, val_acc: 0.94667\n",
      "Epoch [1640/10000], loss: 0.39280 acc: 0.90667 val_loss: 0.37900, val_acc: 0.94667\n",
      "Epoch [1650/10000], loss: 0.39206 acc: 0.90667 val_loss: 0.37825, val_acc: 0.94667\n",
      "Epoch [1660/10000], loss: 0.39132 acc: 0.90667 val_loss: 0.37751, val_acc: 0.94667\n",
      "Epoch [1670/10000], loss: 0.39058 acc: 0.90667 val_loss: 0.37677, val_acc: 0.94667\n",
      "Epoch [1680/10000], loss: 0.38985 acc: 0.90667 val_loss: 0.37604, val_acc: 0.94667\n",
      "Epoch [1690/10000], loss: 0.38913 acc: 0.90667 val_loss: 0.37531, val_acc: 0.94667\n",
      "Epoch [1700/10000], loss: 0.38841 acc: 0.90667 val_loss: 0.37458, val_acc: 0.94667\n",
      "Epoch [1710/10000], loss: 0.38769 acc: 0.90667 val_loss: 0.37386, val_acc: 0.94667\n",
      "Epoch [1720/10000], loss: 0.38698 acc: 0.90667 val_loss: 0.37315, val_acc: 0.94667\n",
      "Epoch [1730/10000], loss: 0.38627 acc: 0.90667 val_loss: 0.37244, val_acc: 0.94667\n",
      "Epoch [1740/10000], loss: 0.38557 acc: 0.90667 val_loss: 0.37173, val_acc: 0.94667\n",
      "Epoch [1750/10000], loss: 0.38487 acc: 0.90667 val_loss: 0.37103, val_acc: 0.94667\n",
      "Epoch [1760/10000], loss: 0.38417 acc: 0.90667 val_loss: 0.37033, val_acc: 0.94667\n",
      "Epoch [1770/10000], loss: 0.38348 acc: 0.90667 val_loss: 0.36964, val_acc: 0.94667\n",
      "Epoch [1780/10000], loss: 0.38280 acc: 0.90667 val_loss: 0.36895, val_acc: 0.94667\n",
      "Epoch [1790/10000], loss: 0.38212 acc: 0.90667 val_loss: 0.36826, val_acc: 0.94667\n",
      "Epoch [1800/10000], loss: 0.38144 acc: 0.90667 val_loss: 0.36758, val_acc: 0.94667\n",
      "Epoch [1810/10000], loss: 0.38076 acc: 0.90667 val_loss: 0.36690, val_acc: 0.94667\n",
      "Epoch [1820/10000], loss: 0.38009 acc: 0.90667 val_loss: 0.36623, val_acc: 0.94667\n",
      "Epoch [1830/10000], loss: 0.37943 acc: 0.90667 val_loss: 0.36556, val_acc: 0.94667\n",
      "Epoch [1840/10000], loss: 0.37877 acc: 0.90667 val_loss: 0.36490, val_acc: 0.94667\n",
      "Epoch [1850/10000], loss: 0.37811 acc: 0.90667 val_loss: 0.36424, val_acc: 0.94667\n",
      "Epoch [1860/10000], loss: 0.37746 acc: 0.90667 val_loss: 0.36358, val_acc: 0.94667\n",
      "Epoch [1870/10000], loss: 0.37681 acc: 0.90667 val_loss: 0.36293, val_acc: 0.94667\n",
      "Epoch [1880/10000], loss: 0.37616 acc: 0.90667 val_loss: 0.36228, val_acc: 0.94667\n",
      "Epoch [1890/10000], loss: 0.37552 acc: 0.90667 val_loss: 0.36163, val_acc: 0.94667\n",
      "Epoch [1900/10000], loss: 0.37488 acc: 0.90667 val_loss: 0.36099, val_acc: 0.94667\n",
      "Epoch [1910/10000], loss: 0.37424 acc: 0.90667 val_loss: 0.36035, val_acc: 0.94667\n",
      "Epoch [1920/10000], loss: 0.37361 acc: 0.90667 val_loss: 0.35972, val_acc: 0.94667\n",
      "Epoch [1930/10000], loss: 0.37298 acc: 0.90667 val_loss: 0.35909, val_acc: 0.94667\n",
      "Epoch [1940/10000], loss: 0.37236 acc: 0.90667 val_loss: 0.35846, val_acc: 0.94667\n",
      "Epoch [1950/10000], loss: 0.37174 acc: 0.90667 val_loss: 0.35784, val_acc: 0.94667\n",
      "Epoch [1960/10000], loss: 0.37112 acc: 0.90667 val_loss: 0.35722, val_acc: 0.94667\n",
      "Epoch [1970/10000], loss: 0.37051 acc: 0.90667 val_loss: 0.35660, val_acc: 0.94667\n",
      "Epoch [1980/10000], loss: 0.36990 acc: 0.90667 val_loss: 0.35599, val_acc: 0.94667\n",
      "Epoch [1990/10000], loss: 0.36929 acc: 0.90667 val_loss: 0.35538, val_acc: 0.94667\n",
      "Epoch [2000/10000], loss: 0.36869 acc: 0.90667 val_loss: 0.35477, val_acc: 0.94667\n",
      "Epoch [2010/10000], loss: 0.36809 acc: 0.90667 val_loss: 0.35417, val_acc: 0.94667\n",
      "Epoch [2020/10000], loss: 0.36749 acc: 0.90667 val_loss: 0.35357, val_acc: 0.94667\n",
      "Epoch [2030/10000], loss: 0.36690 acc: 0.90667 val_loss: 0.35298, val_acc: 0.94667\n",
      "Epoch [2040/10000], loss: 0.36631 acc: 0.90667 val_loss: 0.35238, val_acc: 0.94667\n",
      "Epoch [2050/10000], loss: 0.36572 acc: 0.90667 val_loss: 0.35179, val_acc: 0.94667\n",
      "Epoch [2060/10000], loss: 0.36514 acc: 0.90667 val_loss: 0.35121, val_acc: 0.94667\n",
      "Epoch [2070/10000], loss: 0.36455 acc: 0.90667 val_loss: 0.35062, val_acc: 0.94667\n",
      "Epoch [2080/10000], loss: 0.36398 acc: 0.90667 val_loss: 0.35004, val_acc: 0.94667\n",
      "Epoch [2090/10000], loss: 0.36340 acc: 0.90667 val_loss: 0.34947, val_acc: 0.94667\n",
      "Epoch [2100/10000], loss: 0.36283 acc: 0.90667 val_loss: 0.34889, val_acc: 0.94667\n",
      "Epoch [2110/10000], loss: 0.36226 acc: 0.90667 val_loss: 0.34832, val_acc: 0.94667\n",
      "Epoch [2120/10000], loss: 0.36170 acc: 0.90667 val_loss: 0.34775, val_acc: 0.94667\n",
      "Epoch [2130/10000], loss: 0.36114 acc: 0.90667 val_loss: 0.34719, val_acc: 0.94667\n",
      "Epoch [2140/10000], loss: 0.36058 acc: 0.90667 val_loss: 0.34663, val_acc: 0.94667\n",
      "Epoch [2150/10000], loss: 0.36002 acc: 0.90667 val_loss: 0.34607, val_acc: 0.94667\n",
      "Epoch [2160/10000], loss: 0.35947 acc: 0.90667 val_loss: 0.34551, val_acc: 0.94667\n",
      "Epoch [2170/10000], loss: 0.35892 acc: 0.90667 val_loss: 0.34496, val_acc: 0.94667\n",
      "Epoch [2180/10000], loss: 0.35837 acc: 0.90667 val_loss: 0.34441, val_acc: 0.94667\n",
      "Epoch [2190/10000], loss: 0.35782 acc: 0.90667 val_loss: 0.34386, val_acc: 0.94667\n",
      "Epoch [2200/10000], loss: 0.35728 acc: 0.90667 val_loss: 0.34331, val_acc: 0.94667\n",
      "Epoch [2210/10000], loss: 0.35674 acc: 0.90667 val_loss: 0.34277, val_acc: 0.94667\n",
      "Epoch [2220/10000], loss: 0.35621 acc: 0.90667 val_loss: 0.34223, val_acc: 0.94667\n",
      "Epoch [2230/10000], loss: 0.35567 acc: 0.90667 val_loss: 0.34170, val_acc: 0.94667\n",
      "Epoch [2240/10000], loss: 0.35514 acc: 0.90667 val_loss: 0.34116, val_acc: 0.94667\n",
      "Epoch [2250/10000], loss: 0.35461 acc: 0.90667 val_loss: 0.34063, val_acc: 0.94667\n",
      "Epoch [2260/10000], loss: 0.35409 acc: 0.90667 val_loss: 0.34010, val_acc: 0.94667\n",
      "Epoch [2270/10000], loss: 0.35356 acc: 0.90667 val_loss: 0.33958, val_acc: 0.94667\n",
      "Epoch [2280/10000], loss: 0.35304 acc: 0.90667 val_loss: 0.33905, val_acc: 0.94667\n",
      "Epoch [2290/10000], loss: 0.35253 acc: 0.90667 val_loss: 0.33853, val_acc: 0.94667\n",
      "Epoch [2300/10000], loss: 0.35201 acc: 0.90667 val_loss: 0.33802, val_acc: 0.94667\n",
      "Epoch [2310/10000], loss: 0.35150 acc: 0.90667 val_loss: 0.33750, val_acc: 0.94667\n",
      "Epoch [2320/10000], loss: 0.35099 acc: 0.90667 val_loss: 0.33699, val_acc: 0.94667\n",
      "Epoch [2330/10000], loss: 0.35048 acc: 0.90667 val_loss: 0.33648, val_acc: 0.94667\n",
      "Epoch [2340/10000], loss: 0.34998 acc: 0.90667 val_loss: 0.33597, val_acc: 0.94667\n",
      "Epoch [2350/10000], loss: 0.34947 acc: 0.90667 val_loss: 0.33546, val_acc: 0.94667\n",
      "Epoch [2360/10000], loss: 0.34897 acc: 0.90667 val_loss: 0.33496, val_acc: 0.94667\n",
      "Epoch [2370/10000], loss: 0.34848 acc: 0.90667 val_loss: 0.33446, val_acc: 0.94667\n",
      "Epoch [2380/10000], loss: 0.34798 acc: 0.90667 val_loss: 0.33396, val_acc: 0.94667\n",
      "Epoch [2390/10000], loss: 0.34749 acc: 0.90667 val_loss: 0.33347, val_acc: 0.94667\n",
      "Epoch [2400/10000], loss: 0.34700 acc: 0.90667 val_loss: 0.33297, val_acc: 0.94667\n",
      "Epoch [2410/10000], loss: 0.34651 acc: 0.90667 val_loss: 0.33248, val_acc: 0.94667\n",
      "Epoch [2420/10000], loss: 0.34602 acc: 0.90667 val_loss: 0.33199, val_acc: 0.94667\n",
      "Epoch [2430/10000], loss: 0.34554 acc: 0.90667 val_loss: 0.33151, val_acc: 0.94667\n",
      "Epoch [2440/10000], loss: 0.34506 acc: 0.90667 val_loss: 0.33102, val_acc: 0.94667\n",
      "Epoch [2450/10000], loss: 0.34458 acc: 0.90667 val_loss: 0.33054, val_acc: 0.94667\n",
      "Epoch [2460/10000], loss: 0.34411 acc: 0.90667 val_loss: 0.33006, val_acc: 0.94667\n",
      "Epoch [2470/10000], loss: 0.34363 acc: 0.90667 val_loss: 0.32959, val_acc: 0.94667\n",
      "Epoch [2480/10000], loss: 0.34316 acc: 0.90667 val_loss: 0.32911, val_acc: 0.94667\n",
      "Epoch [2490/10000], loss: 0.34269 acc: 0.90667 val_loss: 0.32864, val_acc: 0.94667\n",
      "Epoch [2500/10000], loss: 0.34222 acc: 0.90667 val_loss: 0.32817, val_acc: 0.94667\n",
      "Epoch [2510/10000], loss: 0.34176 acc: 0.90667 val_loss: 0.32770, val_acc: 0.94667\n",
      "Epoch [2520/10000], loss: 0.34130 acc: 0.90667 val_loss: 0.32723, val_acc: 0.94667\n",
      "Epoch [2530/10000], loss: 0.34083 acc: 0.90667 val_loss: 0.32677, val_acc: 0.94667\n",
      "Epoch [2540/10000], loss: 0.34038 acc: 0.90667 val_loss: 0.32631, val_acc: 0.94667\n",
      "Epoch [2550/10000], loss: 0.33992 acc: 0.90667 val_loss: 0.32585, val_acc: 0.94667\n",
      "Epoch [2560/10000], loss: 0.33947 acc: 0.90667 val_loss: 0.32539, val_acc: 0.94667\n",
      "Epoch [2570/10000], loss: 0.33901 acc: 0.90667 val_loss: 0.32493, val_acc: 0.94667\n",
      "Epoch [2580/10000], loss: 0.33856 acc: 0.90667 val_loss: 0.32448, val_acc: 0.94667\n",
      "Epoch [2590/10000], loss: 0.33812 acc: 0.90667 val_loss: 0.32403, val_acc: 0.94667\n",
      "Epoch [2600/10000], loss: 0.33767 acc: 0.90667 val_loss: 0.32358, val_acc: 0.94667\n",
      "Epoch [2610/10000], loss: 0.33723 acc: 0.90667 val_loss: 0.32313, val_acc: 0.94667\n",
      "Epoch [2620/10000], loss: 0.33678 acc: 0.90667 val_loss: 0.32269, val_acc: 0.94667\n",
      "Epoch [2630/10000], loss: 0.33634 acc: 0.90667 val_loss: 0.32225, val_acc: 0.94667\n",
      "Epoch [2640/10000], loss: 0.33591 acc: 0.90667 val_loss: 0.32180, val_acc: 0.94667\n",
      "Epoch [2650/10000], loss: 0.33547 acc: 0.90667 val_loss: 0.32136, val_acc: 0.94667\n",
      "Epoch [2660/10000], loss: 0.33504 acc: 0.90667 val_loss: 0.32093, val_acc: 0.94667\n",
      "Epoch [2670/10000], loss: 0.33460 acc: 0.90667 val_loss: 0.32049, val_acc: 0.94667\n",
      "Epoch [2680/10000], loss: 0.33417 acc: 0.90667 val_loss: 0.32006, val_acc: 0.94667\n",
      "Epoch [2690/10000], loss: 0.33375 acc: 0.90667 val_loss: 0.31963, val_acc: 0.94667\n",
      "Epoch [2700/10000], loss: 0.33332 acc: 0.90667 val_loss: 0.31920, val_acc: 0.94667\n",
      "Epoch [2710/10000], loss: 0.33290 acc: 0.90667 val_loss: 0.31877, val_acc: 0.94667\n",
      "Epoch [2720/10000], loss: 0.33247 acc: 0.90667 val_loss: 0.31834, val_acc: 0.94667\n",
      "Epoch [2730/10000], loss: 0.33205 acc: 0.90667 val_loss: 0.31792, val_acc: 0.94667\n",
      "Epoch [2740/10000], loss: 0.33164 acc: 0.90667 val_loss: 0.31750, val_acc: 0.94667\n",
      "Epoch [2750/10000], loss: 0.33122 acc: 0.90667 val_loss: 0.31708, val_acc: 0.94667\n",
      "Epoch [2760/10000], loss: 0.33080 acc: 0.90667 val_loss: 0.31666, val_acc: 0.94667\n",
      "Epoch [2770/10000], loss: 0.33039 acc: 0.90667 val_loss: 0.31624, val_acc: 0.94667\n",
      "Epoch [2780/10000], loss: 0.32998 acc: 0.90667 val_loss: 0.31583, val_acc: 0.94667\n",
      "Epoch [2790/10000], loss: 0.32957 acc: 0.90667 val_loss: 0.31542, val_acc: 0.94667\n",
      "Epoch [2800/10000], loss: 0.32916 acc: 0.90667 val_loss: 0.31500, val_acc: 0.94667\n",
      "Epoch [2810/10000], loss: 0.32876 acc: 0.90667 val_loss: 0.31460, val_acc: 0.94667\n",
      "Epoch [2820/10000], loss: 0.32835 acc: 0.90667 val_loss: 0.31419, val_acc: 0.94667\n",
      "Epoch [2830/10000], loss: 0.32795 acc: 0.90667 val_loss: 0.31378, val_acc: 0.94667\n",
      "Epoch [2840/10000], loss: 0.32755 acc: 0.90667 val_loss: 0.31338, val_acc: 0.94667\n",
      "Epoch [2850/10000], loss: 0.32715 acc: 0.90667 val_loss: 0.31297, val_acc: 0.94667\n",
      "Epoch [2860/10000], loss: 0.32675 acc: 0.90667 val_loss: 0.31257, val_acc: 0.94667\n",
      "Epoch [2870/10000], loss: 0.32636 acc: 0.90667 val_loss: 0.31217, val_acc: 0.94667\n",
      "Epoch [2880/10000], loss: 0.32597 acc: 0.90667 val_loss: 0.31178, val_acc: 0.94667\n",
      "Epoch [2890/10000], loss: 0.32557 acc: 0.90667 val_loss: 0.31138, val_acc: 0.94667\n",
      "Epoch [2900/10000], loss: 0.32518 acc: 0.90667 val_loss: 0.31099, val_acc: 0.94667\n",
      "Epoch [2910/10000], loss: 0.32480 acc: 0.90667 val_loss: 0.31060, val_acc: 0.94667\n",
      "Epoch [2920/10000], loss: 0.32441 acc: 0.90667 val_loss: 0.31020, val_acc: 0.94667\n",
      "Epoch [2930/10000], loss: 0.32402 acc: 0.90667 val_loss: 0.30982, val_acc: 0.94667\n",
      "Epoch [2940/10000], loss: 0.32364 acc: 0.90667 val_loss: 0.30943, val_acc: 0.94667\n",
      "Epoch [2950/10000], loss: 0.32326 acc: 0.90667 val_loss: 0.30904, val_acc: 0.94667\n",
      "Epoch [2960/10000], loss: 0.32288 acc: 0.90667 val_loss: 0.30866, val_acc: 0.94667\n",
      "Epoch [2970/10000], loss: 0.32250 acc: 0.90667 val_loss: 0.30827, val_acc: 0.94667\n",
      "Epoch [2980/10000], loss: 0.32212 acc: 0.90667 val_loss: 0.30789, val_acc: 0.94667\n",
      "Epoch [2990/10000], loss: 0.32175 acc: 0.90667 val_loss: 0.30751, val_acc: 0.94667\n",
      "Epoch [3000/10000], loss: 0.32137 acc: 0.90667 val_loss: 0.30714, val_acc: 0.94667\n",
      "Epoch [3010/10000], loss: 0.32100 acc: 0.90667 val_loss: 0.30676, val_acc: 0.94667\n",
      "Epoch [3020/10000], loss: 0.32063 acc: 0.90667 val_loss: 0.30638, val_acc: 0.94667\n",
      "Epoch [3030/10000], loss: 0.32026 acc: 0.90667 val_loss: 0.30601, val_acc: 0.94667\n",
      "Epoch [3040/10000], loss: 0.31989 acc: 0.90667 val_loss: 0.30564, val_acc: 0.94667\n",
      "Epoch [3050/10000], loss: 0.31952 acc: 0.90667 val_loss: 0.30527, val_acc: 0.94667\n",
      "Epoch [3060/10000], loss: 0.31916 acc: 0.90667 val_loss: 0.30490, val_acc: 0.94667\n",
      "Epoch [3070/10000], loss: 0.31880 acc: 0.90667 val_loss: 0.30453, val_acc: 0.94667\n",
      "Epoch [3080/10000], loss: 0.31844 acc: 0.90667 val_loss: 0.30417, val_acc: 0.94667\n",
      "Epoch [3090/10000], loss: 0.31807 acc: 0.90667 val_loss: 0.30380, val_acc: 0.94667\n",
      "Epoch [3100/10000], loss: 0.31772 acc: 0.90667 val_loss: 0.30344, val_acc: 0.94667\n",
      "Epoch [3110/10000], loss: 0.31736 acc: 0.90667 val_loss: 0.30308, val_acc: 0.94667\n",
      "Epoch [3120/10000], loss: 0.31700 acc: 0.90667 val_loss: 0.30272, val_acc: 0.94667\n",
      "Epoch [3130/10000], loss: 0.31665 acc: 0.90667 val_loss: 0.30236, val_acc: 0.94667\n",
      "Epoch [3140/10000], loss: 0.31630 acc: 0.90667 val_loss: 0.30200, val_acc: 0.94667\n",
      "Epoch [3150/10000], loss: 0.31594 acc: 0.90667 val_loss: 0.30165, val_acc: 0.94667\n",
      "Epoch [3160/10000], loss: 0.31559 acc: 0.90667 val_loss: 0.30129, val_acc: 0.94667\n",
      "Epoch [3170/10000], loss: 0.31525 acc: 0.90667 val_loss: 0.30094, val_acc: 0.94667\n",
      "Epoch [3180/10000], loss: 0.31490 acc: 0.90667 val_loss: 0.30059, val_acc: 0.94667\n",
      "Epoch [3190/10000], loss: 0.31455 acc: 0.90667 val_loss: 0.30024, val_acc: 0.94667\n",
      "Epoch [3200/10000], loss: 0.31421 acc: 0.90667 val_loss: 0.29989, val_acc: 0.94667\n",
      "Epoch [3210/10000], loss: 0.31386 acc: 0.90667 val_loss: 0.29954, val_acc: 0.94667\n",
      "Epoch [3220/10000], loss: 0.31352 acc: 0.90667 val_loss: 0.29920, val_acc: 0.94667\n",
      "Epoch [3230/10000], loss: 0.31318 acc: 0.90667 val_loss: 0.29885, val_acc: 0.94667\n",
      "Epoch [3240/10000], loss: 0.31284 acc: 0.90667 val_loss: 0.29851, val_acc: 0.94667\n",
      "Epoch [3250/10000], loss: 0.31251 acc: 0.90667 val_loss: 0.29816, val_acc: 0.94667\n",
      "Epoch [3260/10000], loss: 0.31217 acc: 0.90667 val_loss: 0.29782, val_acc: 0.94667\n",
      "Epoch [3270/10000], loss: 0.31183 acc: 0.90667 val_loss: 0.29748, val_acc: 0.94667\n",
      "Epoch [3280/10000], loss: 0.31150 acc: 0.90667 val_loss: 0.29715, val_acc: 0.94667\n",
      "Epoch [3290/10000], loss: 0.31117 acc: 0.90667 val_loss: 0.29681, val_acc: 0.94667\n",
      "Epoch [3300/10000], loss: 0.31084 acc: 0.90667 val_loss: 0.29647, val_acc: 0.94667\n",
      "Epoch [3310/10000], loss: 0.31051 acc: 0.90667 val_loss: 0.29614, val_acc: 0.94667\n",
      "Epoch [3320/10000], loss: 0.31018 acc: 0.90667 val_loss: 0.29581, val_acc: 0.94667\n",
      "Epoch [3330/10000], loss: 0.30985 acc: 0.90667 val_loss: 0.29548, val_acc: 0.94667\n",
      "Epoch [3340/10000], loss: 0.30953 acc: 0.90667 val_loss: 0.29515, val_acc: 0.94667\n",
      "Epoch [3350/10000], loss: 0.30920 acc: 0.90667 val_loss: 0.29482, val_acc: 0.94667\n",
      "Epoch [3360/10000], loss: 0.30888 acc: 0.90667 val_loss: 0.29449, val_acc: 0.94667\n",
      "Epoch [3370/10000], loss: 0.30856 acc: 0.90667 val_loss: 0.29416, val_acc: 0.94667\n",
      "Epoch [3380/10000], loss: 0.30824 acc: 0.90667 val_loss: 0.29384, val_acc: 0.94667\n",
      "Epoch [3390/10000], loss: 0.30792 acc: 0.90667 val_loss: 0.29351, val_acc: 0.94667\n",
      "Epoch [3400/10000], loss: 0.30760 acc: 0.90667 val_loss: 0.29319, val_acc: 0.94667\n",
      "Epoch [3410/10000], loss: 0.30728 acc: 0.90667 val_loss: 0.29287, val_acc: 0.94667\n",
      "Epoch [3420/10000], loss: 0.30696 acc: 0.90667 val_loss: 0.29255, val_acc: 0.94667\n",
      "Epoch [3430/10000], loss: 0.30665 acc: 0.90667 val_loss: 0.29223, val_acc: 0.94667\n",
      "Epoch [3440/10000], loss: 0.30634 acc: 0.90667 val_loss: 0.29191, val_acc: 0.94667\n",
      "Epoch [3450/10000], loss: 0.30602 acc: 0.90667 val_loss: 0.29159, val_acc: 0.94667\n",
      "Epoch [3460/10000], loss: 0.30571 acc: 0.90667 val_loss: 0.29128, val_acc: 0.94667\n",
      "Epoch [3470/10000], loss: 0.30540 acc: 0.90667 val_loss: 0.29096, val_acc: 0.94667\n",
      "Epoch [3480/10000], loss: 0.30509 acc: 0.90667 val_loss: 0.29065, val_acc: 0.94667\n",
      "Epoch [3490/10000], loss: 0.30479 acc: 0.90667 val_loss: 0.29034, val_acc: 0.94667\n",
      "Epoch [3500/10000], loss: 0.30448 acc: 0.90667 val_loss: 0.29003, val_acc: 0.94667\n",
      "Epoch [3510/10000], loss: 0.30417 acc: 0.90667 val_loss: 0.28972, val_acc: 0.94667\n",
      "Epoch [3520/10000], loss: 0.30387 acc: 0.90667 val_loss: 0.28941, val_acc: 0.94667\n",
      "Epoch [3530/10000], loss: 0.30357 acc: 0.90667 val_loss: 0.28910, val_acc: 0.94667\n",
      "Epoch [3540/10000], loss: 0.30327 acc: 0.90667 val_loss: 0.28879, val_acc: 0.94667\n",
      "Epoch [3550/10000], loss: 0.30297 acc: 0.90667 val_loss: 0.28849, val_acc: 0.94667\n",
      "Epoch [3560/10000], loss: 0.30267 acc: 0.90667 val_loss: 0.28818, val_acc: 0.94667\n",
      "Epoch [3570/10000], loss: 0.30237 acc: 0.90667 val_loss: 0.28788, val_acc: 0.94667\n",
      "Epoch [3580/10000], loss: 0.30207 acc: 0.90667 val_loss: 0.28758, val_acc: 0.94667\n",
      "Epoch [3590/10000], loss: 0.30177 acc: 0.90667 val_loss: 0.28728, val_acc: 0.94667\n",
      "Epoch [3600/10000], loss: 0.30148 acc: 0.90667 val_loss: 0.28698, val_acc: 0.94667\n",
      "Epoch [3610/10000], loss: 0.30119 acc: 0.90667 val_loss: 0.28668, val_acc: 0.94667\n",
      "Epoch [3620/10000], loss: 0.30089 acc: 0.90667 val_loss: 0.28638, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.30060 acc: 0.90667 val_loss: 0.28608, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.30031 acc: 0.90667 val_loss: 0.28579, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.30002 acc: 0.90667 val_loss: 0.28549, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.29973 acc: 0.90667 val_loss: 0.28520, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.29944 acc: 0.90667 val_loss: 0.28491, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.29916 acc: 0.90667 val_loss: 0.28462, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.29887 acc: 0.90667 val_loss: 0.28433, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.29859 acc: 0.90667 val_loss: 0.28404, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.29830 acc: 0.90667 val_loss: 0.28375, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.29802 acc: 0.90667 val_loss: 0.28346, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.29774 acc: 0.90667 val_loss: 0.28318, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.29746 acc: 0.90667 val_loss: 0.28289, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.29718 acc: 0.90667 val_loss: 0.28261, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.29690 acc: 0.90667 val_loss: 0.28232, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.29663 acc: 0.90667 val_loss: 0.28204, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.29635 acc: 0.90667 val_loss: 0.28176, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.29607 acc: 0.90667 val_loss: 0.28148, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.29580 acc: 0.90667 val_loss: 0.28120, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.29553 acc: 0.90667 val_loss: 0.28092, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.29525 acc: 0.90667 val_loss: 0.28064, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.29498 acc: 0.90667 val_loss: 0.28037, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.29471 acc: 0.90667 val_loss: 0.28009, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.29444 acc: 0.90667 val_loss: 0.27982, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.29418 acc: 0.90667 val_loss: 0.27954, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.29391 acc: 0.90667 val_loss: 0.27927, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.29364 acc: 0.90667 val_loss: 0.27900, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.29338 acc: 0.90667 val_loss: 0.27873, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.29311 acc: 0.90667 val_loss: 0.27846, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.29285 acc: 0.90667 val_loss: 0.27819, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.29258 acc: 0.90667 val_loss: 0.27792, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.29232 acc: 0.90667 val_loss: 0.27766, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.29206 acc: 0.90667 val_loss: 0.27739, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.29180 acc: 0.90667 val_loss: 0.27712, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.29154 acc: 0.90667 val_loss: 0.27686, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.29128 acc: 0.90667 val_loss: 0.27660, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.29103 acc: 0.90667 val_loss: 0.27633, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.29077 acc: 0.90667 val_loss: 0.27607, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.29052 acc: 0.90667 val_loss: 0.27581, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.29026 acc: 0.90667 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.29001 acc: 0.90667 val_loss: 0.27529, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.28975 acc: 0.90667 val_loss: 0.27504, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.28950 acc: 0.90667 val_loss: 0.27478, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.28925 acc: 0.90667 val_loss: 0.27452, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.28900 acc: 0.90667 val_loss: 0.27427, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.28875 acc: 0.90667 val_loss: 0.27401, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.28850 acc: 0.90667 val_loss: 0.27376, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.28826 acc: 0.90667 val_loss: 0.27351, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.28801 acc: 0.90667 val_loss: 0.27325, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.28776 acc: 0.90667 val_loss: 0.27300, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.28752 acc: 0.90667 val_loss: 0.27275, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.28727 acc: 0.90667 val_loss: 0.27250, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.28703 acc: 0.90667 val_loss: 0.27225, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.28679 acc: 0.90667 val_loss: 0.27200, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.28654 acc: 0.90667 val_loss: 0.27176, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.28630 acc: 0.90667 val_loss: 0.27151, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.28606 acc: 0.90667 val_loss: 0.27127, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.28582 acc: 0.90667 val_loss: 0.27102, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.28559 acc: 0.90667 val_loss: 0.27078, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.28535 acc: 0.90667 val_loss: 0.27053, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.28511 acc: 0.90667 val_loss: 0.27029, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.28487 acc: 0.90667 val_loss: 0.27005, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.28464 acc: 0.90667 val_loss: 0.26981, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.28440 acc: 0.90667 val_loss: 0.26957, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.28417 acc: 0.90667 val_loss: 0.26933, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.28394 acc: 0.90667 val_loss: 0.26909, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.28370 acc: 0.90667 val_loss: 0.26885, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.28347 acc: 0.90667 val_loss: 0.26862, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.28324 acc: 0.90667 val_loss: 0.26838, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.28301 acc: 0.90667 val_loss: 0.26815, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.28278 acc: 0.90667 val_loss: 0.26791, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.28255 acc: 0.90667 val_loss: 0.26768, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.28233 acc: 0.90667 val_loss: 0.26744, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.28210 acc: 0.90667 val_loss: 0.26721, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.28187 acc: 0.90667 val_loss: 0.26698, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.28165 acc: 0.90667 val_loss: 0.26675, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.28142 acc: 0.90667 val_loss: 0.26652, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.28120 acc: 0.90667 val_loss: 0.26629, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.28098 acc: 0.90667 val_loss: 0.26606, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.28075 acc: 0.90667 val_loss: 0.26583, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.28053 acc: 0.90667 val_loss: 0.26560, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.28031 acc: 0.90667 val_loss: 0.26538, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.28009 acc: 0.90667 val_loss: 0.26515, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.27987 acc: 0.90667 val_loss: 0.26493, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.27965 acc: 0.90667 val_loss: 0.26470, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.27943 acc: 0.90667 val_loss: 0.26448, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.27922 acc: 0.90667 val_loss: 0.26426, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.27900 acc: 0.90667 val_loss: 0.26403, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.27878 acc: 0.90667 val_loss: 0.26381, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.27857 acc: 0.90667 val_loss: 0.26359, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.27835 acc: 0.90667 val_loss: 0.26337, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.27814 acc: 0.90667 val_loss: 0.26315, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.27792 acc: 0.90667 val_loss: 0.26293, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.27771 acc: 0.90667 val_loss: 0.26271, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.27750 acc: 0.90667 val_loss: 0.26249, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.27729 acc: 0.90667 val_loss: 0.26228, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.27708 acc: 0.90667 val_loss: 0.26206, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.27687 acc: 0.90667 val_loss: 0.26185, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.27666 acc: 0.90667 val_loss: 0.26163, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.27645 acc: 0.90667 val_loss: 0.26142, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.27624 acc: 0.90667 val_loss: 0.26120, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.27603 acc: 0.90667 val_loss: 0.26099, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.27583 acc: 0.90667 val_loss: 0.26078, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.27562 acc: 0.90667 val_loss: 0.26057, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.27541 acc: 0.90667 val_loss: 0.26035, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.27521 acc: 0.90667 val_loss: 0.26014, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.27501 acc: 0.90667 val_loss: 0.25993, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.27480 acc: 0.90667 val_loss: 0.25973, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.27460 acc: 0.90667 val_loss: 0.25952, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.27440 acc: 0.90667 val_loss: 0.25931, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.27419 acc: 0.90667 val_loss: 0.25910, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.27399 acc: 0.90667 val_loss: 0.25889, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.27379 acc: 0.90667 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.27359 acc: 0.90667 val_loss: 0.25848, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.27339 acc: 0.90667 val_loss: 0.25828, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.27320 acc: 0.90667 val_loss: 0.25807, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.27300 acc: 0.90667 val_loss: 0.25787, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.27280 acc: 0.90667 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.27260 acc: 0.90667 val_loss: 0.25746, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.27241 acc: 0.90667 val_loss: 0.25726, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.27221 acc: 0.90667 val_loss: 0.25706, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.27202 acc: 0.90667 val_loss: 0.25686, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.27182 acc: 0.90667 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.27163 acc: 0.90667 val_loss: 0.25646, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.27143 acc: 0.90667 val_loss: 0.25626, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.27124 acc: 0.90667 val_loss: 0.25606, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.27105 acc: 0.90667 val_loss: 0.25587, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.27086 acc: 0.90667 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.27067 acc: 0.90667 val_loss: 0.25547, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.27048 acc: 0.90667 val_loss: 0.25528, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.27029 acc: 0.90667 val_loss: 0.25508, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.27010 acc: 0.90667 val_loss: 0.25489, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.26991 acc: 0.90667 val_loss: 0.25469, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.26972 acc: 0.90667 val_loss: 0.25450, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.26953 acc: 0.90667 val_loss: 0.25431, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.26935 acc: 0.90667 val_loss: 0.25411, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.26916 acc: 0.90667 val_loss: 0.25392, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.26897 acc: 0.90667 val_loss: 0.25373, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.26879 acc: 0.90667 val_loss: 0.25354, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.26860 acc: 0.90667 val_loss: 0.25335, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.26842 acc: 0.90667 val_loss: 0.25316, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.26824 acc: 0.90667 val_loss: 0.25297, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.26805 acc: 0.90667 val_loss: 0.25278, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.26787 acc: 0.90667 val_loss: 0.25259, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.26769 acc: 0.90667 val_loss: 0.25240, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.26751 acc: 0.90667 val_loss: 0.25222, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.26733 acc: 0.90667 val_loss: 0.25203, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.26715 acc: 0.90667 val_loss: 0.25184, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.26697 acc: 0.90667 val_loss: 0.25166, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.26679 acc: 0.90667 val_loss: 0.25147, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.26661 acc: 0.90667 val_loss: 0.25129, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.26643 acc: 0.90667 val_loss: 0.25111, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.26625 acc: 0.90667 val_loss: 0.25092, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.26608 acc: 0.90667 val_loss: 0.25074, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.26590 acc: 0.90667 val_loss: 0.25056, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.26572 acc: 0.90667 val_loss: 0.25037, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.26555 acc: 0.90667 val_loss: 0.25019, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.26537 acc: 0.90667 val_loss: 0.25001, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.26520 acc: 0.90667 val_loss: 0.24983, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.26502 acc: 0.90667 val_loss: 0.24965, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.26485 acc: 0.90667 val_loss: 0.24947, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.26468 acc: 0.90667 val_loss: 0.24929, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.26450 acc: 0.90667 val_loss: 0.24912, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.26433 acc: 0.90667 val_loss: 0.24894, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.26416 acc: 0.90667 val_loss: 0.24876, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.26399 acc: 0.90667 val_loss: 0.24858, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.26382 acc: 0.90667 val_loss: 0.24841, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.26365 acc: 0.90667 val_loss: 0.24823, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.26348 acc: 0.90667 val_loss: 0.24806, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.26331 acc: 0.90667 val_loss: 0.24788, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.26314 acc: 0.90667 val_loss: 0.24771, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.26297 acc: 0.90667 val_loss: 0.24753, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.26280 acc: 0.90667 val_loss: 0.24736, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.26264 acc: 0.90667 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.26247 acc: 0.90667 val_loss: 0.24701, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.26230 acc: 0.90667 val_loss: 0.24684, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.26214 acc: 0.90667 val_loss: 0.24667, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.26197 acc: 0.90667 val_loss: 0.24650, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.26181 acc: 0.90667 val_loss: 0.24633, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.26164 acc: 0.90667 val_loss: 0.24616, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.26148 acc: 0.90667 val_loss: 0.24599, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.26131 acc: 0.90667 val_loss: 0.24582, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.26115 acc: 0.90667 val_loss: 0.24565, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.26099 acc: 0.90667 val_loss: 0.24548, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.26083 acc: 0.90667 val_loss: 0.24531, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.26066 acc: 0.90667 val_loss: 0.24514, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.26050 acc: 0.90667 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.26034 acc: 0.90667 val_loss: 0.24481, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.26018 acc: 0.90667 val_loss: 0.24464, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.26002 acc: 0.90667 val_loss: 0.24448, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.25986 acc: 0.90667 val_loss: 0.24431, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.25970 acc: 0.90667 val_loss: 0.24415, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.25954 acc: 0.90667 val_loss: 0.24398, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.25939 acc: 0.90667 val_loss: 0.24382, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.25923 acc: 0.90667 val_loss: 0.24366, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.25907 acc: 0.90667 val_loss: 0.24349, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.25891 acc: 0.90667 val_loss: 0.24333, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.25876 acc: 0.90667 val_loss: 0.24317, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.25860 acc: 0.90667 val_loss: 0.24301, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.25845 acc: 0.90667 val_loss: 0.24285, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.25829 acc: 0.90667 val_loss: 0.24268, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.25814 acc: 0.90667 val_loss: 0.24252, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.25798 acc: 0.90667 val_loss: 0.24236, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.25783 acc: 0.90667 val_loss: 0.24220, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.25767 acc: 0.90667 val_loss: 0.24205, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.25752 acc: 0.90667 val_loss: 0.24189, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.25737 acc: 0.90667 val_loss: 0.24173, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.25722 acc: 0.90667 val_loss: 0.24157, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.25706 acc: 0.90667 val_loss: 0.24141, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.25691 acc: 0.90667 val_loss: 0.24126, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.25676 acc: 0.90667 val_loss: 0.24110, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.25661 acc: 0.90667 val_loss: 0.24094, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.25646 acc: 0.90667 val_loss: 0.24079, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.25631 acc: 0.90667 val_loss: 0.24063, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.25616 acc: 0.90667 val_loss: 0.24048, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.25601 acc: 0.90667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.25586 acc: 0.90667 val_loss: 0.24017, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.25571 acc: 0.90667 val_loss: 0.24001, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.25557 acc: 0.90667 val_loss: 0.23986, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.25542 acc: 0.90667 val_loss: 0.23971, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.25527 acc: 0.90667 val_loss: 0.23955, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.25513 acc: 0.90667 val_loss: 0.23940, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.25498 acc: 0.90667 val_loss: 0.23925, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.25483 acc: 0.90667 val_loss: 0.23910, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.25469 acc: 0.90667 val_loss: 0.23895, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.25454 acc: 0.90667 val_loss: 0.23879, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.25440 acc: 0.90667 val_loss: 0.23864, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.25425 acc: 0.90667 val_loss: 0.23849, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.25411 acc: 0.90667 val_loss: 0.23834, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.25397 acc: 0.90667 val_loss: 0.23819, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.25382 acc: 0.90667 val_loss: 0.23805, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.25368 acc: 0.90667 val_loss: 0.23790, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.25354 acc: 0.90667 val_loss: 0.23775, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.25340 acc: 0.90667 val_loss: 0.23760, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.25325 acc: 0.90667 val_loss: 0.23745, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.25311 acc: 0.90667 val_loss: 0.23731, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.25297 acc: 0.90667 val_loss: 0.23716, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.25283 acc: 0.90667 val_loss: 0.23701, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.25269 acc: 0.90667 val_loss: 0.23687, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.25255 acc: 0.90667 val_loss: 0.23672, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.25241 acc: 0.90667 val_loss: 0.23658, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.25227 acc: 0.90667 val_loss: 0.23643, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.25213 acc: 0.90667 val_loss: 0.23629, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.25199 acc: 0.90667 val_loss: 0.23614, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.25186 acc: 0.90667 val_loss: 0.23600, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.25172 acc: 0.90667 val_loss: 0.23586, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.25158 acc: 0.90667 val_loss: 0.23571, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.25144 acc: 0.90667 val_loss: 0.23557, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.25131 acc: 0.90667 val_loss: 0.23543, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.25117 acc: 0.90667 val_loss: 0.23529, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.25104 acc: 0.90667 val_loss: 0.23514, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.25090 acc: 0.90667 val_loss: 0.23500, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.25076 acc: 0.90667 val_loss: 0.23486, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.25063 acc: 0.90667 val_loss: 0.23472, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.25049 acc: 0.90667 val_loss: 0.23458, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.25036 acc: 0.90667 val_loss: 0.23444, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.25023 acc: 0.90667 val_loss: 0.23430, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.25009 acc: 0.90667 val_loss: 0.23416, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.24996 acc: 0.90667 val_loss: 0.23402, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.24983 acc: 0.90667 val_loss: 0.23388, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.24969 acc: 0.90667 val_loss: 0.23375, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.24956 acc: 0.90667 val_loss: 0.23361, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.24943 acc: 0.90667 val_loss: 0.23347, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.24930 acc: 0.90667 val_loss: 0.23333, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.24917 acc: 0.90667 val_loss: 0.23320, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.24904 acc: 0.90667 val_loss: 0.23306, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.24891 acc: 0.90667 val_loss: 0.23292, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.24878 acc: 0.90667 val_loss: 0.23279, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.24865 acc: 0.90667 val_loss: 0.23265, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.24852 acc: 0.90667 val_loss: 0.23252, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.24839 acc: 0.90667 val_loss: 0.23238, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.24826 acc: 0.90667 val_loss: 0.23225, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.24813 acc: 0.90667 val_loss: 0.23211, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.24800 acc: 0.90667 val_loss: 0.23198, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.24787 acc: 0.90667 val_loss: 0.23184, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.24775 acc: 0.90667 val_loss: 0.23171, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.24762 acc: 0.90667 val_loss: 0.23158, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.24749 acc: 0.90667 val_loss: 0.23145, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.24736 acc: 0.90667 val_loss: 0.23131, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.24724 acc: 0.90667 val_loss: 0.23118, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.24711 acc: 0.90667 val_loss: 0.23105, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.24699 acc: 0.90667 val_loss: 0.23092, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.24686 acc: 0.90667 val_loss: 0.23079, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.24674 acc: 0.90667 val_loss: 0.23066, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.24661 acc: 0.90667 val_loss: 0.23053, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.24649 acc: 0.90667 val_loss: 0.23040, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.24636 acc: 0.90667 val_loss: 0.23027, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.24624 acc: 0.90667 val_loss: 0.23014, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.24611 acc: 0.90667 val_loss: 0.23001, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.24599 acc: 0.90667 val_loss: 0.22988, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.24587 acc: 0.90667 val_loss: 0.22975, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.24575 acc: 0.90667 val_loss: 0.22962, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.24562 acc: 0.90667 val_loss: 0.22949, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.24550 acc: 0.90667 val_loss: 0.22936, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.24538 acc: 0.90667 val_loss: 0.22924, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.24526 acc: 0.90667 val_loss: 0.22911, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.24514 acc: 0.90667 val_loss: 0.22898, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.24502 acc: 0.90667 val_loss: 0.22886, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.24489 acc: 0.90667 val_loss: 0.22873, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.24477 acc: 0.90667 val_loss: 0.22860, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.24465 acc: 0.90667 val_loss: 0.22848, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.24453 acc: 0.90667 val_loss: 0.22835, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.24441 acc: 0.90667 val_loss: 0.22823, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.24430 acc: 0.90667 val_loss: 0.22810, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.24418 acc: 0.90667 val_loss: 0.22798, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.24406 acc: 0.90667 val_loss: 0.22785, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.24394 acc: 0.90667 val_loss: 0.22773, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.24382 acc: 0.90667 val_loss: 0.22761, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.24370 acc: 0.90667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.24359 acc: 0.90667 val_loss: 0.22736, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.24347 acc: 0.90667 val_loss: 0.22724, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.24335 acc: 0.90667 val_loss: 0.22711, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.24324 acc: 0.90667 val_loss: 0.22699, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.24312 acc: 0.90667 val_loss: 0.22687, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.24300 acc: 0.90667 val_loss: 0.22675, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.24289 acc: 0.90667 val_loss: 0.22663, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.24277 acc: 0.90667 val_loss: 0.22651, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.24266 acc: 0.90667 val_loss: 0.22638, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.24254 acc: 0.90667 val_loss: 0.22626, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.24243 acc: 0.90667 val_loss: 0.22614, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.24231 acc: 0.90667 val_loss: 0.22602, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.24220 acc: 0.90667 val_loss: 0.22590, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.24208 acc: 0.90667 val_loss: 0.22578, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.24197 acc: 0.90667 val_loss: 0.22566, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.24186 acc: 0.90667 val_loss: 0.22555, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.24174 acc: 0.90667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.24163 acc: 0.90667 val_loss: 0.22531, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.24152 acc: 0.90667 val_loss: 0.22519, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.24141 acc: 0.90667 val_loss: 0.22507, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.24129 acc: 0.90667 val_loss: 0.22495, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.24118 acc: 0.90667 val_loss: 0.22484, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.24107 acc: 0.90667 val_loss: 0.22472, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.24096 acc: 0.90667 val_loss: 0.22460, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.24085 acc: 0.90667 val_loss: 0.22449, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.24074 acc: 0.90667 val_loss: 0.22437, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.24063 acc: 0.90667 val_loss: 0.22425, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.24052 acc: 0.90667 val_loss: 0.22414, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.24041 acc: 0.90667 val_loss: 0.22402, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.24030 acc: 0.90667 val_loss: 0.22391, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.24019 acc: 0.90667 val_loss: 0.22379, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.24008 acc: 0.90667 val_loss: 0.22368, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.23997 acc: 0.90667 val_loss: 0.22356, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.23986 acc: 0.90667 val_loss: 0.22345, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.23975 acc: 0.90667 val_loss: 0.22333, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.23964 acc: 0.90667 val_loss: 0.22322, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.23953 acc: 0.90667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.23943 acc: 0.90667 val_loss: 0.22299, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.23932 acc: 0.90667 val_loss: 0.22288, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.23921 acc: 0.90667 val_loss: 0.22277, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.23910 acc: 0.90667 val_loss: 0.22265, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.23900 acc: 0.90667 val_loss: 0.22254, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.23889 acc: 0.90667 val_loss: 0.22243, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.23879 acc: 0.90667 val_loss: 0.22232, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.23868 acc: 0.90667 val_loss: 0.22221, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.23857 acc: 0.90667 val_loss: 0.22209, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.23847 acc: 0.90667 val_loss: 0.22198, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.23836 acc: 0.90667 val_loss: 0.22187, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.23826 acc: 0.90667 val_loss: 0.22176, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.23815 acc: 0.90667 val_loss: 0.22165, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.23805 acc: 0.90667 val_loss: 0.22154, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.23794 acc: 0.90667 val_loss: 0.22143, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.23784 acc: 0.90667 val_loss: 0.22132, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.23773 acc: 0.90667 val_loss: 0.22121, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.23763 acc: 0.90667 val_loss: 0.22110, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.23753 acc: 0.90667 val_loss: 0.22099, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.23742 acc: 0.90667 val_loss: 0.22088, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.23732 acc: 0.90667 val_loss: 0.22078, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.23722 acc: 0.90667 val_loss: 0.22067, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.23712 acc: 0.90667 val_loss: 0.22056, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.23701 acc: 0.90667 val_loss: 0.22045, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.23691 acc: 0.90667 val_loss: 0.22034, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.23681 acc: 0.90667 val_loss: 0.22024, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.23671 acc: 0.90667 val_loss: 0.22013, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.23661 acc: 0.90667 val_loss: 0.22002, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.23651 acc: 0.90667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.23640 acc: 0.90667 val_loss: 0.21981, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.23630 acc: 0.90667 val_loss: 0.21970, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.23620 acc: 0.90667 val_loss: 0.21960, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.23610 acc: 0.90667 val_loss: 0.21949, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.23600 acc: 0.90667 val_loss: 0.21939, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.23590 acc: 0.90667 val_loss: 0.21928, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.23580 acc: 0.90667 val_loss: 0.21918, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.23570 acc: 0.90667 val_loss: 0.21907, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.23560 acc: 0.90667 val_loss: 0.21897, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.23551 acc: 0.90667 val_loss: 0.21886, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.23541 acc: 0.90667 val_loss: 0.21876, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.23531 acc: 0.90667 val_loss: 0.21865, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.23521 acc: 0.90667 val_loss: 0.21855, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.23511 acc: 0.90667 val_loss: 0.21845, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.23501 acc: 0.90667 val_loss: 0.21834, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.23492 acc: 0.90667 val_loss: 0.21824, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.23482 acc: 0.90667 val_loss: 0.21814, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.23472 acc: 0.90667 val_loss: 0.21803, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.23462 acc: 0.90667 val_loss: 0.21793, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.23453 acc: 0.90667 val_loss: 0.21783, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.23443 acc: 0.90667 val_loss: 0.21773, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.23433 acc: 0.90667 val_loss: 0.21762, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.23424 acc: 0.90667 val_loss: 0.21752, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.23414 acc: 0.90667 val_loss: 0.21742, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.23405 acc: 0.90667 val_loss: 0.21732, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.23395 acc: 0.90667 val_loss: 0.21722, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.23385 acc: 0.90667 val_loss: 0.21712, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.23376 acc: 0.90667 val_loss: 0.21702, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.23366 acc: 0.90667 val_loss: 0.21692, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.23357 acc: 0.90667 val_loss: 0.21682, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.23348 acc: 0.90667 val_loss: 0.21672, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.23338 acc: 0.90667 val_loss: 0.21662, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.23329 acc: 0.90667 val_loss: 0.21652, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.23319 acc: 0.90667 val_loss: 0.21642, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.23310 acc: 0.90667 val_loss: 0.21632, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.23301 acc: 0.90667 val_loss: 0.21622, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.23291 acc: 0.90667 val_loss: 0.21612, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.23282 acc: 0.90667 val_loss: 0.21602, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.23273 acc: 0.90667 val_loss: 0.21592, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.23263 acc: 0.90667 val_loss: 0.21582, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.23254 acc: 0.90667 val_loss: 0.21573, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.23245 acc: 0.90667 val_loss: 0.21563, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.23236 acc: 0.90667 val_loss: 0.21553, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.23226 acc: 0.90667 val_loss: 0.21543, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.23217 acc: 0.90667 val_loss: 0.21534, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.23208 acc: 0.90667 val_loss: 0.21524, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.23199 acc: 0.90667 val_loss: 0.21514, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.23190 acc: 0.90667 val_loss: 0.21505, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.23181 acc: 0.90667 val_loss: 0.21495, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.23172 acc: 0.90667 val_loss: 0.21485, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.23162 acc: 0.90667 val_loss: 0.21476, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.23153 acc: 0.90667 val_loss: 0.21466, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.23144 acc: 0.90667 val_loss: 0.21457, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.23135 acc: 0.90667 val_loss: 0.21447, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.23126 acc: 0.90667 val_loss: 0.21437, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.23117 acc: 0.90667 val_loss: 0.21428, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.23108 acc: 0.90667 val_loss: 0.21418, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.23099 acc: 0.90667 val_loss: 0.21409, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.23091 acc: 0.90667 val_loss: 0.21400, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.23082 acc: 0.90667 val_loss: 0.21390, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.23073 acc: 0.90667 val_loss: 0.21381, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.23064 acc: 0.90667 val_loss: 0.21371, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.23055 acc: 0.90667 val_loss: 0.21362, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.23046 acc: 0.90667 val_loss: 0.21353, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.23037 acc: 0.90667 val_loss: 0.21343, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.23029 acc: 0.90667 val_loss: 0.21334, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.23020 acc: 0.90667 val_loss: 0.21325, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.23011 acc: 0.90667 val_loss: 0.21315, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.23002 acc: 0.90667 val_loss: 0.21306, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.22994 acc: 0.90667 val_loss: 0.21297, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.22985 acc: 0.90667 val_loss: 0.21288, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.22976 acc: 0.90667 val_loss: 0.21278, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.22968 acc: 0.90667 val_loss: 0.21269, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.22959 acc: 0.90667 val_loss: 0.21260, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.22950 acc: 0.90667 val_loss: 0.21251, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.22942 acc: 0.90667 val_loss: 0.21242, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.22933 acc: 0.90667 val_loss: 0.21233, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.22925 acc: 0.90667 val_loss: 0.21223, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.22916 acc: 0.90667 val_loss: 0.21214, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.22907 acc: 0.90667 val_loss: 0.21205, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.22899 acc: 0.90667 val_loss: 0.21196, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.22890 acc: 0.90667 val_loss: 0.21187, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.22882 acc: 0.90667 val_loss: 0.21178, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.22873 acc: 0.90667 val_loss: 0.21169, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.22865 acc: 0.90667 val_loss: 0.21160, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.22857 acc: 0.90667 val_loss: 0.21151, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.22848 acc: 0.90667 val_loss: 0.21142, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.22840 acc: 0.90667 val_loss: 0.21133, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.22831 acc: 0.90667 val_loss: 0.21124, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.22823 acc: 0.90667 val_loss: 0.21115, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.22815 acc: 0.90667 val_loss: 0.21107, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.22806 acc: 0.90667 val_loss: 0.21098, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.22798 acc: 0.90667 val_loss: 0.21089, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.22790 acc: 0.90667 val_loss: 0.21080, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.22781 acc: 0.90667 val_loss: 0.21071, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.22773 acc: 0.90667 val_loss: 0.21062, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.22765 acc: 0.90667 val_loss: 0.21054, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.22757 acc: 0.90667 val_loss: 0.21045, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.22748 acc: 0.90667 val_loss: 0.21036, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.22740 acc: 0.90667 val_loss: 0.21027, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.22732 acc: 0.90667 val_loss: 0.21019, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.22724 acc: 0.90667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.22716 acc: 0.90667 val_loss: 0.21001, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.22707 acc: 0.90667 val_loss: 0.20993, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.22699 acc: 0.90667 val_loss: 0.20984, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.22691 acc: 0.90667 val_loss: 0.20975, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.22683 acc: 0.90667 val_loss: 0.20967, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.22675 acc: 0.90667 val_loss: 0.20958, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.22667 acc: 0.90667 val_loss: 0.20950, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.22659 acc: 0.90667 val_loss: 0.20941, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.22651 acc: 0.90667 val_loss: 0.20932, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.22643 acc: 0.90667 val_loss: 0.20924, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.22635 acc: 0.90667 val_loss: 0.20915, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.22627 acc: 0.90667 val_loss: 0.20907, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.22619 acc: 0.90667 val_loss: 0.20898, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.22611 acc: 0.90667 val_loss: 0.20890, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.22603 acc: 0.90667 val_loss: 0.20881, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.22595 acc: 0.90667 val_loss: 0.20873, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.22587 acc: 0.90667 val_loss: 0.20865, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.22579 acc: 0.90667 val_loss: 0.20856, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.22572 acc: 0.90667 val_loss: 0.20848, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.22564 acc: 0.90667 val_loss: 0.20839, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.22556 acc: 0.90667 val_loss: 0.20831, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.22548 acc: 0.90667 val_loss: 0.20823, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.22540 acc: 0.90667 val_loss: 0.20814, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.22532 acc: 0.90667 val_loss: 0.20806, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.22525 acc: 0.90667 val_loss: 0.20798, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.22517 acc: 0.90667 val_loss: 0.20789, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.22509 acc: 0.90667 val_loss: 0.20781, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.22501 acc: 0.90667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.22494 acc: 0.90667 val_loss: 0.20765, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.22486 acc: 0.90667 val_loss: 0.20756, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.22478 acc: 0.90667 val_loss: 0.20748, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.22471 acc: 0.90667 val_loss: 0.20740, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.22463 acc: 0.90667 val_loss: 0.20732, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.22455 acc: 0.90667 val_loss: 0.20724, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.22448 acc: 0.90667 val_loss: 0.20716, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.22440 acc: 0.90667 val_loss: 0.20707, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.22432 acc: 0.90667 val_loss: 0.20699, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.22425 acc: 0.90667 val_loss: 0.20691, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.22417 acc: 0.90667 val_loss: 0.20683, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.22410 acc: 0.90667 val_loss: 0.20675, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.22402 acc: 0.90667 val_loss: 0.20667, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.22395 acc: 0.90667 val_loss: 0.20659, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.22387 acc: 0.90667 val_loss: 0.20651, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.22380 acc: 0.90667 val_loss: 0.20643, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.22372 acc: 0.90667 val_loss: 0.20635, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.22365 acc: 0.90667 val_loss: 0.20627, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.22357 acc: 0.90667 val_loss: 0.20619, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.22350 acc: 0.90667 val_loss: 0.20611, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.22342 acc: 0.90667 val_loss: 0.20603, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.22335 acc: 0.90667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.22327 acc: 0.90667 val_loss: 0.20587, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.22320 acc: 0.90667 val_loss: 0.20579, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.22313 acc: 0.90667 val_loss: 0.20571, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.22305 acc: 0.90667 val_loss: 0.20563, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.22298 acc: 0.90667 val_loss: 0.20556, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.22291 acc: 0.90667 val_loss: 0.20548, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.22283 acc: 0.90667 val_loss: 0.20540, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.22276 acc: 0.90667 val_loss: 0.20532, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.22269 acc: 0.90667 val_loss: 0.20524, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.22261 acc: 0.90667 val_loss: 0.20517, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.22254 acc: 0.90667 val_loss: 0.20509, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.22247 acc: 0.90667 val_loss: 0.20501, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.22240 acc: 0.90667 val_loss: 0.20493, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.22232 acc: 0.90667 val_loss: 0.20485, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.22225 acc: 0.90667 val_loss: 0.20478, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.22218 acc: 0.90667 val_loss: 0.20470, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.22211 acc: 0.90667 val_loss: 0.20462, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.22204 acc: 0.90667 val_loss: 0.20455, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.22196 acc: 0.90667 val_loss: 0.20447, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.22189 acc: 0.90667 val_loss: 0.20439, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.22182 acc: 0.90667 val_loss: 0.20432, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.22175 acc: 0.90667 val_loss: 0.20424, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.22168 acc: 0.90667 val_loss: 0.20416, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.22161 acc: 0.90667 val_loss: 0.20409, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.22154 acc: 0.90667 val_loss: 0.20401, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.22147 acc: 0.90667 val_loss: 0.20394, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.22140 acc: 0.90667 val_loss: 0.20386, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.22133 acc: 0.90667 val_loss: 0.20379, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.22126 acc: 0.90667 val_loss: 0.20371, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.22119 acc: 0.90667 val_loss: 0.20364, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.22112 acc: 0.90667 val_loss: 0.20356, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.22105 acc: 0.90667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.22098 acc: 0.90667 val_loss: 0.20341, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.22091 acc: 0.90667 val_loss: 0.20334, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.22084 acc: 0.90667 val_loss: 0.20326, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.22077 acc: 0.90667 val_loss: 0.20319, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.22070 acc: 0.90667 val_loss: 0.20311, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.22063 acc: 0.90667 val_loss: 0.20304, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.22056 acc: 0.90667 val_loss: 0.20296, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.22049 acc: 0.90667 val_loss: 0.20289, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.22042 acc: 0.90667 val_loss: 0.20282, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.22035 acc: 0.90667 val_loss: 0.20274, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.22028 acc: 0.90667 val_loss: 0.20267, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.22022 acc: 0.90667 val_loss: 0.20260, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.22015 acc: 0.90667 val_loss: 0.20252, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.22008 acc: 0.90667 val_loss: 0.20245, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.22001 acc: 0.90667 val_loss: 0.20238, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.21994 acc: 0.90667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.21988 acc: 0.90667 val_loss: 0.20223, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.21981 acc: 0.90667 val_loss: 0.20216, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.21974 acc: 0.90667 val_loss: 0.20209, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.21967 acc: 0.90667 val_loss: 0.20201, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.21961 acc: 0.90667 val_loss: 0.20194, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.21954 acc: 0.90667 val_loss: 0.20187, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.21947 acc: 0.90667 val_loss: 0.20180, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.21940 acc: 0.90667 val_loss: 0.20173, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.21934 acc: 0.90667 val_loss: 0.20165, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.21927 acc: 0.90667 val_loss: 0.20158, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.21920 acc: 0.90667 val_loss: 0.20151, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.21914 acc: 0.90667 val_loss: 0.20144, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.21907 acc: 0.90667 val_loss: 0.20137, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.21901 acc: 0.90667 val_loss: 0.20130, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.21894 acc: 0.90667 val_loss: 0.20123, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.21887 acc: 0.90667 val_loss: 0.20115, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.21881 acc: 0.90667 val_loss: 0.20108, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.21874 acc: 0.90667 val_loss: 0.20101, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.21868 acc: 0.90667 val_loss: 0.20094, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.21861 acc: 0.90667 val_loss: 0.20087, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.21854 acc: 0.90667 val_loss: 0.20080, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.21848 acc: 0.90667 val_loss: 0.20073, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.21841 acc: 0.90667 val_loss: 0.20066, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.21835 acc: 0.90667 val_loss: 0.20059, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.21828 acc: 0.90667 val_loss: 0.20052, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.21822 acc: 0.90667 val_loss: 0.20045, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.21815 acc: 0.90667 val_loss: 0.20038, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.21809 acc: 0.90667 val_loss: 0.20031, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.21803 acc: 0.90667 val_loss: 0.20024, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.21796 acc: 0.90667 val_loss: 0.20017, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.21790 acc: 0.90667 val_loss: 0.20010, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.21783 acc: 0.90667 val_loss: 0.20004, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.21777 acc: 0.90667 val_loss: 0.19997, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.21770 acc: 0.90667 val_loss: 0.19990, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.21764 acc: 0.90667 val_loss: 0.19983, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.21758 acc: 0.90667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.21751 acc: 0.90667 val_loss: 0.19969, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.21745 acc: 0.90667 val_loss: 0.19962, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.21739 acc: 0.90667 val_loss: 0.19956, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.21732 acc: 0.90667 val_loss: 0.19949, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.21726 acc: 0.90667 val_loss: 0.19942, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.21720 acc: 0.90667 val_loss: 0.19935, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.21713 acc: 0.90667 val_loss: 0.19928, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.21707 acc: 0.90667 val_loss: 0.19922, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.21701 acc: 0.90667 val_loss: 0.19915, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.21695 acc: 0.90667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.21688 acc: 0.90667 val_loss: 0.19901, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.21682 acc: 0.90667 val_loss: 0.19895, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.21676 acc: 0.90667 val_loss: 0.19888, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.21670 acc: 0.90667 val_loss: 0.19881, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.21663 acc: 0.90667 val_loss: 0.19874, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.21657 acc: 0.90667 val_loss: 0.19868, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.21651 acc: 0.90667 val_loss: 0.19861, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.21645 acc: 0.90667 val_loss: 0.19854, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.21639 acc: 0.90667 val_loss: 0.19848, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.21633 acc: 0.90667 val_loss: 0.19841, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.21626 acc: 0.90667 val_loss: 0.19835, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.21620 acc: 0.90667 val_loss: 0.19828, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.21614 acc: 0.90667 val_loss: 0.19821, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.21608 acc: 0.90667 val_loss: 0.19815, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.21602 acc: 0.90667 val_loss: 0.19808, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.21596 acc: 0.90667 val_loss: 0.19802, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.21590 acc: 0.90667 val_loss: 0.19795, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 반복 계산 메인 루프\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 훈련 페이즈\n",
    "    \n",
    "    # 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 경사 계산\n",
    "    loss.backward()\n",
    "    \n",
    "    # 파라미터 수정\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    # 예측 페이즈\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs_test = net(inputs_test)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ((epoch) % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기상태 : 손실 : 1.09263  정확도 : 0.26667\n",
      "최종상태 : 손실 : 0.19795  정확도 : 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 손실과 정확도 확인\n",
    "\n",
    "print(f'초기상태 : 손실 : {history[0,3]:.5f}  정확도 : {history[0,4]:.5f}' )\n",
    "print(f'최종상태 : 손실 : {history[-1,3]:.5f}  정확도 : {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAIyCAYAAADoq5ECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAClJUlEQVR4nOzdd3gU1foH8O/sbnoPhBCS0ELvHaTXiIgNFEUU8adXLjYUsaNw5XqDXBBRVK4FBRWpCoIBggQIRUJJBEIPNYRAElJJ3Zk5vz/GXbJkk2ySs5nZzft5nn2YzMzOnvnukn1zzhSBMcZACCGEEKJhOrUbQAghhBBSFSpYCCGEEKJ5VLAQQgghRPOoYCGEEEKI5lHBQgghhBDNo4KFEEIIIZpHBQshhBBCNI8KFkKckCRJEEURNbnMUmlpKXJyclBQUGCHljmOw4cPY86cOUhLS1O7KTYrKirCBx98gO3bt6vdFEK4o4KFEAfw2GOPQRAEq48lS5aUW3/IkCFwcXHB7t27q/1aCxcuREBAACZOnMij6bjrrrvQrl27aj9OnDhh0/ZPnz6Nw4cPIycnp9L1wsLCIAgCLl26VOU2L126hHvuuQfx8fEICQmxqR07d+5E48aN0atXL5vWr0h8fDyWLl2KAwcOVLre0KFDIQgC/vjjD/M8Dw8P3LhxA/fffz8OHjxYq3YQojUGtRtACKna8OHD4e3tbXVZx44dub5WdHQ0AKXQ4OHcuXO4efMml21ZM3nyZBw6dAi///47xowZU+vtSZKEiRMnori4GP/73/9sfl5iYiJu3LiBNm3a1Or1165di4ULF2LWrFno169ftZ8fFRWFjRs3YuLEifjrr7/g4+NTq/YQohVUsBDiAJ577jk899xzdn+dH374AXv37gWAGg0nWZOZmVmt9du1a4czZ87Ay8vLpvVLS0sBgNsX87Jly3DgwAHMnTsXTZs2tek5kiTh22+/BQCMHj26Vq9vyqthw4Y1er6vry+ioqIwefJkzJ8/H3Pnzq1VewjRChoSIkSj3nrrrQqHgSp6JCcn1/j1Vq9ejWeffRYuLi5o3rw53n33XbzyyivIz8/nuFdVMw3tBAYG2rT+5cuXAQCtW7eu9WsXFBRg9uzZ8PLywgsvvGDz8/7zn//g5MmTAIClS5ciJSWlxm0wDeV06tSpxtt47LHHEBYWho8//tihjsEhpDLUw0KIRvXp0wfPPPNMtZ7j5+dX7de5evUq3n33XaxYsQLe3t5Yt24d+vXrh0cffRSLFy/G6tWrMXv2bDzxxBMVDkvxlJOTAxcXF/j6+la57tmzZ5GTk4OAgAA0btzYYpkoitV+7c8++wxpaWmYPn06AgICbHrOl19+idmzZ8PT0xNjx47FmjVr0L9/f6xYsQLDhg2r1usfOXIEp06dAgB88803GDFiRLX3AQBcXFwwffp0vP766/jwww+tHudEiMNhhBCHUFRUxPbu3ct++ukntmLFCrZ161Z28+ZNq+sOGDCAAWA7d+60ujwnJ4dt3LiRTZw4kbm6ujIAbMiQIezMmTPmdWRZZsuWLWONGjViAJiXlxebPHky++6771hycnKN9yMzM5MtWrSIffXVV+WWZWVlMQAsPDzcpm3NmzePAWAA2Lp168zz9+zZY55/5+PixYsVbq9ly5YMADt48KBN+zFlyhQGgHl6erLY2FjGGGOzZs1iAJggCOz5559nKSkpNu2LLMtsyJAh5u0BYIsWLapwfdO627dvt7o8NTWVAWC+vr6soKDApjYQomVUsBCicbIss6ioKObv71/uy9fFxYVNmTKF5eTkWDzHVLCEh4eztm3bsrZt27K33nqLMcZYenq6xbb69evH1q5dy2RZtvr6t27dYp9//jnr0KGD+TmVfZFW5fjx4wwACw4OLrfs8OHDDAC76667qtxOSUkJCwsLMxcHoaGhLDMz0/waI0aMsHi4ublVWrD89ddfDABr0KABkySpwte9dOkSe++991hAQAADwNq3b8+OHj1qsc7WrVtZaGio+T2aNGkS27RpE8vNza1wuzNnzmQAWEREBDtz5gxr3LgxEwSBffLJJ1bXr6pgYYyxzp07MwBs48aNFa5DiKOggoUQjZszZw4DwAICAtjs2bPZH3/8weLi4tgXX3zBWrdube4dKVtwmAqWso+nnnrKvHzDhg1s0aJF7Pjx49Vqy/nz59mKFSsq/UKvSmUFy/r165ler2eTJk2qcjumnoxRo0ax2bNnMwBs4MCBrLi42Or6pgKiooJl0aJFDAB7+OGHrS4XRdFcJABgfn5+7P333zf3XqSmprI9e/aYe6ny8/PZvHnzzD1UANgDDzxQbrvFxcXsH//4h3mbhw8fZowpBVRQUJC5TdevX7d4ni0Fy4wZMxgA9sorr1S4DiGOggoWQjRMkiTm6+vLALA9e/aUW56ZmckCAwMZAHbgwAHz/KqGhNRUWcFiq02bNjG9Xs/c3NxYUlISMxqNbPjw4QwAGzFihNWhsqoKlv/7v/9jANjrr79e4etu2LCBjR49mn3++ecsKyvLYpmp4Lmz2CopKWHbtm1jr7zyCrt27ZrFsj179rCOHTua84iPj7dYfvbsWda9e3fzMNFHH31kXmZLwbJkyRJzJoQ4OjpLiBANKywsRF5eHnQ6Hfr06VNueYMGDcxnx1y/fr3K7TVv3rzaZx5V9pg3bx73fa7Kr7/+igkTJkCSJHz11Vfo2LEjDAYDNmzYgL59+2LHjh3o1asXYmNjq7VdU353Hrxb1gMPPIAtW7bg+eeft/mgXFdXV0RGRmLRokUWF6E7efIkRo0ahRMnTmDMmDE4evRoufe4devWOHDgABYsWIAmTZogMjKyWvtk2hdbPhuEaB2dJUSIhnl7e6Nz5844fvw45s2bh/feew+CIJiXb926FUeOHIHBYLDpCqsRERFwd3fn1r4GDRpYnT906NAqr7J748YNi32pzNSpU7Fo0SLMmTMH//3vfwEAH3/8MSZPnmxex8fHB7t27cI//vEP/PjjjxgxYgSWLFli8+nJpuu52Hr9l9rq0KEDtm7diry8PNx3330Vrufq6orXXnsNr732msX80aNHo3nz5mjSpEmFzzWd1VVSUsKn0YSoiAoWQjRu6dKluPvuuzF79mz8/PPPGDhwIFxcXHD8+HHs3bsXgiBg4cKFCA0NrXJbO3bsqIMWA02bNkXbtm25ba9x48bYuHEjFixYgMDAQHz11VcYN25cufXc3d3xww8/4KGHHsJPP/2Ep59+2ubXMJ0Snp6eXm7ZlClTsHz5cpu289NPP+Gnn36qdJ27774bW7duxZAhQ2xu353eeuutKtcx9azU5HR3QrSGChZCNK5///44duwYFi5ciD/++AM//vgjJElCcHAwJkyYgJdeegkDBw6s9nb/+usv7N27F926dbPp+Zs2bcLly5dx//33V3kF2BUrVlS7PbYICgpC586d0ahRo0rXGzdunNWCpjKtWrUCYH34JCQkhGsBFh4eXm7epUuX0KJFi2pva/v27Rg5cqTVZaZ94XFRPULURgULIQ6gRYsW1br4V1RUFG7evFnp1VL/+OMPvP7665g+fbpNBcvnn3+Obdu2oVWrVjZfsp63ml5IzRa9e/cGAKs3DYyKikJUVJTdXhtQLvZWnaLo6tWrVd5R27Qvpn0jxJFRwUKIA5gzZw5WrVpV7eetWLGixvek4aVXr144cuRItZ+3adMmjB07ttJ1XnnlFQDAggULYDDU7tfZiBEj4OLigoSEBNy8ebPC43MyMjJw9OhRBAUFoWvXrrV6zbJCQ0Nx+vRpm9cfPXo0tm3bVuFyURTNQ4D33HNPrdtHiNqoYCHEAVy/fh1nzpyp9vMKCwurXGfx4sVYvHhxTZplk+bNm+PWrVs2r29Lz4GJqd3z5s2rsmDZsWMHjEZjhcf6+Pv7495778WGDRuwdetWTJo0yep6+/btw0MPPYR7770XmzdvtqmdtkhNTa1WD9LVq1crXb5v3z7k5uaiV69eaN++fW2bR4jqqGAhxAEsXboUS5cutXn9gQMHYt++fTat26lTJ/Ts2bPK9Xbs2FHll6Q169atq9b6VfUc1JQtwy0zZ87Ehg0b8Omnn1ZYsNiL0WisUVFakU8//RSAsk+EOAMqWAip5+69916brqcyduzYGhUsjmTAgAF44IEHsHHjRuzevbtWZ/HUVERERK3uug0AycnJ2LBhA3r16oUJEyZwahkh6qILxxFCSBkfffQRXFxcMHv2bLWbUmNz586FLMuYP3++zde6IUTrqIeFkHru66+/xoYNG6pcT8u9K127drX5i/mxxx7DnDlzKlzetm1bzJs3D6+99hq++eYbPPvss1bX27VrF9q1a2dzG1u2bIno6Ogq17ty5Uq1ttu/f38sW7bM/PMff/yBFStW4IUXXsCwYcNs3g4hWkcFCyFOqFmzZsjMzISnp2eV62ZlZSErK6sOWmU/Z8+etXldWy5TP2PGDBw7dgyvv/467r33XotL6psUFBRwPebEpLrHsoSFhZmni4qK8M9//hPDhg3Dxx9/zL1thKhJYIwxtRtBCCEmf/31FzIzM9GtWzfVT8kmhGgHFSyEEEII0Tw66JYQQgghmkcFCyGEEEI0jw66tYEsy7h27Rp8fHzoFEFCCCGkGhhjyM/PR5MmTaDT1byfhAoWG1y7ds3q3VUJIYQQYpuUlBSLs9qqiwoWG/j4+ABQwvb19VW5NYQQQojjyMvLQ3h4uPm7tKaoYLGBaRjI19eXW8FiNBoRExODyMhIuLi4cNlmfUeZ8kV58keZ8keZ8mXPPGt7SAWd1myDvLw8+Pn5ITc3l1vBYhrTo+Ni+KFM+aI8+aNM+aNM+bJHnry+Q6mHRSWCINDwEmeUKV+UJ3+UKX+UKV9azpNOa1aJ0WjExo0bYTQa1W6K06BM+aI8+aNM+aNM+dJynjQkZAN7DQkVFxfD3d2dujE5oUz5ojz5o0z5o0z5skeevL5DqYdFRQYDjcjxRpnyRXnyR5nyR5nypdU8tdmqekAURURHR2PMmDF0ZDsnlClflCd/lGnNGY1GSJJkdX5cXBwGDx5MmXJgS556vV6VrGlIyAb2GhISRREGg4G6MTmhTPmiPPmjTKsvLy8PmZmZKCkpqXAdxhjlyZEtebq5uaFhw4Y2fSfSWUJOwPSLi/BDmfJFefJHmdouLy8Pqamp8Pb2RsOGDeHi4lLui5QxZv6CpaKl9qrKkzEGo9GI3NxcpKamAkCdnVVE/2tUIooiYmJiqGuYI8qUL8qTP8q0ejIzM+Ht7Y2wsLAKixFZlpGXlwdfX99a3aeGKGzJ08PDAz4+Prh69SoyMzPrrGChISEb2GNIiBBCSMWMRiOSk5MRGhpKv3c1ytQD1qpVq0oLcDpLyMExxpCXlweqF/mhTPmiPPmjTG1nOsC2qp4oxhgkSaJMOalOnqb3xtrB0PZABYtKRFHEnj17IIqi2k1xGpQpX5Qnf5Rp9VV1XIrpUvJUsPBRnTzr+pghGhKyAQ0JEUJI3SouLsbFixfRokULuLu7q90cYoWt7xENCTk4WZaRlZUFWZbVborToEz5ojz5o0z5M50qTn9786HlPKlgUYkkSTh06FCdjf3VB5QpX5Qnf5Qpf4wxFBQUaPILlifGGG7dulXhg9cwo5bzpCEhG9CQECGE1C0aErKUnJyM1q1bV7j8hx9+wBNPPGExr6CgACkpKRU+JyQkBH5+fuafCwsL0aZNG0yYMAEff/xxlW2q6yEhug6LCmQZ+PVXGTk5+Zg0yQfu7tTRxYMsy8jMzETDhg3pegwcUJ78Uab81ZerBzdu3Bg///xzhcvvuuuucvP27NmDe+65p8LnfPfdd5gyZYr5Z1mWkZqaiszMTE1ePZgKFpU8/LAOgB/uvVdE48b0i4sHWZaRlJSEwYMH05cBB5Qnf5SpfRQVFcHHx0ftZnB348YNjBgxotrPW7BgAUaPHo3+/fvj0KFD5Zbv3bsXr776qvnnq1evAlB6WIC6O025uqhgUYFOBwgCwBggCPQW8GIwGDB8+HC1m+E0KE/+KFP+BEFw2qF6f39/LFiwoNrP69atGwDlkvm9evUqt/z69evmaVEUER4ebrHc2i0QtIC+LVUgiiIEYTYYK0Fe3gcIDvZUu0lOQZZlpKWlISQkhP565YDy5I8y5c90bxutfsnWhpubG0aPHg0AiI2NxbJly3D48GFcvXoVRUVFcHV1RXBwMDp37owJEyZg0qRJFp+r0tJSZGVlldtuTk6OedpgMGDPnj3m9UeMGAFZlmlIiCh0Oh1k+T8AgOzs1wBQwcKDLMs4f/48goOD6cuAA8qTP8qUD8aAv0cvwBhw61YJvL1doLHvV3h6gkubVqxYgaeeegpDhgzB7Nmz0apVK3h5eaG0tBRXrlzBhg0bMHnyZBw8eBCfffaZ+Xn79+/HsGHDqtz+wIEDASgH0QI0JETKUH5RuQIoRUkJXfGSF4PBgMGDB6vdDKdBefJHmfJRWAh4e5t+EgBo8/iVW7cAL6/ab2fnzp0AgFmzZmHkyJEWy7p164b+/ftj1apV2LVrl9Xnv/DCC3jsscfKzW/Tpg0kSULHjh0BwHwqs1Z7q6hgUY07gFIUFBSq3RCnIcsyUlJSEB4eTn+9ckB58keZkpqYPn06oqOjMXr0aPTr1w8tW7aEh4cHSktLkZqaiv3790OWZcyaNcvq85s3b27uRbkTY8x8OnRpaSnmzp1rvpeQ1ooWKlhUIggeYCwPt24VqN0Up2E6JS80NJS+DDigPPmjTPnw9FR6L4DbFzrz8vLS3BesJ6fR/m7duuH8+fP49ddfER8fj6tXr+LGjRtwcXFBeHg4oqKiMH78eDRp0qRa201LS8OZM2fQtGlTTJ48Gbdu3cLcuXM1eyVmKlhUIgjuYAw0JMSRwWBA//791W6G06A8+aNM+RCEskMtArxvjw85LW9vbzz55JN48sknq/3cRYsW4ccff4QkSSgtLUVBQQEyMjJQWloKAOjTpw8mT55sXp+GhIgFnc4dsqxciZDwIUmS+aqLer1e7eY4PMqTP8qUP8YYSkpK4Obmpskv2ZoaOnQodu/eXatt7N27F6+99hoA5fRvvV4PNzc3+Pn5ISgoCE2bNkXbtm3RuHFji+fRkBCxIAgeAIDCwmKVW+I8GGPIzs5G8+bN1W6KU6A8+aNM7UOrZ7XUxooVK8wXcrNm8uTJSEhIQFJSUoXrNG/eHAMGDKj2a2v1jj1UsKhEp1Puu1BSUqpyS5yHwWBA79691W6G06A8+aNM+RMEAV48TsXRmKZNm5qn4+Pj4e/vj7Zt25rnef59gEy7du1s2t6aNWuwZs0azJ8/Hy1btqx0Xa3e5oCO+lKJqWCprIIm1SNJEk6fPu2Uf22pgfLkjzLljzGGoqIizfYK8DBgwADz0I5J06ZNbS5WAODkyZNYv3691QvJmXh7e0OWZXz55ZeazJN6WFSi1ytDQqYL9RA+ioqK1G6CU6E8+aNM+dPil6u9rVixwm7b1mqeVLCoxNTDUlxconJLnIder0f37t3VbobToDz5o0z5EwTBPDzizC5duoQlS5bYtO4LL7xQ4ZDOmjVrcODAAZu2oTVUsKhEr1cKlqIiGhLiRZIknDp1Cu3bt6czMDigPPmjTPljjKG4uBju7u6aPO6ClxMnTuCll16yad1//vOfMBisf73/97//tWkbU6dOhYuLi83tqwt0DItKTAULDQkRQgipjCiKYIzZ/LBWrMyZM8em58qyjMLCwgoLHjVpr0X1hOkYltJSGhLiRa/Xo1OnTmo3w2lQnvxRpvwJggAPDw+1m+E0tJwn9bCoRK93A0BDQjxJkoTExEQ6A4MTypM/ypQ/xhgKCws1e6Coo9FynlSwqMRgoB4We9DqXwaOivLkjzLlz5mPXVGDVvOkISGVmAqWkhI6hoUXvV5fresSkMpRnvxRpvxpeQjDEWk5T+phUYnBoAwJFRfTNRl4EUURhw4dgijSDSV5oDz5o0z5M92tWYtDGI5Iy3lSwaISUw+L0Ug9LLwIgoCAgADNdmc6GsqTP8rUPugUcb60micNCanE1dV0DAsVLLzo9Xq0atVK7WY4DcqTP8qUP0EQ4O7urnYznIaW86QeFpUYDK4AgJISGhLiRRRF7N+/n7rbOaE8+aNM+WOM4datW5ocwnBEWs6TChaVuLgol5I2GuksIV50Oh1CQ0Oh09HHmgfKkz/K1D60dkVWR6fVPGlISCW3h4Soh4UXnU6HZs2aqd0Mp0F58keZ8icIAtzc3NRuhtPQcp5U5qvENCREB93yI4oi4uLiqLudE8qTP8qUP8YY8vPzNTmE4Yi0nCf1sKjEzc00JEQFCy86nQ4RERHU3c4J5ckfZWofWu0R4CUnJ8fqfFmWIUkS/Pz84Oqq/BG8evVqREVF4ZtvvkGvXr3M6x4+fBhXr16t9HUkSYIoihg5ciS3tvNEBYtK3NxMpzXTkBAvpuMDCB+UJ3+UKX+CIJi/rJ3RrVu3EBAQUOk6J06cQIcOHQAAGRkZOHr0KG7dumWxzoIFC7B69eoKtyEIAhhjCA0NxYkTJzR56j0VLCoxDQmJIvWw8GLqbh88eLAm7zTqaChP/ihT/kxDGD4+Ppr8kq0td3d3/PzzzxbzDAYD3Nzc8MILLyAnJwetW7eucjvLly/HN998Y/5ZEATo9XoYDAbs378fDz30ECRJwoYNG8zFi9bypP8xKvH0VIaEqGDhR6fToVOnTtTdzgnlyR9lah9avZQ8DwaDAY899li5+RcuXMDVq1fx5JNP2nRWj5ubW7mhs9zcXMyaNQuffPIJ2rRpgw0bNqB169aaPcaKChaVeHndHhLSYiXriHQ6HRo1aqR2M5wG5ckfZcqfIAiaPQ3Xnt577z3odDq8+eab1X7u2bNn8e233+J///sfcnNzAQBNmzbFtWvX0KZNG83mSWW+Sjw9TR8IBqPRqGpbnIXRaMS2bdsoT04oT/4oU/5kWUZubi5kWVa7KXVmyZIlWLlyJd544w20adMGgiCYHy+99FK59S9duoQ1a9Zg5syZ6Nq1K9q2bYvFixfj4Ycfxrlz57B8+XKcOnUKw4YNQ+fOnTFz5kz88ccfKCnR1nXCqIdFJb6+nubp4uJipz5orK7o9Xr07t1bs/fBcDSUJ3+UKR+MMRQWFpqnAaCwsFBzPdWenp5c21RaWor33nsP8+fPx7hx4zB37lzodDp89tln5nXi4uKwdu1ai+fcfffdOHv2LDw9PTFkyBBMmzYNjz76qPlg3latWuHxxx/HunXr8O2332LRokVYvHgxDh8+jK5du3Jrf21RwaISb+/b92ooKiqCr6+viq1xDjqdDoGBgWo3w2lQnvxRpnwUFhbC29tb7WZU6datW/Dy8qr1doxGI9asWYM5c+YgOTkZL774Ij755BNz4fviiy9arF+2YHF1dcXmzZtRVFSEDh06VHiwt+lYmcceewxZWVlITk7WVLECUMGiGldXGYA7gGIUF9OBtzwYjUbExMQgMjJSs2OwjoTy5I8yJdX19ttv47vvvsONGzfQoUMHbNmyBaNHj7bpuWfOnMHOnTvNP+/fv7/K58iyjOLiYri7uyMhIQEdO3bEoEGDatx+nqhgUYmnpw5UsPBlMBgwaNAgOl2UE8qTP8qUD09PT/N1RhhjkGUZOp1Ok0NCtdW1a1f07dsXTz31FB588MEqzzDz9vZGaGgo3Nzc8Oeff2LatGm1ev2pU6dqpmARmBavv6sxeXl58PPzQ25uLrehm1WrgIkTmwBIQ2JiIrp168Zlu4QQ4gyKi4tx8eJFtGjRAu7u7lU/oR64fv26zaccBwUF2f0KwLa+R7y+Q+ksIZW4uIhQelhAPSycGI1GbNy4kc7A4ITy5I8y5U+WZeTk5NSLs4R69eqF8PBwmx5//vlnuefn5+fjk08+wahRoxAWFgYPDw8YDAb4+fmhc+fOePbZZ7Fnzx7N5kn9kirx8tKDCha+DAYDIiMjqbudE8qTP8qUP0EQ4Ovrq7nhIHtp2bIlPvroowqXb926Fd9++225+cnJyRgxYgSysrLw3HPPYfr06QgLC4OLiwtyc3Nx4sQJfP/99xg8eDDefPNNREVF2XM3aoT+16hE6T1TLh5XVET3E+KFvgj4ojz5o0xJbQQEBODhhx+ucPn169etzn/33Xdx5coV7N69G4MHDy63vH///nj22WcxYsQIfPTRR5g8ebL5/kRaofkhoeXLl8NgMKB58+bVfu7SpUvRpUsXeHh4ICQkBFOnTsXNmzf5N7IGXFwkUA8LX6IoIjo6WrOXlXY0lCd/lCl/jDHk5eWBDsesnOm7r2HDhhWuIwiC+bT7zMzMOmlXdWi21M/JycGcOXPw6aef1ugiSzNnzsTChQsxceJEzJo1CxcuXEBUVBR2796NAwcOwN/fn3+jq4GGhPgzGAwYM2YM/QXLCeXJH2XKX30bEsrIyMDSpUsrXL53716r81966SXExsbivvvuw9tvv41hw4ZZDAklJSXhhx9+wPr169GrVy/079/fXrtQY5r9XzNjxgxs3rwZK1aswDfffINLly7Z/NyEhAQsXLgQkyZNwo8//mie37NnT0RGRmLu3LlYuHChHVptOxoSsg9RFOnLgCPKkz/KlNTGlStXanSq8gMPPIAtW7Zgzpw5eO6556z2SPn7++Pll1/Gv/71L01ejVmzQ0Ivv/wyrly5gieeeKLazzXdQvudd96xmD9q1Cj06tULy5YtU71Lls4S4k8URcTExKj+3joLypM/ypS/+jQkdPXqVTDGbHoMHTq03PPvvvtu/Pnnn7hx4wZ27dqFtWvXYuXKlfjtt99w7NgxZGZmYtGiRQCgyTw1W+bX5roksbGxCAkJsXrA0MiRI3H48GEkJCSgT58+tWhh7fj4uMBUsBQVUcHCg4uLCx544AG1m+E0KE/+KFP+dDqd6kP8jiYoKAhDhgypcLlW89RsD0tNiaKI8+fPo23btlaXm+afPn26wm2UlJQgLy/P4gEAkiSZ/7U2LYqixbTpPHZr025uDKYhoVu3imA0Gs0VrWmaMVZuGoDFtCzLFtOmv9wqmpYkyWKa5z6Z2l52ui73iTGGnJycKvfPkfZJzfeptLTUfBdcZ9kntd8no9GInJwcMMacZp/s+T6Z2mbap4qmTf//TQ/T/LqalmW50mlTe8tOV7VPauyHaVqSJJv3yfS8qj57PDhdwWL6wmrUqJHV5ab5lR0BHRUVBT8/P/MjPDwcAJCUlAQAOHXqFE6dOgUAOHbsGM6dOwcASExMxMWLFwEABw8eREpKCgDl/g1paWkAlDtpZmZmwmC4PSR061YxYmJikJ+fDwCIjo5GcXGxxRkFxcXFiI6OBqBc/CcmJsa8v7GxseZ9iouLAwCkpaWZ7xuRkpKCgwcPAgAuXryIxMREAMC5c+dw7NgxbvsEKL1bOTk5AFDn+ySKIuLi4nD06FGn2Sc136ctW7Zgz549uHXrltPsk9rvU0JCAvbs2QNRFJ1mn+z5PjHGzJfgl2XZ4o9H0/OMRiNu3bpl/qI0rV9aWoqCggIAyh+hprs7FxcXm48bLC6+fWuUoqIi83RhYSFKSkoAAAUFBSgtLQWg3MzQ9AWcn59vLuzy8/PNRVteXp75i9w0VFV22Mo0Xdk+iaJYbv/qap+MRiPy8/Nt2idT7iUlJVV+9rhgDmDIkCGsWbNmNq175coVBoA9+eSTVpfv2LGDAWBz586tcBvFxcUsNzfX/EhJSWEAWFZWFmOMMVEUmSiK5aaNRqPFtCRJFU7LMmPAawwAmzZtJistLWWyLDPGmHlaluVy04wxi2lJkiymjUZjpdOiKFpMW9uPmu6Tqe1lp2mfaJ9on2ifarJPhYWF7OTJk6ygoMC8T6bn3Tlt2oZa08rv9IqnTe0tO+0M+1RQUMBOnjzJCgsLK/3s5ebmMgAsNzeX1YZmj2GpKdO9Eyo6qM1USVZ2jwU3Nzery01HTZc9errsdNkj/6ualmUZBoMHRFEZEip759aqpgVBME/rdDrzzbBsma6o7Tz2yZa223OfZFlGbm6uefzVGfbJ1ml77JNer0d2djb8/f2dZp/Ufp90Oh1ycnLg7+/vNPtkr/fJ9Ne9qV2CIJhPXS47DSi9E3q93mJeXU6XvSFhRdPWnlvRPqm1H4IgmIfYyuZZ1f6V/bxZ++zxOhPW6YaETOfj5+bmWl1u6or08/Orw1aVJ0kSdDpXAEBhIR10y4MkSTh06JD5Fx2pHcqTP8qUP8YYCgoKNHlWiyPScp5O18Pi7u6OsLAwXLhwwepy0/zWrVvXZbPKcXFxgbu7F0pLqWDhxcXFBXfffbfazXAalCd/lGn1VfXFqdPpVP8D1JlUJ8+6LmqcrocFAAYOHIgzZ84gPT293LKdO3fCzc0NvXv3VqFltylDQsqwE104jg9ZlpGenq7Ju4w6IsqTP8rUdqZhp6rOMmF3nFVEaqc6eZrem7q6yJxDFyyXLl3CkCFD8Oqrr1rMnzJlChhj5a5me/jwYezYsQPjx4+Ht7d3XTa1HFmWIQhK/HQdFj5kWUZSUhJ9GXBCefJHmdrOxcUFbm5uyM3NrfLLk/7o48uWPBljyM3NhZubm8XxR/bk0ENCa9euRVxcHOLi4vDuu++ab+oUGRmJRx99FPPnz0d2djYiIyNx+fJlREVFITg4GPPmzVO55cpBaD4+/rh5k650y4vBYMDw4cPVbobToDz5o0yrp2HDhkhNTcXVq1fh5+cHFxcXq/cMcnV1NZ+yS2qvsjxNPTC5ubm4desWQkND66xdDl2wjBgxAkFBQejWrRsaNGhgsezHH39Et27d8P3332P58uXw9/fHvffeiw8//BBhYWEqtfg2ZUhIib+4mP464EGWZaSlpSEkJMTiSHZSM5Qnf5Rp9fj6+gJQrh+TmppqdR3294XO7jxLiNSMrXm6ubkhNDTU/B7VBYcoWHbt2mV1fo8ePawepwIof8m89dZbeOutt+zYspor2yVcUkI9LDzIsozz588jODiYvgw4oDz5o0yrz9fXF76+vjAajVbPrhJFEYmJiejevTvdVJIDW/LU6/V1NgxUlsDoSKUq5eXlwc/PD7m5uVyrybvu2oUDB4YhJKQ9rl07yW27hBBCiFbw+g6lEl8lykG3ynRpKQ0J8SDLMi5fvkwHNHJCefJHmfJHmfKl5TypYFGJ8mFQOrdKS2lIiAdZlpGamqrJ/2iOiPLkjzLljzLlS8t50pCQDew1JPTww2ewfn07uLv7o6gom9t2CSGEEK2gISEHJ0kSGFPulmk00pAQD5IkITk5mS57zgnlyR9lyh9lypeW86SCRSWMMZhOEpCkErpKIweMMWRnZ1OWnFCe/FGm/FGmfGk5TxoSsoG9hoTeeCMP//2vcs+GoqIiuLu7c9s2IYQQogU0JOTgJElCUdEt8890aenakyQJp0+f1mRXpiOiPPmjTPmjTPnScp5UsKjIYJBhegvo8vx8UOHHF+XJH2XKH2XKl1bzpMsCqkSv16NVqzAA7gAKqWDhQK/Xo3v37mo3w2lQnvxRpvxRpnxpOU/qYVGJJEnIyroKwAOAditaRyJJEpKSkjTZlemIKE/+KFP+KFO+tJwnFSwqcnVlUHpYaEiIEEIIqQwNCalEr9ejdetwUMHCj16vR6dOndRuhtOgPPmjTPmjTPnScp7Uw6ISSZJw7VoyaEiIH0mSkJiYqMmuTEdEefJHmfJHmfKl5TypYFGRn58LqIeFLw8PD7Wb4FQoT/4oU/4oU760micNCalEr9ejfftmoIKFH71ej3bt2qndDKdBefJHmfJHmfKl5Typh0Uloiji/PnjoCEhfkRRxKFDhyCKotpNcQqUJ3+UKX+UKV9azpMKFpUIgoDgYB9QDws/giAgICAAgiCo3RSnQHnyR5nyR5nypeU8aUhIJXq9Hh06NIepYCkqooKltpSL8bVSuxlOg/LkjzLljzLlS8t5Ug+LSkRRxPHjB2AaEsrLoyGh2hJFEfv379dkV6Yjojz5o0z5o0z50nKeVLCoRKfToWXLEJh6WPLzqYeltnQ6HUJDQ6HT0ceaB8qTP8qUP8qULy3nSUNCKtHpdGjRohn0endIEnDrFhUstaXT6dCsWTO1m+E0KE/+KFP+KFO+tJyn9kqoekIURcTFxcHFRelhuXWLhoRqy5SpFrsyHRHlyR9lyh9lypeW86SCRSU6nQ4RERHmgqWggHpYasuUqRa7Mh0R5ckfZcofZcqXlvOkISGVmMYJ3dw8kJ9PBQsPpkwJH5Qnf5Qpf5QpX1rOU3slVD0hiiJiY2Ph5qb0sBQW0pBQbZky1WJXpiOiPPmjTPmjTPnScp5UsKhEp9OhU6dOcHen67DwYspUi12Zjojy5I8y5Y8y5UvLedKQkEp0Oh0aNWoEd3flOix0pdvaM2VK+KA8+aNM+aNM+dJyntoroeoJo9GIbdu2wd3dDQBQXExDQrVlytRoNKrdFKdAefJHmfJHmfKl5TypYFGJXq9H79694emp9LCUlFAPS22ZMtXr9Wo3xSlQnvxRpvxRpnxpOU8aElKJTqdDYGAgvLyoYOHFlCnhg/LkjzLljzLlS8t5Ug+LSoxGI37//Xd4eroCAEpLaUiotkyZarEr0xFRnvxRpvxRpnxpOU8qWFRiMBgwaNAgeHt7AgCMRuphqS1TpgYDdRzyQHnyR5nyR5nypeU8tdeiekIQBPj6+sLHRxkSEkUqWGrLlCnhg/LkjzLljzLlS8t5Ug+LSoxGIzZu3GgeEhJFGhKqLVOmWuzKdESUJ3+UKX+UKV9azlNgjDG1G6F1eXl58PPzQ25uLrfKkzGG4uJifPxxJmbNagpBcIEsl3LZdn1lytTd3R2CIKjdHIdHefJHmfJHmfJljzx5fYdSD4uKDAYD/PyUK90yZoQkSSq3yPFpcdzVkVGe/FGm/FGmfGk1TypYVCKKIqKjo+Ht7WqeR1e7rR1Tplq8B4Yjojz5o0z5o0z50nKeNCRkA3sNCYmiiK1bdbj/fqWavXHjhmYviewITJkaDAbqGuaA8uSPMuWPMuXLHnnSkJATEEUR3t46AMqpzQUFBeo2yAlo8a8CR0Z58keZ8keZ8qXVPKlgUYkoioiJiYGbmwTACwBw69YtdRvl4EyZavU/m6OhPPmjTPmjTPnScp40JGQDewwJmZw4AXTq1ALAJfz555/o168f1+0TQgghaqIhIQfHGENeXh48PBgAbwA0JFRbpkypBueD8uSPMuWPMuVLy3lSwaISURSxZ88euLqKMA0J5efTkFBtmDLVYlemI6I8+aNM+aNM+dJynjQkZAN7Dgnl5wO+viMAxGLZsp/w9NOPc90+IYQQoiYaEnJwsiwjKysL7u4yTENCWVk0JFQbpkxlWVa7KU6B8uSPMuWPMuVLy3lSwaISSZJw6NAhABL0emVIKDubhoRqw5QpXTGYD8qTP8qUP8qULy3nSUNCNrDnkBAAeHo+h6Kir/HCC3OxZMks7tsnhBBC1EJDQg5OlmWkp6dDlmW4uio9LLm5NCRUG2UzJbVHefJHmfJHmfKl5TypYFGJLMtISkqCLMtwdzcVLDQkVBtlMyW1R3nyR5nyR5nypeU8aUjIBvYeEmrefB4uX34bw4Y9jdjYZdy3TwghhKiFhoQcnCzLSE1NhSzL8PSk67DwUDZTUnuUJ3+UKX+UKV9azpMKFpXIsozz589DlmV4eSkFS2EhHcNSG2UzJbVHefJHmfJHmfKl5TxpSMgG9h4SGjZsDXbtehQtWgzBhQu7uG+fEEIIUQsNCTk4WZZx+fJlyLIMHx+lh6WoiIaEaqNspqT2KE/+KFP+KFO+tJwnFSwqKTtO6OenFCwlJTQkVBtaHnt1RJQnf5Qpf5QpX1rOk4aEbGDvIaEXXzyMzz/vDS+vcNy6dYX79gkhhBC10JCQg5MkCcnJyZAkCQEBSg9LaSkNCdVG2UxJ7VGe/FGm/FGmfGk5TypYVMIYQ3Z2Nhhj5oJFFGlIqDbKZkpqj/LkjzLljzLlS8t50pCQDew9JLR8eRamTGkAACgtLYWLiwv31yCEEELUQENCDk6SJJw+fRqSJKFBAy/z/IIC6mWpqbKZktqjPPmjTPmjTPnScp5UsKioqKgIABAY6ApAD4AKltoyZUr4oDz5o0z5o0z50mqeNCRkA3sPCR0/DnTp4g8gF2fOnEGbNm24vwYhhBCiBhoScnCSJCEpKQmSJMHHBwCUYaFbt+hMoZoqmympPcqTP8qUP8qULy3nSQWLBnh7A6aCJS+PhoQIIYSQOxnUbkB9pdfr0alTJwD4u4fFGwCQmUkFS02VzZTUHuXJH2XKH2XKl5bzpB4WlUiShMTEREiSBFdX4HbBkq9quxxZ2UxJ7VGe/FGm/FGmfGk5TypYVOTh4QEAEATAxUU5EIkKltoxZUr4oDz5o0z5o0z50mqeNCSkEr1ej3bt2pl/dnHxhdEIZGXlqdgqx3ZnpqR2KE/+KFP+KFO+tJwn9bCoRBRFHDp0CKIoAgDc3JQeFipYau7OTEntUJ78Uab8UaZ8aTlPKlhUIggCAgICIAgCAMDdXSlYcnKoYKmpOzMltUN58keZ8keZ8qXlPGlISCV6vR6tWrUy/+zpSQVLbd2ZKakdypM/ypQ/ypQvLedJPSwqEUUR+/fvN3e7eXv7AADy86lgqak7MyW1Q3nyR5nyR5nypeU8qWBRiU6nQ2hoKHQ65S3w81N6WKhgqbk7MyW1Q3nyR5nyR5nypeU8aUhIJTqdDs2aNTP/bCpYCgupYKmpOzMltUN58keZ8keZ8qXlPLVXQtUToigiLi7O3O0WEKAULEVFVLDU1J2ZktqhPPmjTPmjTPnScp5UsKhEp9MhIiLC3O3WoIFSsBQX04XjaurOTEntUJ78Uab8UaZ8aTlP7bXoDkuXLkWXLl3g4eGBkJAQTJ06FTdv3rTpuVlZWZg5cyZat24NNzc3+Pr6YtCgQfjpp5/s3Oqq3TlO2KiRUrAYjdTDUlNaHnt1RJQnf5Qpf5QpX1rOU3stKmPmzJmYNm0aOnXqhOXLl2P69OlYtWoVBgwYgJycnEqfm5mZiT59+uDjjz/GgAED8O233yIqKgp5eXl44okn8Morr9TJPlREFEXExsaau91MBYso5oExpmbTHNadmZLaoTz5o0z5o0z50nSeTKOOHDnCALBJkyZZzI+JiWEA2IwZMyp9/quvvsoAsI8//thifmlpKevVqxcDwJKSkmxqS25uLgPAcnNzq7cTlZAkid24cYNJksQYY+z33/MYAAaAFRYWcnud+uTOTEntUJ78Uab8UaZ82SNPXt+hmu1h+eabbwAA77zzjsX8UaNGoVevXli2bFmlFeCOHTvg6uqKF154wWK+i4sLnn/+eQDAH3/8wbnVttPpdGjUqJG52y042AuAcmXBvDwaFqqJOzMltUN58keZ8keZ8qXlPLXXor/FxsYiJCQEHTp0KLds5MiRyMnJQUJCQoXP1+l08PX1haura7llQUFBXNtaE0ajEdu2bYPRaAQABAbqACgXj6OCpWbuzJTUDuXJH2XKH2XKl5bz1GTBIooizp8/j7Zt21pdbpp/+vTpCrcxbNgwZGZmYvv27eWW/fjjjxAEAUOHDrX63JKSEuTl5Vk8AECSJPO/1qZFUbSYlmW5wmm9Xo/u3bub79fg6WkEoBzHkp6eBcYYGGMwGo0W0wAspmVZtpg29TpVNC1JksU0z30ClA972Wn29/E4d+6HPfZJr9ejZ8+e5vfRGfZJzfdJlmX06tULOp3OafZJ7feJMYaePXtCr9c7zT6p/T4JgoAePXpAr9c7zT6p+T4JgoDevXubfwfw2iceNFmw5OTkQBRFNGrUyOpy0/zMzMwKt/Hee++hZ8+emDhxIpYtW4bU1FScOHECU6dOxerVqzFnzhx07drV6nOjoqLg5+dnfoSHhwMAkpKSAACnTp3CqVOnAADHjh3DuXPnAACJiYm4ePEiAODgwYNISUkBAOzfvx9paWkAgLi4OGRmZkKn0yExMdFcDMXHb4epYNm8eSeKi4shiiKio6MhiiKKi4sRHR0NAMjPz0dMTIw5q9jYWHMecXFxAIC0tDTs378fAJCSkoKDBw8CAC5evIjExEQAwLlz53Ds2DFu+wQoPWOmA6JjYmKQn6+cph0dHW33fdLpdMjMzOT6Pqm9T2q+T1u3boWvry9KS0udZp/Ufp+OHj2KnJwc6HQ6p9kntd+nrKwsHD9+HDqdzmn2Sc33KSsrC4GBgdi5cyfXfeKiVkfA2MmVK1cYAPbkk09aXb5jxw4GgM2dO7fS7RQVFbGnn37afDArAObp6cnWr19f6fOKi4tZbm6u+ZGSksIAsKysLMYYY6IoMlEUy00bjUaLadNBS9amS0tL2aZNm1hxcTFjTDkYWKfrxwCwzz5bx2RZZrIss9LSUotpxpjFtGlbpmmj0VjptCiKFtPW9qOm+2Taj7LTsixbTNtzn0yZFhUVOc0+qfk+FRQUsE2bNrGSkhKn2Se136eioiK2adMmVlpa6jT7pPb7VFxcbM7UWfZJzfepuLiYbd68mRUWFnLbJ14H3Wry0vxubm4AUOFBtaYuJtN61mRlZeGRRx5BfHw83n33XfTv3x+5ubn46aef8PjjjyMqKgqvvvpqha9vbdt6vd7i3zunDQaDzdOCIGDw4MHmY2xcXFzg4uKLkhIgK6vQPFTk4uJifq5pWhAE87ROpzMfHGXLdEVt57FPFbXXlmke+8QYw+DBg83vnTPsk63T9tgnDw8PDB48GC4uLubPo6Pvk9rvk5ubGwYPHgyDwWDO1NH3Se33ydXV1SJTZ9gnNd8nvV6PQYMGwd3dvdLvoersU1FREXjQZMHi6+sLQRCQm5trdbmpm8rPz6/CbUybNg179uzB7t27cdddd5nnT5w4ES+99BJmzJiBzp07Y+TIkVzbbitBEODr62sxz9VVKVgyM+mg25qwlimpOcqTP8qUP8qULy3nqcljWNzd3REWFoYLFy5YXW6a37p1a6vLS0tLsX79ekRGRloUKybvv/8+AOXgW7UYjUZs3LjR4oAkd3flQ5KdTZfnrwlrmZKaozz5o0z5o0z50nKemixYAGDgwIE4c+YM0tPTyy3buXMn3Nzc0Lt3b6vPzcrKgiRJFl1dZZm6q27cuMGvwdVkMBgQGRlp0UYvL1PBQj0sNWEtU1JzlCd/lCl/lClfWs5TswXLlClTwBjDwoULLeYfPnwYO3bswPjx4+Ht7Y2cnByMGTMGkyZNMh/zEhwcjPDwcGzbts18FHVZUVFRAGBxCqwa7vxAmAqWnBzrQ2Gkalr8T+bIKE/+KFP+KFO+tJqnZguWyMhIPProo5g/fz6ee+45rFu3DgsXLsTo0aMRHByMefPmAQC2b9+OLVu2YOXKlfjrr78AKGNwn376KYxGI4YMGYI333wTq1evxjfffIOxY8di/vz5aNWqFWbMmKHa/pU9JczE19cfAJCbm61SqxybtUxJzVGe/FGm/FGmfGk5T4Ex7d5pTxRFLFiwAN9//z0uXrwIf39/jB49Gh9++CHCwsIAKOelDxo0CP7+/ti3bx+8vLzMzz98+DAWLlyIPXv2ID09HS4uLoiIiMADDzyAmTNnVnrQbll5eXnw8/NDbm4ut4ORGGMQRdHibIExY77Hli1Po1mz0bh0aQuX16lPrGVKao7y5I8y5Y8y5cseefL6DtV0waIV9ipYiouLLU4dmzx5I3744UE0bNgXGRkHuLxOfWItU1JzlCd/lCl/lClf9siT13eoZoeEnJ0oioiJibHodgsODgAAFBXRkFBNWMuU1BzlyR9lyh9lypeW86QeFhvYo4fFmo8/Po7XXusCF5cglJaWPzuKEEIIcTTUw+LgGGPIy8tD2XoxPFzpYTEas0F1ZPVZy5TUHOXJH2XKH2XKl5bzpIJFJaIoYs+ePRbdbqaCBRBRUFCgTsMcmLVMSc1RnvxRpvxRpnxpOU8aErJBXQ0JXb3KEB7uBsCIy5evoGnTcLu9FiGEEFIXaEjIwcmyjKysLMiybJ7XoIEAQOlluXqVDrytLmuZkpqjPPmjTPmjTPnScp5UsKhEkiQcOnQIkiSZ53l4AIKgFCxXrlDBUl3WMiU1R3nyR5nyR5nypeU8aUjIBnU1JAQArq79YDTGY8GCX/Haaw/a9bUIIYQQe6MhIQcnyzLS09PLdbu5uSk9LNeuUQ9LdVWUKakZypM/ypQ/ypQvLedJBYtKZFlGUlJSuQ+Fp6dSsKSnU8FSXRVlSmqG8uSPMuWPMuVLy3nSkJAN6nJIKCLiBVy48AVGj56FLVvm2vW1CCGEEHujISEHJ8syUlNTy1Wxvr5KD0tWFvWwVFdFmZKaoTz5o0z5o0z50nKeVLCoRJZlnD9/vtyHIiBAKVhyc6lgqa6KMiU1Q3nyR5nyR5nypeU8aUjIBnU5JDRhwjKsXfsMmjS5B6mp0XZ9LUIIIcTeaEjIwcmyjMuXL5erYoOClB6WwkLqYamuijIlNUN58keZ8keZ8qXlPKlgUUlF44QhIUrBUlxMBUt1aXns1RFRnvxRpvxRpnxpOU8aErJBXQ4Jff99Ep5+ujN0ugaQpEy7vhYhhBBibzQk5OAkSUJycnK5yx+3ahUEAJDlLE1eGlnLKsqU1AzlyR9lyh9lypeW86SCRSWMMWRnZ+PODq7WrQNNayAtLavuG+bAKsqU1AzlyR9lyh9lypeW86QhIRvU5ZCQLAN6fSCAbMTGnsSwYe3t+nqEEEKIPdGQkIOTJAmnT58u1+2m0wF6fUMAwIULdAxLdVSUKakZypM/ypQ/ypQvLedJBYuKioqKrM53c1MKlkuXMuqyOU6hokxJzVCe/FGm/FGmfGk1T4PaDaiv9Ho9unfvbnWZl1cQCguBq1eph6U6KsuUVB/lyR9lyh9lypeW86QeFpVIkoSkpCSr3W6+vkoPy/Xr1MNSHZVlSqqP8uSPMuWPMuVLy3lSwaJBgYHKqc0ZGdTDQgghhAA0JKQavV6PTp06WV0WFKT0sGRnUw9LdVSWKak+ypM/ypQ/ypQvLedJPSwqkSQJiYmJVrvdQkKUHpa8POphqY7KMiXVR3nyR5nyR5nypeU8qWBRkYeHh9X5YWFKD0thIRUs1VVRpqRmKE/+KFP+KFO+tJonDQmpRK/Xo127dlaXNW+u9LCUlNCQUHVUlimpPsqTP8qUP8qULy3nST0sKhFFEYcOHYIoiuWWRUQoPSySlAm6DrHtKsuUVB/lyR9lyh9lypeW86SCRSWCICAgIACCIJRb1qZN0N9Thbh+vbBuG+bAKsuUVB/lyR9lyh9lypeW86R7CdmgLu8lBCg3n9Lp3AGUYseOSxg+vJndX5MQQgixB7qXkIMTRRH79++32u0mCAIMhsYAgDNnbtR10xxWZZmS6qM8+aNM+aNM+dJynlSwqESn0yE0NBQ6nfW3wMNDKViSk6/XZbMcWlWZkuqhPPmjTPmjTPnScp50lpBKdDodmjWreKjHz68x8vOBS5fS6rBVjq2qTEn1UJ78Uab8UaZ8aTlP7ZVQ9YQoioiLi6uw2y0wUOlhuXaNelhsVVWmpHooT/4oU/4oU760nCcVLCrR6XSIiIiosNutcWOlYMnIoILFVlVlSqqH8uSPMuWPMuVLy3nSkJBKTOOEFWnaNAQAkJNDBYutqsqUVA/lyR9lyh9lypeW89ReCVVPiKKI2NjYCrvdWrRQelhu3aKCxVZVZUqqh/LkjzLljzLlS8t5UsGiEp1Oh06dOlXY7da2rVKwlJZep6vd2qiqTEn1UJ78Uab8UaZ8aTlPGhJSiU6nQ6NGjSpc3rGjUrAwloacHIaAAO1ddVBrqsqUVA/lyR9lyh9lypeW89ReCVVPGI1GbNu2DUaj0ery5s0b/z1VgjNncuuuYQ6sqkxJ9VCe/FGm/FGmfGk5TypYVKLX69G7d2/o9Xqry93d3aHT+QMATp6k41hsUVWmpHooT/4oU/4oU760nCcVLCrR6XQIDAysdJzQdLXbs2epYLGFLZkS21Ge/FGm/FGmfGk5T+21qJ4wGo34/fffK+128/FRCpYLF+hqt7awJVNiO8qTP8qUP8qULy3nSQWLSgwGAwYNGgSDoeLjnoOCmgAALl++VlfNcmi2ZEpsR3nyR5nyR5nypeU8qWBRiSAI8PX1hSBUfPZPWFgYAOD69ZS6apZDsyVTYjvKkz/KlD/KlC8t50kFi0qMRiM2btxYabdbRIRSsGRlXa2rZjk0WzIltqM8+aNM+aNM+dJyngJjVV+W7Msvv8TFixcr3ogg4MMPP8Q777xjMf/pp59GfHw8ZsyYgaysrNq3ViV5eXnw8/NDbm4ufH19uWyTMYbi4mK4u7tXWMkuXboB06Y9BEHoC0k6AA0WvJpiS6bEdpQnf5Qpf5QpX/bIk9d3qE2DVCtXrsS+ffsqXC4IAt5//30sWLDAYt7AgQNRUlKC3Fy6jog1VY0Rdumi9LAwloLMTCAoqC5a5di0OO7qyChP/ihT/ihTvrSap01DQuvWrcPFixcrfFy4cMG87meffYajR4/Cho6bek0URURHR1d6v4aWLcP+nkrDhQva657TGlsyJbajPPmjTPmjTPnScp42lVHBwcFVrlNQUAAACAgIQJMmTWrXqnrAYDBgzJgxlVayjRo1giC4gDEjjh5NQ9++TeuwhY7HlkyJ7ShP/ihT/ihTvrScZ60OupVlGc8//7y5WCHVU1UFq9Pp4OGh3Ob7xAk68NYWWvyrwJFRnvxRpvxRpnxpNc9aFSzfffcd/ve//2H37t282lNviKKImJiYKj8YAQHKsFByMp3aXBVbMyW2oTz5o0z5o0z50nKeNe7zSU5OxmuvvYYBAwZgzJgx1MtSTS4uLnjggQeqXK9x43CkpgKXL1MPS1VszZTYhvLkjzLljzLlS8t51qiH5fLlyxg9ejRcXV3x448/8m5TvcAYQ15eXpUHJzdvbrp4HBUsVbE1U2IbypM/ypQ/ypQvLedpU8GSkJCAZcuW4Y8//sC6devQt29f5OfnIyYmBk2b0oGgNSGKIvbs2VNlt1v79uEAgJycK9Dg50dTbM2U2Iby5I8y5Y8y5UvLedo0JLRlyxa899575ovI6HQ67Nq1C926dav0eaIoanKntcDFxQX33ntvlet1794cACBJF3H9OhASYueGOTBbMyW2oTz5o0z5o0z50nKeNvWwPProo/j111+xYMECDB8+HLIsY+zYsdi8eXOlz3vkkUfw8ssvc2mos5FlGVlZWZBludL12rRp8ffUJSQn279djszWTIltKE/+KFP+KFO+tJynTQVLq1at8MADD+DVV1/F9u3bsXfvXvj5+WH8+PHYtm0bAKUqe+qppxAREQF3d3c89dRTmDx5svlBLEmShEOHDkGSpErXa968+d9T2Th2jK4YXBlbMyW2oTz5o0z5o0z50nKeNt1LyJpr166hf//+KCgowF9//YXQ0FDebdMMe9xLqDo8PIJQXJyJZ55JxDffdKvz1yeEEEJqitd3aI2vw9KkSRP88ssvyMvLw2uvvVbjBtRXsiwjPT3dpm63oCBlWOj06YpvQEmqlympGuXJH2XKH2XKl5bzrNWF43r06IFXX30V/v7+OHjwIDIzM3m1y+nJsoykpCSbPhRNmyoFy+XLVLBUpjqZkqpRnvxRpvxRpnxpOc8aDwmZFBcXw9XVFS4uLvjyyy/x3HPP8WqbZqg9JPTss2/h228/gqvriygu/gx0B3VCCCGOQvUhod27d2Pbtm1wd3eHTqfT5EVmtEyWZaSmptpUxXbtqvSwlJZeQlaWvVvmuKqTKaka5ckfZcofZcqXlvOsccGyfv16jB8/vsrrrKxZswY9evSo6cs4LVmWcf78eZs+FG3bmk5tvkinNleiOpmSqlGe/FGm/FGmfGk5zxoVLKIo4tdff8Xw4cOrvAV1RkYGjh49WqPGOTODwYDBgwfbdAvvli1b/j11AadPa+9DpBXVyZRUjfLkjzLljzLlS8t51qhgWbNmDa5du4ZnnnmGd3vqDVmWcfnyZZuq2ObNm0OnMwAowqFDqfZvnIOqTqakapQnf5Qpf5QpX1rOs9oFS15eHt5++2106dJFs3d0dATVGSc0GAxo2DACAJCQcMbeTXNYWh57dUSUJ3+UKX+UKV9azrPaBctzzz2HtLQ0fPPNN/ZoT71hMBjQv39/m7vdIiLaAACSk8/as1kOrbqZkspRnvxRpvxRpnxpOU+bCpb27dvjiSeewIMPPoi1a9diwYIF6NmzJ5YsWYLHH38cjz/+uPnGiMQ2kiQhOTnZ5ssfd+vWFgCQkXEWRUX2bJnjqm6mpHKUJ3+UKX+UKV9aztOmguXy5ctYuXIlNm3ahD59+phvaLhv3z6sWrUKq1atsmsjnRFjDNnZ2TafDt6tW5u/p87gDI0KWVXdTEnlKE/+KFP+KFO+tJynTQVLYWEh/vzzTwwdOhQHDx7E9OnTAQBff/01MjIykJ6ersmd0zKDwYDevXvb3O3Wtq2pYDmLEyfs1y5HVt1MSeUoT/4oU/4oU760nKfNx7D07dsXO3bswHPPPYclS5Zg+fLl8Pb2RoMGDdCwYUN7ttEpSZKE06dP29zt1rZt27+nLuHYsRL7NcyBVTdTUjnKkz/KlD/KlC8t51ntg26/+OILDB8+HC+99BIyMjLs0aZ6o6gaB6MEBwfDzc0HgIxDh87br1EOrjqZkqpRnvxRpvxRpnxpNc8a3UvowoUL6NChA15++WXMnz8fAKDT6bB06VJMnDgRkyZNMq976dIlnDhxQpPVmq3UvpeQSdu2vXH27GGEhPyCa9ceUq0dhBBCiK1UvZdQy5Yt8eijj2L58uXllhmNRkRHR2PLli3YsmULTp06Bb1eX+MGOitJkpCUlFStQq5jR+U4luvX6Uwha2qSKakY5ckfZcofZcqXlvOs8b2EJk2ahPz8fKSkpFjMDwwMhCiKMBqN5kdpaWmNG7h06VJ06dIFHh4eCAkJwdSpU3Hz5s1qbWPLli2IjIxEUFAQPD090bp1a7z66qs1bpNaunRRChbGTuP4cZUbQwghhNShGhcsgwYNwqFDhxAeHs6zPRZmzpyJadOmoVOnTli+fDmmT5+OVatWYcCAAcjJybFpG7NmzcKYMWOg0+nw0Ucf4dtvv8Wjjz6KuLg4u7XbFnq9Hp06dapW71OnTh3/nkpCYqJ92uXIapIpqRjlyR9lyh9lypem82ScDB06lG3atInX5tiRI0cYADZp0iSL+TExMQwAmzFjRpXb+OmnnxgAtnDhwlq1JTc3lwFgubm5tdpOWaIosoSEBCaKos3POXPmDAPAAHf27LO2P6++qEmmpGKUJ3+UKX+UKV/2yJPXd2iNe1jutHPnTowdO5bX5syX/n/nnXcs5o8aNQq9evXCsmXLIIpihc8vLS3FW2+9hXHjxmHGjBnc2sWTh4dHtdaPiIiAq6sHgGIcOEBnCllT3UxJ5ShP/ihT/ihTvrSaJ7eChbfY2FiEhISgQ4cO5ZaNHDkSOTk5SEhIqPD527dvR0pKCt58803zvMoKnLqm1+vRrl27anW76fV6tGmj5HH69HEYjfZqnWOqSaakYpQnf5Qpf5QpX1rOU5MFiyiKOH/+fJmLpVkyzT99+nSF24iJiUGDBg3Qtm1bTJs2DYGBgXBxcUHLli2xYMGCSq/MW1JSgry8PIsHAPNR05IkWZ0WRdFi2nS3S2vToigiPj7efECy0Wg0t8k0zRgrN92rV5e/t3Mcp04pd9Y0/l25mLZb2bQkSRbTPPfJ1Pay07bsEwCL6ZrukyiKOHjwIEpKSpxmn9R8n4qKinDw4EHzwfPOsE9qv08lJSU4ePCg+fPqDPuk9vtUWlqK+Ph4i9+tjr5Par5PpaWlOHToEIqLi7nuEw+aLFhycnIgiiIaNWpkdblpfmZmZoXbOH78OJo2bYpRo0bh6tWrWLFiBX777Te0aNECr7/+Ol555ZUKnxsVFQU/Pz/zw3RgcVJSEgDg1KlTOHXqFADg2LFjOHfuHAAgMTERFy9eBAAcPHjQfAbV/v37kZaWBgCIi4tDZmYmBEFAZmamuRiKiYlBfn4+ACA6OhrFxcUQRRHR0dEQRRHFxcWIjo5Gly6dTXuIxEQlq9jYWHMepoOJ09LSsH//fgBASkoKDh48CAC4ePEiEv8+YvfcuXM4duwYt30ClJ4x0wHRtu4TAOTn5yMmJgZAzfdJEASIoogTf9+7wBn2Sc33KSYmBn5+figpKXGafVL7fTp69ChkWYYgCE6zT2q/Tzdv3kR2djYEQXCafVLzfbp58yYCAgKwe/durvvERa2OgLGTK1euMADsySeftLp8x44dDACbO3duhdvo0KEDEwSBPfjgg0yWZfP80tJS1qdPHwaAnThxwupzi4uLWW5urvmRkpLCALCsrCzGmHJQkumApLLTRqPRYlqSpEqnS0tLLaZN7TRNy7Jcbnr79u1/H3jbir38MmOSJLHS0lLGmDJtNBornRZF0WLa2n7U9T4xxiymaZ9on2ifaJ9on5xnnzR30C1Pbm5uACo+5sTUxWRazxpRFMEYw6xZsyAIgnm+i4sLXnjhBQDAb7/9VuHr+/r6WjwAmMf09Hq91WmDwWAxrdPpKpwWRRGHDh0yd7m5uLiY22maFgSh3HTnzqYelvOIjy+ATqeDi4sLAOVqw6YbVlU0rdfrLaZ57pOp7WWnbdknABbTNd0n8e9hNvZ316Uz7JOa75MgCPjzzz8hSZLT7JPa7xMA8/CFs+yT2u+TLMvmYTZn2Sc13ydZlrF//34IgsB1n3jQZMHi6+sLQRCQm5trdbmpm8rPz6/CbTRo0AAeHh7o3r17uWXt27cHoNw2QC06nQ6hoaHmD4StgoOD0aBBIwAMCQknUYtr8jmdmmZKrKM8+aNM+aNM+dJyntprEQB3d3eEhYXhwoULVpeb5rdu3brCbTRu3Bg6nc5q6KYDXV1dXTm0tmZ0Oh2aNWtWow9F9+7KgbdGYyJdQK6M2mRKyqM8+aNM+aNM+dJyntpr0d8GDhyIM2fOID09vdyynTt3ws3NDb17967w+X379kVBQQHOnj1bbtmRI0cAoMzwSt0TRRFxcXE1OtW6V69ef08dxp9/8m2XI6tNpqQ8ypM/ypQ/ypQvLeep2YJlypQpYIxh4cKFFvMPHz6MHTt2YPz48fD29kZOTg7GjBmDSZMmWQQ8adIkuLi44L333rM4hTkrKwuLFy+Gl5cXxo8fX2f7cyedToeIiIgaVbG3C7VDVLCUUZtMSXmUJ3+UKX+UKV9azlNgZb/NNeaxxx7D6tWr8Y9//AORkZG4fPkyoqKi4Orqivj4eISHh2Pt2rWYMGECAODQoUNleh+ARYsWYcaMGbj77rsxZcoU3Lp1CwsXLsTZs2exYsUKTJo0yaZ28Lo1Ni9XrlxBs2bNABgQGpqHq1e1eVVCQgghhNd3qPZKqDJ+/PFHREVFIS4uDpMmTcL8+fNx77334uDBg+Zro/Tr1w/NmjVD165dzQfTmrz66qtYtWoVsrKy8Oyzz2LGjBkIDw9HbGyszcWKvYiiiNjY2Bp1u4WHh6NhwyAAIlJTjyE1lX/7HFFtMiXlUZ78Uab8UaZ8aTlPTfewaIU9elhkWUZmZiYaNmxYo663e++99+8L9XyGNWtexCOPcGmWQ6ttpsQS5ckfZcofZcqXPfKsFz0szkyn06FRo0Y1/kCUPfB2zx5+7XJktc2UWKI8+aNM+aNM+dJyntprUT1hNBqxbdu2Gt9noeyBtzt38muXI6ttpsQS5ckfZcofZcqXlvOkISEb2GtIKCcnB/7+/jWqZK9fv46QkBAAAoBspKf7ISiIS9McVm0zJZYoT/4oU/4oU77skScNCTk4nU6HwMDAGn8gGjdujJYtWwJgAA5g926uzXNItc2UWKI8+aNM+aNM+dJyntprUT1hNBrx+++/16rbbeDAgX9P7aNhIfDJlNxGefJHmfJHmfKl5TypYFGJwWDAoEGDzDevqokBAwb8PbWXChbwyZTcRnnyR5nyR5nypeU8qWBRiSAI5ps81tTtHpYDOHXKiLQ0Pm1zVDwyJbdRnvxRpvxRpnxpOU8qWFRiNBqxcePGWnW7tWvXDoGBgQCKACRi2zZuzXNIPDIlt1Ge/FGm/FGmfGk5TzpLyAb2OEuIMYbi4mK4u7vXqpK9//77sWnTJgAfY8KEV7F6NZfmOSRemRIF5ckfZcofZcqXPfKks4ScAI8xwtvDQnHYtg3Q4NWU65QWx10dGeXJH2XKH2XKl1bzpIJFJaIoIjo6utb3axg6dCgAQBB2ITdXqtd3b+aVKVFQnvxRpvxRpnxpOU8aErKBvYaERFGEwWCoVbebJElo0KABcnNzARzE22/3xn/+w6WJDodXpkRBefJHmfJHmfJljzxpSMgJ8Khg9Xo9hg0b9vdPOxAdXetNOjQt/lXgyChP/ihT/ihTvrSaJxUsKhFFETExMVw+GCNHjvx76g8cPQqkptZ6kw6JZ6aE8rQHypQ/ypQvLedJQ0I2sMeQEE+nT59G+/btIQhuYCwbn3/ugeefV7tVhBBCCA0JOTzGGPLy8sCjXmzbti1CQ0PBWAmAfVi3rvbtc0Q8MyWUpz1QpvxRpnxpOU8qWFQiiiL27NnDpdtNEASMGjXq75+2YPduICOj1pt1ODwzJZSnPVCm/FGmfGk5TxoSsoHWh4QAYP369Xj44Yfh5tYGJSVn8NVXwD/+oXarCCGE1Hc0JOTgZFlGVlYWZFnmsr1Ro0bBxcUFJSVnAZytl8NCvDOt7yhP/ihT/ihTvrScJxUsKpEkCYcOHYIkSVy25+vriyFDhvz902bs2AHcvMll0w6Dd6b1HeXJH2XKH2XKl5bzpCEhGzjCkBAAfPrpp5g+fTq8vIaioGAnvv4aePZZtVtFCCGkPqMhIQcnyzLS09O5druNHTsWAFBUtAdADn74gdumHYI9Mq3PKE/+KFP+KFO+tJwnFSwqkWUZSUlJXD8ULVu2RIcOHSDLEoCtiIsDLl7ktnnNs0em9RnlyR9lyh9lypeW86QhIRs4ypAQALz99tuYN28eGjV6GOnpa/HBB8B776ndKkIIIfUVDQk5OFmWkZqayr2KfeSRRwAAOTm/A7iFFSuA+lKS2ivT+ory5I8y5Y8y5UvLeVLBohJZlnH+/HnuH4ru3bujVatWKC0tgpvbZiQnA3/+yfUlNMtemdZXlCd/lCl/lClfWs6ThoRs4EhDQgDw7rvv4j//+Q/Cwx9ESsqv+L//A779Vu1WEUIIqY9oSMjBybKMy5cv26WKffTRRwEAN25sAZCHn38GcnK4v4zm2DPT+ojy5I8y5Y8y5UvLeVLBohJ7jhN27twZ7dq1Q2lpCcLCNqKoCFixgvvLaI6Wx14dEeXJH2XKH2XKl5bzpCEhGzjakBAAzJkzB//617/Qvv3dOHVqK9q3B06cAARB7ZYRQgipT2hIyMFJkoTk5GS7Xf74ySefBACcPh0DD4+rOHUK2LPHLi+lGfbOtL6hPPmjTPmjTPnScp5UsKiEMYbs7GzYq4MrIiICgwYNAmMMnTop40GffmqXl9IMe2da31Ce/FGm/FGmfGk5TxoSsoEjDgkBwHfffYf/+7//Q7NmrXH58hnodALOngUiItRuGSGEkPqChoQcnCRJOH36tF273R555BF4eXnh8uVz6Nt3P2QZ+OQTu72c6uoi0/qE8uSPMuWPMuVLy3lSwaKioqIiu27f29vbfOXbgIBlAIBly4CbN+36sqqyd6b1DeXJH2XKH2XKl1bzpCEhGzjqkBAA7N27F4MGDYKHhwciIq4iKSkQ//438O67areMEEJIfUBDQg5OkiQkJSXZvdttwIAB6Nq1K4qKitCly3cAgM8+A4qL7fqyqqirTOsLypM/ypQ/ypQvLedJBYuTEwQBL774IgDgzz8/R1iYhBs3gK+/VrlhhBBCSDXQkJANHHlICAAKCwsRFhaG7OxsPP/8JnzxxViEhAAXLgDu7mq3jhBCiDOjISEHJ0kSEhMT66TbzdPTE8888wwA4Ny5JQgPB9LSnK+XpS4zrQ8oT/4oU/4oU760nCcVLCry8PCos9eaNm0aBEHA9u3b8MwzpwEAUVGARg8Gr7G6zLQ+oDz5o0z5o0z50mqeVLCoRK/Xo127dtDr9XXyei1btsR9990HALh06b9o2lTpZfnqqzp5+TpR15k6O8qTP8qUP8qULy3nSQWLSkRRxKFDhyCKYp295ltvvQUA+OmnH/D881cBAP/+N5CXV2dNsCs1MnVmlCd/lCl/lClfWs6TChaVCIKAgIAACHV4++S77roLQ4YMgdFoRFrax2jbFsjMBD76qM6aYFdqZOrMKE/+KFP+KFO+tJwnnSVkA0c/S6isbdu2YfTo0fDy8sKXX17G5MkN4O4OnDsHhIWp3TpCCCHOhs4ScnCiKGL//v113u0WGRmJ7t27o6CgAMnJn2HQIOUicu+9V6fNsAu1MnVWlCd/lCl/lClfWs6TChaV6HQ6hIaGQqer27dAEAS8/fbbAIDFiz/Be+9lAwCWLwcSEuq0Kdyplamzojz5o0z5o0z50nKeNCRkA2caEgIAWZbRrVs3HD9+HO+88w4uXvwQP/8M9OsH7NsHaPBzSgghxEHRkJCDE0URcXFxqnS76XQ6/Pvf/wYAfPLJJ3jzzRvw9gYOHAC+/77Om8ONmpk6I8qTP8qUP8qULy3nSQWLSnQ6HSIiIlTrdrvvvvvQp08fFBYW4rvvovCvfynz33wTyMpSpUm1pnamzoby5I8y5Y8y5UvLedKQkA2cbUjIZMeOHRg5ciRcXV1x8uQ5PPhgUyQlAf/8J/Dll2q3jhBCiDOgISEHJ4oiYmNjVe12GzFiBIYPH47S0lK8//7b+PxzZf7//gf8+adqzaoxLWTqTChP/ihT/ihTvrScJxUsKtHpdOjUqZPq3W4LFiyAIAhYuXIlDIb9mDIFYAz4v/9TTnd2JFrJ1FlQnvxRpvxRpnxpOU/ttaie0Ol0aNSokeofiu7du+P//u//AADTp0/HggUyGjcGTp+G+bgWR6GVTJ0F5ckfZcofZcqXlvPUXovqCaPRiG3btsFoNKrdFHz44Yfw8fHB4cOHsXnzD1i6VJn/3/8Chw+r27bq0FKmzoDy5I8y5Y8y5UvLeVLBohK9Xo/evXtr4o6YwcHBmDVrFgDg7bffxvDh+Zg4EZAk4OmngZISlRtoIy1l6gwoT/4oU/4oU760nCcVLCrR6XQIDAzUTLfb9OnTERERgbS0NMyePRuffgoEBQFJScDfF8bVPK1l6ugoT/4oU/4oU760nKf2WlRPGI1G/P7775rpdnNzc8Nnn30GAFi8eDEuXz6CZcuUZYsWAVu3qtg4G2ktU0dHefJHmfJHmfKl5TzpOiw2sMd1WBhjyM/Ph4+Pj6Zu4z1x4kSsWrUK3bt3x8GDB/HqqwYsWQI0agQcOwYEB6vdwoppNVNHRXnyR5nyR5nyZY886TosDk4QBPj6+mruP9gnn3wCf39/JCYmYvHixZg/H+jUCUhPV45n0XJ5q9VMHRXlyR9lyh9lypeW86SCRSVGoxEbN27UXLdbcHAwFixYAAB4//33kZZ2AT//DLi5AVu2KMNDWqXVTB0V5ckfZcofZcqXlvOkISEb2GtIqLi4GO7u7pqrZBljGDZsGHbv3o1BgwZh586d+N//9HjhBUCvB2JjgcGD1W5leVrO1BFRnvxRpvxRpnzZI08aEnICBoNB7SZYJQgCli1bBm9vb+zZsweLFi3CtGnApEnKqc4TJgDXrqndSuu0mqmjojz5o0z5o0z50mqeVLCoRBRFREdHa/J+DQDQsmVLLPp7/Ofdd9/FiRNJ+N//gM6dgRs3gEceAUpLVW7kHbSeqaOhPPmjTPmjTPnScp40JGQDew0JiaIIg8Gg2W5Mxhjuv/9+bN68Gd26dUN8fDyuXHFFr15Abi7w4ovA32dCa4IjZOpIKE/+KFP+KFO+7JEnDQk5AS1WsGUJgoCvv/4aDRo0wF9//YU333wTrVoBP/ygLF+yBPjyS3XbeCetZ+poKE/+KFP+KFO+tJonFSwqEUURMTExmv1gmDRu3BjfffcdAOWU540bN+K++4B//1tZ/tJLwLZtKjawDEfJ1FFQnvxRpvxRpnxpOU8aErKBPYaEHM3MmTOxcOFC8zVamjVrjilTgBUrAF9fYP9+oGNHtVtJCCFEa2hIyMExxpCXlwdHqRejoqLQt29f5OTk4LHHHoPRWIqvvgIGDQLy8oCxY5WLy6nJ0TLVOsqTP8qUP8qULy3nSQWLSkRRxJ49ezTZ7WaNi4sLVq9eDX9/f8THx+P111+Hmxvwyy9ARARw6ZJStNy6pV4bHS1TraM8+aNM+aNM+dJynjQkZAMaErrtt99+wwMPPAAA+O677zBlyhScOQMMGADcvAmMGgVs2qRcGZcQQgihISEHJ8sysrKyIMuy2k2plvvvvx+zZ88GAEydOhXx8fFo2xaIjga8vIDt24Enn1QuMFfXHDVTraI8+aNM+aNM+dJynlSwqESSJBw6dAiSGt/stfT+++/jwQcfRGlpKR566CFcu3YNffoAv/4KuLgAa9cq12ip6747R85UiyhP/ihT/ihTvrScJw0J2YCGhMrLz8/HXXfdhRMnTqBv377YuXMnPDw8sHYt8OijSrHyxhvAvHkAXcuJEELqLxoScnCyLCM9PV2T3W628PHxwcaNGxEYGIj4+HhMmjQJkiThkUduX0xu/nzgnXfqrqfF0TPVGsqTP8qUP8qULy3nSQWLSmRZRlJSkiY/FLaKiIjAhg0b4Obmhl9//RWvvvoqGGOYOhX49FNlnXnzgFmz6qZocYZMtYTy5I8y5Y8y5UvLedKQkA1oSKhya9aswaOPPgoAWLBgAV577TUAwOLFwCuvKOvMmgV88AENDxFCSH1DQ0IOTpZlpKamarKKra4JEyZgwYIFAJQr4q5evRoAMH068PHHyjr//jfw3nv27Wlxpky1gPLkjzLljzLlS8t5ar5gWbp0Kbp06QIPDw+EhIRg6tSpuHnzZo229dtvv0EQBE3c0VOWZZw/f16TH4qamDFjBl566SUAwJNPPoktW7YAAF59FVi4UFnnww+Bl18G7LXLzpap2ihP/ihT/ihTvrScp6aHhEz3r5k4cSIefPBBXLhwAVFRUQgJCcGBAwfg7+9v87aysrLQsWNHiKKIzMzMal12mIaEbCNJEp544gmsWrUK7u7u2LJlC4YOHQoA+OIL4IUXlPWeeAJYtkw5BZoQQohzc/ohoYSEBCxcuBCTJk3CypUrMWHCBLz11ltYt24dzpw5g7lz51Zrey+++CLCwsIwZswYO7W4emRZxuXLlzVZxdaUXq/HihUrcN9996G4uBj33Xcf4uPjAQDPPw/8+COg1yv/jh8PFBfzfX1nzFRNlCd/lCl/lClfWs5TswXLN998AwB45513LOaPGjUKvXr1wrJly2y+18Evv/yCdevW4ZtvvtHEcBCg7XHC2nBxccGaNWswYsQI3Lp1C6NHj8Zff/0FAJg0CdiwAXB3Vy7fP3o0kJ3N77WdNVO1UJ78Uab8UaZ8aTlPzRYssbGxCAkJQYcOHcotGzlyJHJycpCQkFDldjIzMzFt2jS8+eab6Nq1qz2aWiMGgwH9+/eHwWBQuyncubu7Y+PGjejfvz9ycnIwYsQI83s1diywdSvg4wPs3g307w9cvMjndZ05UzVQnvxRpvxRpnxpOU9NFiyiKOL8+fNo27at1eWm+adPn65yWy+88AIaNmyI9957z+bXLykpQV5ensUDgPlSxZIkWZ0WRdFi2lShWpuWJAlnzpyB0WgEABiNRvNxNaZpxli5aQAW07IsW0ybep0qmpYkyWKa5z6Z2i7LMry8vLBx40b069cPWVlZGD58OA4cOADGGPr3NyIujiE0lOH0aaBfPyA+vvb7JEkSzp49i9LSUrvskzO+T5XtU3FxMc6dOwdRFJ1mn9R+n0pLS3H27Fnz85xhn9R+n4xGI86cOQNJkpxmn9R8n4xGI5KTk1FSUsJ1n3jQZMGSk5MDURTRqFEjq8tN8zMzMyvdzrp167Bu3Tp8++23cHV1tfn1o6Ki4OfnZ36Eh4cDAJKSkgAAp06dwqlTpwAAx44dw7lz5wAAiYmJuPh3d8HBgweRkpICANi/fz/S0tIAAHFxceaDfs+ePYucnBwAQExMDPLz8wEA0dHRKC4uhiiKiI6OhiiKKC4uRnR0NADlsvgxMTHmrGJjY815xMXFAQDS0tKwf/9+AEBKSgoOHjwIALh48SISExMBAOfOncOxY8e47ROg9IyZ9ik+Ph5r167FwIEDkZubi8jISMTFxSE6OhodO4rYtasYLVrkID0dGDYM+Ne/jtZqnxhjSElJ4fo+3blPzvg+VbRP27ZtQ1ZWFoqKipxmn7TwPqWmpoIx5lT7pPb7lJycDMaYU+2Tmu9TdnY2du3axXWfuGAadOXKFQaAPfnkk1aX79ixgwFgc+fOrXAb6enpLCgoiL366qsW85966ilW1W4XFxez3Nxc8yMlJYUBYFlZWYwxxkRRZKIolps2Go0W05IkVTpdWlpqMS3LssW0LMvlphljFtOSJFlMG43GSqdFUbSYtrYfvPcpPz+fDR06lAFgXl5ebPv27eZ9unmzlN1zD2MAY4Igs//+lzFR1P4+OeP7RPtE+0T7RPtkj33Kzc1lAFhubi6rDU0WLDdu3GAA2MSJE60u37p1KwPA5s+fX+E2xo8fz1q2bMkKCgos5ttSsNyJV9hliaLITp06Zf4AObuCggI2atQoBoC5ubmxX3/91bzMaGTsn/9UihaAsccfZ+yOt80m9S1Te6M8+aNM+aNM+bJHnry+QzU5JOTr6wtBEJCbm2t1uambys/Pz+ryzZs3Y/369ViwYAFKS0uRk5NjfpiObzD9bBoDVENRUZFqr13XPD098dtvv+H+++9HSUkJxo8fj6+//hoAYDAo12lZskSZXrkSGDgQuHy5+q9TnzKtC5Qnf5Qpf5QpX1rNU5MFi7u7O8LCwnDhwgWry03zW7dubXV5cnIyAGDcuHEICAiwePz8888AYP557969dtiDqun1enTv3h16vV6V11eDu7s71q9fj2effRayLOO5557D3LlzwRiDICgXlvvjD6BhQyAxEejVSzmTyFb1MVN7ojz5o0z5o0z50nKemixYAGDgwIE4c+YM0tPTyy3buXMn3Nzc0Lt3b6vPffjhh7Fz506rj7vvvtu8jZ07d6Jbt2723I0KSZKEpKQk81Hb9YXBYMBXX32FWbNmAQDef/99vPjii+aeriFDgCNHgO7dgcxMYMQI4L//te1y/vU1U3uhPPmjTPmjTPnScp6aLVimTJkCxhgWmm5E87fDhw9jx44dGD9+PLy9vZGTk4MxY8Zg0qRJ5i+9sLAwDB061OqjcePGAGD+uTqX9yd8CIKAuXPnYsmSJRAEAV988QXuv/9+8+njTZsCe/cqF5qTJOCNN4D77wdqeAspQgghTkDT9xJ67LHHsHr1avzjH/9AZGQkLl++jKioKLi6uiI+Ph7h4eFYu3YtJkyYAAA4dOgQevXqVek2p0yZguXLl9O9hDTi119/xaRJk1BUVISOHTti06ZNaNGiBQDlENyvv1ZumFhSAoSFAatXKxebI4QQ4hic/l5CAPDjjz8iKioKcXFxmDRpEubPn497770XBw8eNF8bpV+/fmjWrBm6du2K9u3bq9xi20mShMTERE12u9Wlhx56CHv27EGTJk1w4sQJ9OnTB/v27QMACALw3HNAfDzQpg1w9SoweDAwf771ISLKlC/Kkz/KlD/KlC8t56npgsVgMOCtt97C6dOnUVJSghs3bmD58uUICwszrxMeHo5Lly7hr7/+gpeXV5Xb/P7776vVu2JPHh4eajdBE3r27ImDBw+iR48eyMzMxPDhw7F8+XLz8q5dgcOHgYkTlSGiN98EIiOVAuZOlClflCd/lCl/lClfWs1T00NCWkFDQnWjoKAAkydPxi+//AIAmDZtGhYtWgQ3NzcAyhDRN98A06cDRUWAv79yOvTEiSo2mhBCSKXqxZCQMxNFEYcOHVL1OjBa4+XlhbVr12LOnDkQBAFffvklhgwZgqt/d6UIAvCPfwB//QX07g3k5ACPP64ULNnZlClvlCd/lCl/lClfWs6TChaVCIKAgIAACIKgdlM0RafTYfbs2fj9998REBCA+Ph49OjRw+J+FG3aAPv2AXPmAHo9sGoV0Lkz8McflClP9BnljzLljzLlS8t50pCQDWhISB0XLlzA+PHj8ddff0Gn0+Hf//433nzzTeh0t+vsgweBJ54A/r6/F55+Gli4EAgIUKnRhBBCLNCQkIMTRRH79+/XZLebVrRs2RL79+/HU089BVmW8c477yAyMtJ8Z1EA6NNHuSruSy8BgsDw3XdAhw4M69er2HAnQZ9R/ihT/ihTvrScJxUsKtHpdAgNDbXoLSDleXh44LvvvsO3334LT09P7NixA126dDHfyhwAvLyATz8F4uIYIiKMuH5dwMMPA+PHA2VqG1JN9BnljzLljzLlS8t50pCQDWhISBtOnz6Nxx57DEePHgUAvPLKK5g3b575LCIAKC4GPvwQmDcPEEXlTKL//Ee5nosGb41BCCFOj4aEHJwoioiLi9Nkt5tWtWvXDgcOHMD06dMBAJ988gn69OljLmBEUcTBg3GYPVvE4cNAz57KmUTPPw/07asc70JsR59R/ihT/ihTvrScJxUsKtHpdIiIiNBkt5uWubu745NPPsGmTZvQsGFDHDt2DL169cLcuXMhSZI5065dgQMHgM8+A/z8lBsq9uun9LRkZqq9F46BPqP8Uab8UaZ8aTlPGhKyAQ0JadONGzcwbdo0/PrrrwCUK+YuX74cHTt2vGM95eq4povnBgYCUVHAM8/QMBEhhNgbDQk5OFEUERsbq8luN0cRHByM9evX48cff4S/vz+OHDmC7t27Y968eRa5BgcD338P7NkDdOkCZGUBU6cCPXoA27er136to88of5Qpf5QpX1rOkwoWleh0OnTq1EmT3W6ORBAETJo0CSdOnMA999wDo9GIt99+G3379kVCQoLFugMHKkNDixcr12k5dky5J9G99wInT6q0AxpGn1H+KFP+KFO+tJyn9lpUT+h0OjRq1EiTHwpH1KRJE/z+++/49ttv4e/vj4SEBPTu3RszZszArVu3zOsZDMDLLwPJycArrwAuLkB0tNLzMm0akJ6u3j5oDX1G+aNM+aNM+dJyntprUT1hNBqxbds2GI1GtZviNERRRGhoKI4dO4bHHnsMsixj0aJF6NixIzZv3myxbmAgsGiR0rMybpxyF+ilS4FWrYC5c4H8fJV2QkPoM8ofZcofZcqXlvOkg25tYI+DbmVZRk5ODvz9/TVZyTqiOzPdunUrnn/+eVy8eBEAMH78eCxatAjh4eHlnhsXB7z2GnD4sPJzw4bAW28pp0Rr9E7rdkefUf4oU/4oU77skSev71AqWGxAZwk5rsLCQvzrX//CwoULIUkSPDw88Pbbb2PmzJnwuKMSkWVg7Vrg/feBs2eVeU2aALNmKWcUubqqsAOEEOLg6CwhB2c0GvH7779rstvNUVnL1NPTEx999BESEhIwaNAgFBUV4f3330eHDh3wyy+/oGy9rtMBjz4KnDgBfPst0LQpcO2a0svSrp1yplF9ervoM8ofZcofZcqXlvOkHhYb2KOHhTGG/Px8+Pj4aPI23o6oqkwZY1izZg1mzpyJq1evAgBGjBiBxYsXl7t2CwCUlABffw38+9/KtVwAoHlz5ZouTz8NlLkjgFOizyh/lCl/lClf9siThoTqEA0JOZeCggJ89NFHmD9/PkpKSqDT6fDMM89gzpw5aNKkSbn1CwuBzz8HFiy4fRZRkybA668rV8719KzjHSCEEAdCQ0IOzmg0YuPGjZrsdnNUtmbq5eWFDz74AKdOncK4ceMgyzK+/vprtG7dGu+99x7y8vIs1vf0VIqTixeVu0KHhipDRa++qvS4zJsH3PEUp0CfUf4oU/4oU760nCf1sNjAXkNCxcXFcHd3p25MTmqa6b59+/D666/jzz//BAA0bNgQ77//PqZOnQpXK0falpQAK1Yol/f/+wQk+PgA//gHMH26cuyLM6DPKH+UKX+UKV/2yJN6WJyAwWBQuwlOpyaZDhgwAPv27cMvv/yCNm3aIDMzEy+//DI6dOiAn376CZIkWazv5qYUJ2fPKoVL+/bKdVs+/hho2RJ4/HHlirrOgD6j/FGm/FGmfGk1TypYVCKKIqKjozV5vwZHVZtMBUHAQw89hKSkJHz55ZcIDg7G+fPn8cQTT6BTp05YtWpVucLFYACefBJISgJ+/x0YPly5AN3PPwO9egFDhwKbNimnSzsi+ozyR5nyR5nypeU8aUjIBvYaEhJFEQaDgboxOeGZ6a1bt/Dpp59iwYIFyM7OBgB06NABc+bMwfjx4yu8oFJiotLTsmoVYPr/3rq1ctn/KVOUexg5CvqM8keZ8keZ8mWPPGlIyAlosYJ1dLwy9fb2xjvvvINLly7hgw8+gL+/P06ePIkJEyagW7duWL9+PWQrXSfduwM//KAc2/LGG4CfH3DuHDBjhnKw7rPPKkWNo6DPKH+UKX+UKV9azZMKFpWIooiYmBjNfjAckT0y9fX1xXvvvYeLFy9i9uzZ8PX1xfHjx/Hwww+jU6dOWL58OUpLS8s9LywM+Ogj4OpV4H//U26uWFSkXJCuRw/grruAH39UDuDVKvqM8keZ8keZ8qXlPGlIyAZ0HRZikp2djUWLFuHTTz9Fbm4uACA8PByvvfYann32WXh5eVl9HmPAvn3AF18A69bdvmJuUBAwebJy6f/27etqLwghpO7QhePqEF3p1jHUZaZ5eXlYunQpFi1ahOvXrwMAGjRogJdeegkvvvgiGjRoUOFzr19XelqWLlV6YEzuukspXCZMUE6TVht9RvmjTPmjTPnS8pVuaUhIJaIoYs+ePZrsdnNUdZmpr68v3njjDVy8eBH/+9//EBERgZs3b2LOnDlo1qwZXnrpJZw7d87qcxs3Bt59VznOZeNG4P77Ab0e+PNP5RiXkBClcNm/X+mZUQt9RvmjTPmjTPnScp7Uw2IDGhIiVZEkCevXr8e8efOQWOao2nvvvRfTp0/HyJEjK/1rJS1NOVj3229v3ykaUG66OHmycm2XZs3suQeEEGIfNCRUh+xRsMiyjJycHPj7+1d4iiypHi1kyhjDjh07sHjxYvz+++/mu0F36NAB06dPxxNPPAHPSm4+ZDrW5dtvgTVrlPsYmQwaBEyaBDzyCBAYaO890UaezoYy5Y8y5cseedKQkIOTJAmHDh0qdzEyUnNayFQQBIwcORKbNm3CmTNn8NJLL8Hb2xsnT57E1KlTER4ejrfeegsXLlyo4PnAwIHAd98pvS7ffAMMG6bM37MH+Oc/lSGlBx9UDt4tLrbfvmghT2dDmfJHmfKl5Typh8UGNCREaiM3NxfLli3DZ599hot/33xIEARERkbin//8J8aOHVvlpbCvXlWuoPvTT8DRo7fn+/oC48YpvS4jRwJWbn1ECCGqoiGhOmSvIaHMzEw0bNiQujE50XqmkiRh06ZN+PLLLxETE2Oe36RJEzz77LN49tlnER4eXuV2kpKUwuWnn4CUlNvz/f2BBx4AHn4YGDVKuedRbWg9T0dEmfJHmfJljzxpSMjBybKMpKQkq1dLJTWj9Uz1ej0efPBBbNu2DcnJyXjzzTcRFBSEa9eu4YMPPkDz5s1x//33Y9OmTZXe2r1TJ+VO0ZcuAbt3Ay+8oAwT5eQAy5cD990HNGqk3Odo48aaDxtpPU9HRJnyR5nypeU8qYfFBjQkROylpKQEGzZswNKlS7Fr1y7z/EaNGuGJJ57AlClT0Llz5yq3I0nKadBr1wLr1wPXrt1e5u0N3Huv0vtyzz1KTwwhhNQVGhKqQ/YaEkpLS0NISAh1Y3Li6JmePn0aX3/9NX788Uekp6eb5/fo0QNTpkzBxIkT0bBhwyq3I8vKNV3WrVMeZS9OZzAAgwcr1365/36gRYvKtuPYeWoRZcofZcqXPfKkISEHJ8syzp8/r8luN0fl6Jm2a9cOCxcuxNWrV/Hbb79h3LhxcHFxQUJCAl5++WU0adIE48ePx8aNG1FSyU2IdDpgwABg0SLg8mWleHnrLaBDB+UO0rGxwCuvAC1bAp07Kxexi49XCp2yHD1PLaJM+aNM+dJyntTDYgMaEiJqyczMxM8//4zvv/8eCQkJ5vn+/v4YN24cJk6ciGHDhkGv19u0veRkYNMm4LfflNOky565GBwM3H23Mmw0ahRQyd0FCCHEZjQkVIfsNSSUkpKC8PBw6sbkxNkzPXbsGJYvX45Vq1bhWpmDVIKDgzFhwgRMnDgR/fr1s/n+H1lZwJYtSvGyZQuQn397mSAAffow9OuXiwkTfNG3rw421kSkEs7+GVUDZcqXPfKkISEHJ8syUlNTNdnt5qicPdMuXbpg4cKFuHLlCnbu3InnnnsOgYGBuHHjBj777DP0798fLVu2xNtvv42//voLVf0tEhioXDl39WogMxPYsQN4/XVlmIgxID5ewOLF/hgwQIegIOCxx4Dvv1cuaEdqxtk/o2qgTPnScp7Uw2IDGhIiWlVaWort27fj559/xoYNG1BQUGBe1qJFC4wbNw7jx49H3759q/XXUmoqsG0bsHUrsH27csp0WR06AMOHK48hQ+rmVgGEEMdEQ0J1yB4FiyRJuHjxIlq0aGHz8QekcvU908LCQmzevBmrVq3C1q1bUVRUZF7WpEkTPPTQQxg3bhwGDx5c5ZV1gdt5hoe3wJEjemzdqhQwhw9b3kVaEIAePW4XMAMHKqdSk/Lq+2fUHihTvuyRJw0JOTjGGLKzs6vstie2q++Zenp6YsKECfjll1+QkZGBdevW4fHHH4ePjw+uXbuGzz//HCNGjEDjxo3xzDPPYNOmTSgse3fFO5jy1OsZ+vcHPvgAOHgQyMhQrvXywgtA+/ZK8XLkCPDf/yoH7AYEKEXL7NnAzp2WN3Cs7+r7Z9QeKFO+tJwn9bDYgIaEiCMrKSnBjh07sH79emzcuBE3b940L3N3d8eIESMwduxY3HvvvTbdGuBO164phUlsrHIczOXLlstdXICePZW7TQ8apJxyTUNIhNQfNCRUh+w1JHTu3Dm0bt2aujE5oUyrJooi9uzZg/Xr12PTpk24cuWKxfJu3bph7NixGDt2LHr06IHz589XK0/GgIsXbxcvcXGWV9016djxdgEzaBBQgzrJIdFnlD/KlC975EkFSx2yV8Fy7NgxdOnShf6TcUKZVg9jDElJSdi8eTM2b96MP//806IbuFGjRujbty8ef/xxjBo1Cg1qcGEWxpR7Hu3Zc/tx5kz59Zo1U4aR+vVTHl26OOedp+kzyh9lypc98qSCpQ7RkBCpDzIyMrB161Zs3rwZW7duRV5ennmZIAjo3bs3IiMjERkZiX79+sHFxaVGr5OeDuzde7uASUwsf5Vdd3dlGMlUwPTrB4SF1WbvCCFqoYKlDtmrh+XUqVNo3749/VXACWXKj9FoxO7du/HDDz/gyJEjOHHihMVyHx8fDB8+HJGRkbj77rsRERFR49fKzwcOHFBuIXDggPLIzi6/XmioZQHTowfg6Vnjl1UFfUb5o0z5skeevL5Dqz63kRBS77i4uGDYsGFo3Lgx2rdvj+vXr2P79u3Ytm0btm/fjps3b2Ljxo3YuHEjAKBly5YYOXIkhg0bhmHDhiE4ONjm1/LxUW4FMGqU8jNjwLlzt4uXAweAY8eUa8OsX688AOWeSR06KD0xvXop/3bt6nhFDCHENtTDYgMaEiLkNlmWkZiYiG3btiEmJgb79u2DKIoW67Rv395cvAwdOtSmu0xXpqBAOXXaVMD8+Sdw/Xr59fT620WM6UFFDCHqoiGhOkQH3ToGypQvW/PMz8/Hrl27EBsbi507d+Lo0aPl1uncubO5gBkyZAgCAgJq1TbGlLOPjhy5/Th8GLhxo/y6ZYuYbt2UAqZLF3VOrabPKH+UKV9aPuiWhoRU5OHhoXYTnA5lypctefr4+OC+++7DfffdBwC4efMm4uLisHPnTuzcuRNJSUk4fvw4jh8/jk8//RSCIKBLly4YMGAABg4ciIEDB1b7+i+CoBzTEhoK3H+/Mu/OIubwYeXfGzeA48eVR1lhYUrxUvbRqhXsfpNH+ozyR5nypdU8qYfFBjQkREjNpaenY/fu3eYC5vTp0+XWadq0qbmAGTBgADp16sTlrztTEXP4MJCQABw9qjwuXbK+vqcn0KnT7V4Y079+frVuCiH1Fg0J1SF7FCyiKCIxMRHdu3e36b4upGqUKV/2yvP69evYt28f9u7di7179yIxMRGSJFms4+vri/79+5uLmN69e8PLy4tbG3JzlQN5TQXM0aNAUhJQ5vZLFkJDlYvddeyoDC+Z/q1uIUOfUf4oU77skScVLHWIbn7oGChTvuoqz1u3buHgwYPYu3cv9u3bh/379+PWrVsW6+j1enTq1Al9+/ZFnz590LdvX+6nsUoSkJxsWcQcPQpcvVrxc8LCbhcypiKmQwegol8T9BnljzLlS8s3P6SCxQY0JERI3RFFEcePH7fohUlNTS23no+PD3r16oW+ffuaC5kmTZpwb09ODnDyJHDixO1/T5ywfssBk/BwpYBp21Z5tGun/BsSohx/Q0h9QgVLHbLXkNDBgwfRp08f6sbkhDLlS0t5pqamIj4+HvHx8Th48CAOHTqEgoKCcuuFhYWZi5cePXqgR48eCLTT6UDZ2UoBU7aIOXECSEur+Dne3gyhoQXo3t0T7dvrzAVNmzZ06nVNaelz6gzskScVLHXIHgWLLMtISUlBeHg4dDodl23Wd5QpX1rOU5IknDx50lzExMfH48SJE5DvvMY/gObNm6NHjx7o2bOnuYhp1KiR3dpWtpA5c+b248IFZdipIuHht3tk2rYFWrcGIiKA5s2VO14T67T8OXVE9siTCpY6RENChGjfrVu3cOTIEcTHx+Pw4cNISEjA+fPnra4bGhpqUcD07NkTISEhEOw4XlNaqhQtZYsY0yMzs+Ln6fVA06bKKdcREZb/tmxJPTNE+6hgqUP2GhLav38/+vfvT92YnFCmfDlDnjk5Ofjrr79w5MgRJCQkICEhAWfOnIG1X3uNGjVCly5d0LVrV3Tp0gVdunRB+/bt4ebmxq09FWWalXW7eDl9Wvn3/HnlUVhY+TabNFEKmDuLmYgIwN/f+Y+ZcYbPqZbYI08qWOqQvYaE0tLSEBISQt2YnFCmfDlrnvn5+Th69CgSEhLMhczJkyetDifp9Xq0a9fOoojp0qULmjRpUqPemOpmyphyC4LkZKV4KftvcrJyQHBlfH2VIaUWLZR/yz5atHCO68s46+dULfbIkwqWOkRDQoQ4t8LCQpw4cQLHjh3D0aNHcezYMRw7dgzZ1m4bDSAwMNBcvHTu3BkdO3ZE+/bt4e/vX6ftzsoqX8iY/rV2r6U7+fuXL2LK/ky/7ggPVLDUIXsNCcXFxWHw4MHUjckJZcpXfc+TMYbU1FSLAubYsWM4c+ZMuQvdmTRp0gQdO3ZEhw4dLB6mM5XqMtPCQuDyZeWqvhcvKv+WfWRkVL2NgACgWTPlgGDTo2nT29OhoeofEFzfP6e82SNPKljqkL2GhDIzM9GwYUPqxuSEMuWL8rSuuLgYJ0+eNPfGnDhxAidPnrR6rRiTxo0bo0OHDmjfvj2aNWuG3r17o1OnTrW+i3Vt3Lp1u6CxVtTcvFn1NgQBaNy4fCFT9tG4MWDPjw99TvmyR55UsNQhGhIihFQlNzcXJ0+eLPe4cuVKhc9p0KAB2rZti7Zt26JNmzbmf1u1asX1YN+ayM9XCpcrV4CUlNsP089XrypnPlXFxUXpiQkPV64M3KSJ8nOTJrenQ0IAjd5vj3BABUsdskfBYjQaERsbi+HDh8NF7T5VJ0GZ8kV58pGfn49Tp07h5MmTOH78OPbs2YOMjAxcqugOjAB0Oh2aNWtmtZgJDQ3VRE+CLCvDSmWLmbIFTUqKcjVgK8cyWxUQYFnIWCtsgoOBO0cp6HPKlz3ypIKlDtlrSCgnJwf+/v6a+OXjDChTvihP/spmWlRUhHPnzuHMmTM4c+YMzp49a57Oz8+vcBuenp5o3bq1RW9MREQEIiIi0LhxY7teS6a6RFG58q+pgElNVR7XrikP08/FxbZtTxCUoqVsIdO4sQwfnyK0aOGBJk10CA5WhqGox6Zm7PH/ngqWOkRDQoSQusIYw40bNywKGNP0hQsXIIpihc/19PREy5YtzQVM2UezZs002QPBmHL37DsLGdO06ee0tMqvFHwnX1+Yi5fGjS2ny/7cqBHg6mq//SNUsNQpew0JxcTEIDIyUpO/RBwRZcoX5clfbTM1Go24ePGiuYA5e/Yszp8/j/Pnz+PKlStWryVjotfr0bRpU4seGdOjRYsW8PHxqc2u2Z0kKVcELl/YSEhKyoAsN8KNGzpcvw6UlFRv24GB1guZoKDb/5qmvb2d+2J89vh/TwVLHbJHwcIYQ35+Pnx8fDTVhevIKFO+KE/+7JlpaWkpLl++bC5gzp8/j+TkZJw/fx4XLlxAcRXjLoGBgWjevLnVR7NmzTTbu3xnpowBeXnKdWiuXwdu3Lg9fefP6enKsFV1uLlZFjBVTfv4OFaBY4/PKBUsdYiGhAghjsx09dKyxUzZR1ZWVpXbKFvQNGvWrFxR44i/G2VZufietWImI0MpaDIybk8XFVX/NSoqcIKCgAYNrD9UPkGMOypY6pC9hoSio6MxZswY6m7nhDLli/LkT6uZ5uXl4fLly7h06ZL5UfbnmzZclCUgIADNmjVDeHi41UdoaChc7XCwSF1mWlBQvpCxVtjUpsABlGGnioqZih6+vnx6cuyRJxUsdcheQ0LFxcVwd3en7nZOKFO+KE/+HDXT/Pz8cgVN2aIms7LbTf9NEAQEBwdXWNCEhYUhJCSk2ldX1XKmpgLHWmGTkaFcnK/sIyvL9tPA72QwKMfiNGgANGxoWcwEBiqnjZf91zR955CVPfKkgqUO2atgEUURBoNBc//JHBVlyhflyZ+zZnrr1i1z8ZKSklLucfXqVZTYcCSsXq9HSEiIRSHTpEkThIaGokmTJuaHR5lzlp0pU1lWzpjKzCxfzFT2qGlPDgDo9XcWMwxt2shYtEhHBYsjoiEhx0CZ8kV58ldfM2WMISMjw2oxY3qkpqZWeI+mOwUEBJiLl5CQEBQWFmLQoEFo2rSpeX7jxo3rzb2FiooqL2iysoDsbMt/s7IqPpuqZcscnD7tRUNCjoh6WBwDZcoX5ckfZVoxSZJw/fr1cj0zaWlpSE1NxbVr15Camlrl2U4mpiEoUwFj6qUJCQlB48aN0bhxYwQHByM4OFj12yCopaiofDFz8yaDh4eExx7TUw9LdSxduhRffPEFzp07B39/f9x///34z3/+gwYNGlT53Ly8PPz3v//F2rVrcfnyZRgMBnTs2BH//Oc/MWXKlGq1g45hcQyUKV+UJ3+Uae0wxpCTk4Nr166ZH1evXkVKSgrS09PNRU1aWprNvTWA0mNjKmDKFjOmadPPQUFBTt9rQ8ew1MDMmTOxcOFCTJw4EQ8++CAuXLiAqKgohISE4MCBA/D396/wuadOncLQoUMBAE899RR69eqF3NxcfP311zh06BCioqLw1ltv2dwWGhJyDJQpX5Qnf5Qpf9YylWUZGRkZ5p4Z0yM1NRXXr183P27cuAGj0WjzawmCgKCgoEqLG1Nh06BBA4csbugsoWpKSEhAz549MWnSJPz444/m+du3b0dkZCRmzJiBhQsXVvj8HTt24JdffsFHH30Eb29v8/zCwkK0atUKRUVFyMzMhF6vt6k9dB0WQghxPowxZGdnWxQwFU2np6dXeiXhOwmCgMDAQAQFBaFRo0YW/1qb16BBA5u/kxyNUxcszz//PL788kucOHECHTp0sFjWu3dvJCcnIyMjo8LqlTFWYVfW+PHj8csvv+DSpUto1qyZTe2hK906BsqUL8qTP8qUv7rKVJIkZGZmVlrYmH7OyspCdb9aBUFAgwYNKixsyk43bNgQgYGBduml0/KVbjXZXxUbG4uQkJByxQoAjBw5EocPH0ZCQgL69Olj9fmVhWy6C2plQ0p1QRRF7Nmzh+7TwhFlyhflyR9lyl9dZarX680H6VZFkiTcvHkT6enpyMjIQEZGhnn6zn8zMjJw8+ZNMMaQmZmJzMxMnDp1yqY2+fn5oUGDBmjYsKHFvxXNa9CgAdzd3SvdppY/o5rrYRFFER4eHhg4cCB27txZbvn333+Pp59+GsuXL8fkyZOrte1Lly6hdevW6NmzJw4cOFDheiUlJRbXDMjLy0N4eDiysrIQEBBgPphLr9dbTIuiCEEQzNM6nQ46na7CaaPRCL1eb542nTlgmjblUXbaxcXFfKaBi4sLZFmGJEnmaVmWYTAYKpyWJAmMMfO0tf2gfaJ9on2ifaJ9qrt9EgQBGRkZSEtLQ05ODm7cuGHuqblx44a5sDEVOtnZ2agpLy+vckWMqWfH398fDRs2RHh4OO666y5u71NRURGXHhZdjZ9pJzk5ORBFEY0aNbK63DTflisrliXLMp5++mlIkoQPP/yw0nWjoqLg5+dnfoSHhwMAkpKSACgH9Zoq4GPHjuHcuXMAgMTERFy8eBEAcPDgQaSkpAAA9u/fj7S0NABAXFwcMjMzIcsy/vjjD/M9PGJiYsy9P9HR0SguLoYoioiOjoYoiiguLkZ0dDQApZcoJibGnFdsbKw5k7i4OABAWloa9u/fDwBISUnBwYMHAQAXL15EYmIiAODcuXM4duwYt30ClN6xnJwcVfZJlmUcO3bMqfZJ7fcpIyMDhYWFTrVPar5PCQkJOHHiBGRZdpp9Uvt9Sk9Px86dO833S3LEfTIYDHBzc0NGRgaGDx+OESNGoEuXLvjggw/w/vvv45VXXsGePXuwbds2bN68GaIoIj4+HmvWrMHevXuxZMkSvP/++5g/fz6efvppjBs3Dg888AC6deuGiIgIBAUFmY+PKSgowOXLl5GQkIDt27dj1apV+PzzzzFnzhy88soreOKJJzB16lTu7xMPmuthSUlJQdOmTfHkk09ixYoV5ZbHxsZixIgRmDt3LmbNmmXzdufMmYN//etfeOWVV7Bo0aJK162LHhZJkrBjxw4MGzYMbm5u9JcGh31ijGHHjh0YOnQo3N3dnWKf1HyfioqKEBcXh+HDh0MQBKfYJ7Xfp+LiYuzatQsjRoyAIAhOsU9qv08lJSXYuXMnRowYAb1e7xT7ZI/3qbS0FHl5eeYenKysLGRnZyM9PR1ZWVnIyspCRkYGMjMz4e7ujg0bNsDNzU1TPSyaK1jS09MRHByMiRMnYuXKleWWb9u2DaNHj8b8+fPx+uuv27TNLVu2YOzYsRg8eDC2b99e7VPN6CwhQgghpGZ4fYdqbkjI19cXgiAgNzfX6nJTF5Wfn59N20tMTMSECRMQERGBdevWaea8eFmWq32aHKkcZcoX5ckfZcofZcqXlvPUXMHi7u6OsLAwXLhwwepy0/zWrVtXua0rV67g3nvvhYeHB7Zs2WLTFXLriizLSEpK0uSHwlFRpnxRnvxRpvxRpnxpOU/NDQkBwOOPP45Vq1bh+vXr5Q6+jYyMNB/sVPaicHfKycnBgAEDcPHiRezcuRN9+/atcXtoSIgQQgipGacdEgKAKVOmgDFW7mq2hw8fxo4dOzB+/Hh4e3sjJycHY8aMwaRJkyCKonm90tJSPPTQQzh9+jRWrlxZq2LFXmRZRmpqqiarWEdFmfJFefJHmfJHmfKl5Ty1cUDHHSIjI/Hoo49i/vz5yM7ORmRkJC5fvoyoqCgEBwdj3rx5AJRL9W/ZsgUA8Oqrr6JXr14AgFdeeQW7du3CAw88AIPBgM2bN5d7jW7duiEsLKzuduoOsizj/PnzCA4Ohk6nybrR4VCmfFGe/FGm/FGmfGk5T00OCQHKKVILFizA999/j4sXL8Lf3x+jR4/Ghx9+aC40UlJSMGjQIPj7+2Pfvn3w8vICAAwdOhS7d++udPvfffedzXdtpiEhQgghpGac+l5CWmOPgkWWZaSkpCA8PFxzVayjokz5ojz5o0z5o0z5skeeTn0MS32g5XFCR0WZ8kV58keZ8keZ8qXlPKmHxQY0JEQIIYTUDPWwODhJkpCcnGy+dDKpPcqUL8qTP8qUP8qULy3nSQWLShhjyM7OBnVw8UOZ8kV58keZ8keZ8qXlPGlIyAY0JEQIIYTUDA0JOThJknD69GlNdrs5KsqUL8qTP8qUP8qULy3nSQWLioqKitRugtOhTPmiPPmjTPmjTPnSap40JGQDGhIihBBCaoaGhBycJElISkrSZLebo6JM+aI8+aNM+aNM+dJynlSwEEIIIUTzaEjIBjQkRAghhNQMr+9QTd6tWWtMNV1eXh63bZq63Tp16gS9Xs9tu/UZZcoX5ckfZcofZcqXPfI0fXfWtn+EChYb5OfnAwDCw8NVbgkhhBDimPLz8+Hn51fj59OQkA1kWca1a9fg4+MDQRC4bDMvLw/h4eFISUmhYSZOKFO+KE/+KFP+KFO+7JEnYwz5+flo0qRJre4ATT0sNtDpdAgLC7PLtn19fek/GWeUKV+UJ3+UKX+UKV+886xNz4oJnSVECCGEEM2jgoUQQgghmkcFi0rc3Nwwe/ZsuLm5qd0Up0GZ8kV58keZ8keZ8qXlPOmgW0IIIYRoHvWwEEIIIUTzqGAhhBBCiOZRwUIIIYQQzaOChRBCCCGaRwWLCpYuXYouXbrAw8MDISEhmDp1Km7evKl2s+rc9evXMX36dLRs2RJubm7w9/fHsGHD8Ntvv5Vb99KlS3jssccQFBQELy8v9O3bF+vXr7e6XVEUERUVhTZt2sDd3R3NmjXDG2+8gcLCQqvr79y5E8OGDYOPjw8CAgIwduxYHDt2jOu+quXTTz+FIAho3rx5uWV//fUXxo4di4CAAPj4+GDYsGHYtWuX1e0UFBTgjTfeQLNmzeDu7o42bdpg3rx5Fd6Cft26dejbty88PT0RFBSEiRMn4vLlyxz3rG6tXLkSAwcOREBAALy9vdGxY0fMmzev3HrV+SxlZmbiueeeQ0hICDw8PNClSxd89dVXFbbBmX5vpKSkYOrUqWjWrBlcXV0REBCAyMhIbNmypdy69Dktb/ny5TAYDFb/X5to5bNYnfevSozUqddee40BYBMnTmSrV69mUVFRzNfXl7Vt25ZlZ2er3bw6s3PnTubj48OaN2/OZs+ezdasWcOWLFnC2rRpwwCwlStXmte9cOECa9iwIQsJCWGLFy9mK1euZJGRkQwA++KLLyy2K8sye/jhh5kgCOyFF15ga9asYe+88w5zcXFhAwcOZKWlpRbrb9iwgel0Ota7d2+2fPly9tVXX7E2bdowT09Pdvjw4TrJwl7OnTvHPD09WYMGDVizZs0slh08eJB5eHiwNm3asK+++ootX76c9e7dm+l0OrZ582aLdYuLi1n//v2Zq6sre/fdd9maNWvYCy+8wARBYI8++mi51/3ss88YABYZGclWrlzJFi9ezEJCQlijRo3YpUuX7LnL3MmyzJ588knzvq5YsYL98MMPbMaMGeyee+6xWLc6n6WsrCzWunVr5uvry6Kiotjq1avZxIkTGQD2xhtvlGuHM/3eOHv2LGvYsCFzcXFhL730Elu5ciVbsGABa968OQPAFi1aZF6XPqeWsrOz2fTp05kgCMxgMJT7f22ilc9idd4/W1DBUoeOHDnCALBJkyZZzI+JiWEA2IwZM1RqWd377rvv2Jw5c1hJSYnF/NTUVObu7s46depknnf//fczV1dXduLECfM8SZLY4MGDmaenJ7t+/bp5/i+//MIAsHfffddiu19//TUDwD799FPzvMLCQta4cWPWunVrVlhYaJ5//fp1FhgYyHr27Mltf+uaJEls4MCBbNy4cWzIkCEWv9hkWWZdu3ZlgYGB7MaNG+b5BQUFrHXr1iw0NJQVFRWZ53/88ccMAPv6668tXuPdd99lANhvv/1mnnft2jXm7u7OBg8ezCRJMs9PSkpirq6ubNy4cXbYW/v58MMPmU6nY2vWrKl0vep+ll5++WUGgG3fvt1i/qRJk5ggCOzo0aPmec72e+Ohhx5iANgvv/xiMT87O5s1bdqUubu7s8zMTPqcWvH000+zoKAg9sMPP5T7f22ilc9idd8/W1DBUoemTZvGAFh88Zr06tWL+fv7M6PRqELL6p4syxUu69GjB9PpdEySJHb9+nUmCAJ75JFHyq23efNmBoAtWLDAPO+ee+5hrq6uLCsry2JdURRZ48aNLQqh1atXMwDs888/L7ftmTNnMgAO28uycOFC5ufnx1JTU8v9YouPj2cA2Ouvv17ueUuWLGEA2Lp168zz2rdvzxo3bsxEUbRYNysri7m6urKxY8ea53300UcMAPv999/Lbfvhhx9mOp2Opaenc9hD+8vIyGBeXl42FQTV+SyVlpYyX19f1rt373LrJiUlMQDsxRdfNM9ztt8bvr6+FfYMvP/++wwA27BhA31OrUhMTDR/yVdUsGjls1jd988WdAxLHYqNjUVISAg6dOhQbtnIkSORk5ODhIQEFVpW9yq767XpFuQ6nQ47d+4EYwwjR44st97QoUOh1+uxY8cOAMpdtXfv3o2ePXsiICDAYl29Xo+hQ4ciKSkJ6enpAJT3A4DVbZvmmbbtSM6ePYtZs2Zh4cKFaNKkSbnl1dnv69ev49SpUxg2bBj0er3FugEBAejRo4f5PTJt22AwYOjQoVa3Lcsydu7cWav9qyurV69GcXExZs6caZ4niqLVdauT6ZEjR5CXl2d13Y4dO6Jx48YWnztn+72h0+kQFBRkdVnZ+fQ5La9bt25wd3evdB2tfBbt8fuVCpY6Iooizp8/j7Zt21pdbpp/+vTpumyW5uzbtw/nzp1DZGQkAODMmTMAYDU3Ly8vhIWFmTNLSUlBYWGhzRmfOXMGBoMBERERVa7rKGRZxpQpUzBgwAA888wzVtepLNNWrVpBr9dbZFTRuqb5BQUFSElJMa8fFhYGT09Pq+sCjpNpTEwMunXrBlmWMXHiRPj6+sLV1RUdOnTA8uXLLdatzmfJlkyTk5MhSZJT/t4YNmwYjh49ipMnT1rMl2UZP//8Mzw9PdGvXz/6nNaQVj6L1Xn/bEUFSx3JycmBKIpo1KiR1eWm+ZmZmXXZLE0pKirCs88+Czc3N7z//vsAgIyMDACoNDdTZrasC8Bi/cDAwHJ/kVlb11EsXLgQx44dq/QI/8py0uv1CAwMrFWmzvIZP378OBo2bIiBAwfC3d0da9euxZo1a+Du7o4pU6Zg0aJF5nWr81myJVOj0Yjc3Fyn/L3x8ccfIzw8HGPGjMG6detw/fp1JCQkYPz48YiPj8eSJUsQHBxMn9Ma0spnsTrvn60M1Vqb1FhRUREAVHhDKVM3X0Wn3tYH06ZNw+nTp/HJJ5+Yuxxtyc2UWXUzLioqcqr349SpU3j//ffx0UcfoUWLFhWuR5na5saNG7h06RJeeuklLF682Dx/9OjR6NixI95991089dRTCAwMrNZ+VydT0xCGs2QKAM2bN0dCQgImTpyIRx55xDw/KCgIu3btwsCBAwHQ57SmtPJZrM77ZyvqYakjpjetojFwo9FosV5989VXX2H58uWYNGkSpk+fbp5vS26mdaqbsZvb/7d370FRlXEfwL/Lrrtclg0hRQGFLRBNEXA0bt5wRmdEU2QM8lZBk84Q/dEomA2F3cYuZI1ooCNGM854wVKD0izFSZ0gZZCREM1AdPCSlq5BGrff+4cv+7rtsuwCwsr7/czsHzznt895znMeDj/O5TmaAbM/2trakJycjAkTJiAtLc1qLPvUNq2trVAoFMjMzDQp12q1eOmll3D37l0cOnQIgH3bbU+fDsTjRn19PaZNm4ZffvkF69atw4EDB/Dll18iKCgIcXFx2LVrFwCO0+5ylLFoz/6zFc+w9BGdTgeFQgGDwWBx+e3btwEAjz32WB+2yjEcPHgQr7zyCqKjo7F161aTZR4eHgBgtd86+syWWAAm8Z1NEvWo7Y/c3FyUl5fj2LFjuHPnjsmy1tZWtLe3G7fpwX6ydPOjwWAwnqHpTp8OlDHu5eUFd3d3i300ZswYAPcnNATsG0u29KlCoYBOp4OIDLjjRlJSEi5evIjy8nKT+yyWLVuG+fPnY8mSJQgLC+M47SZHGYv27D9b8QxLH3F2doafnx9qa2stLu8oDwoK6stm9buKigo8++yz0Ov1+Oabb8zugA8MDAQAi/3W1taG+vp6Y58FBARApVLZ3MeBgYH4559/cP369S5jHd2FCxfQ2tqKqKgoDB482ORz4sQJXL582fizSnX//xRL/XT16lXcvXvXpI86i+0oVyqVxgNPYGAg6uvr0d7ebjEWeHT6dNiwYRg0aJDFZc3NzQAAtVoNwL6xZEufjhgxAhqNZsAdN2pra1FWVoalS5ea3RSqUCjw5ptvoq2tDTt27LDaTxynnXOUsWjP/rMVE5Y+NHnyZJw7d874WO2DSkpKoNFoMGnSpH5oWf+or6/HnDlz4OLiggMHDsDLy8sspuN69rFjx8yWlZWV4e7du8YYtVqNSZMmoayszHh68kFHjx6Fr6+vcTpra3V3PNLYEePo0tLSUFJSYvETGhoKb29v488LFy4EYNt26/V6+Pr6Woy9d+8eSktLERERYfzDPnnyZDQ1NVl8zPZR69OIiAj8/vvvFv+jLC8vBwCEhIQAsG8sTZo0CWq12mJsQ0MDzp8/b9JHA+m40bENHUnzf3WMo+vXr9vVp/+fx+l/OcpYfCjHV7tmbaEe+f777y1Od3zy5ElxcnKSxYsX91PL+t6tW7fkqaeeEhcXFyktLbUaGxUVJR4eHnLlyhWT8nnz5olSqZTq6mpj2ebNmy1O2d8xA+4bb7xhLLt586ZotVqJiooymWzKYDCIn5+f+Pv7m03l/yj67wRTzc3NMnLkSNHr9dLY2Ggsb2lpkQkTJoi7u7vcvHnTWL5mzRoBIN99951JvR0zi27ZssVYVl1dLU5OTpKYmGgSW19fL1qtVqKjo3t56x6e0tJSASCrVq0yKa+rqxMPDw8ZOXKkcZIse8fSokWLRKVSmcwiKvJ/s44eOnTIWDaQjht37twRFxcXGTJkiFy6dMlseVJSknG2Wo5T6zqbOM5RxqK9+88WTFj6WMcv5MsvvyyFhYWSnZ0tXl5eMnz4cIu/wAPV7NmzBYAsX75cioqKLH46BvOpU6fE1dVVnnjiCcnNzZWdO3fK/PnzBYBkZmaa1Nvc3CyTJ08WlUol6enpsmfPHnn77bfFxcVFxo4dKwaDwSQ+NzdXAEhsbKxs375d8vPzJSQkRFQqlRw8eLDP+uNhsnRgKy4uFqVSKeHh4bJt2zbZvn27TJkyRQDI1q1bTWJv3bolwcHB4ubmJu+++67s2bNHVq5cKUqlUmJjY81mWV29erUAkISEBNm1a5ds2rRJ/P39xd3dXSoqKh7y1vaujoP2okWLZPfu3ZKTkyM+Pj7i7OwsR44cMYm1ZyxdvHhRhg4dKkOHDpVPPvlECgsLJSUlRQDI0qVLzdoxkI4bGzZsEAAyZMgQWbt2rezevVs+//xziYmJEQASGRlpfGUHx2nnOktYRBxnLNqz/2zBhKWPtbS0yLp16yQ4OFjUarUMHTpUnn/+ebl8+XJ/N61P+fv7CwCrn5KSEmN8ZWWlzJ07Vzw8PMTZ2VnCw8Pliy++sFh3Y2OjZGRkSEBAgKjVavH19ZW0tDSz6fo77NmzRyIjI8XV1VXc3d1l5syZcvz48Yew1f2jswPb0aNHZcaMGeLu7i5ubm4SExNj8r6VB924cUNWrFghPj4+olarRa/XS2Zmpsm7Sjq0t7fL5s2bJTQ0VJydnWXw4MESHx9vcTrvR8HGjRtl3Lhx4uLiYtyW06dPW4y1ZyzV1dXJokWLZMiQIaJWq2XMmDGSnZ1tNrW8yMA7bvzwww8yb9488fb2FpVKJVqtViZOnCgff/yx3Lt3zySW49QyawmLiOOMRXv2X1cUIv/7cDURERGRg+JNt0REROTwmLAQERGRw2PCQkRERA6PCQsRERE5PCYsRERE5PCYsBAREZHDY8JCREREDo8JCxERETk8y2+gIiIaABoaGmBpbkwfHx84OfH/NaJHCX9jichu58+ft/jaeIPBgKqqKjQ1NRnLiouLoVAoUFBQYLGu/Px8xMfHo66uzuo64+PjkZWVZVc7/f39MWLECLPPf982GxAQgIkTJ9pUZ01NDTIzM41vnCWivsEzLERkt1mzZmHYsGEoLS01KS8qKsKyZctQUlKC6dOn21TXmTNnsH//fqxdu9Zq3P79+9HY2GhXO8vKyiyeYXn88cftqudBP/74I95//30MHz4csbGx3a6HiOzDhIWIHMLevXtx6tSpHtdz4sQJLFmyxKbY7OxsLFy40Oa629vbsW3bNgBAdHR0t9pHRN3DhIWIuuXvv//G8ePHTcrOnz/f7freeeednjYJwP3LQKtWrbIpdty4cXbVnZWVhYqKCgDAqlWrUFRUBFdXV7vbSET2Y8JCRN1SXV2NKVOm2Bz/888/Q6W6f8iZM2cOBg8ebLL87NmzGD16dKffVygUNq3Hz88PaWlp+Ouvv7B+/XocPnwYV65cgYjA29sbU6dOxcqVK+Hj42Nz21taWvD6669j/fr1mDt3LhISErB8+XJMmDABBQUFiIyMtLkuIuoeJixE1C1hYWHYu3evSdm+ffvw2muvWYzfsmULtmzZAgCoqKgwS1gqKytx+/btXmlbS0sLYmJicOnSJaSlpWH8+PFwcnLC2bNnkZOTg507d+LXX3+Fh4eH1Xra2tqwb98+ZGZmoqamBsnJycjLy4NarYZer8cLL7yA6OhoxMXF4dVXX8WMGTMwaNCgXtkGIjLFhIWIukWj0SAgIMCkzNrNrHl5ecZ7SyxdRnnuued6rW21tbWoqalBRkYGPvzwQ5NlOp0O6enpqKysxLRp0zqtIzMzEwUFBWhoaMCoUaPw9ddfY8GCBcbl06dPx5kzZ/DRRx9h48aN+Pbbb6HT6VBUVISpU6f22rYQ0X1MWIioT2g0Gmi1WrPy9PR0vPjiiyZlSUlJ+OOPP8weHXZ3d7dpXUFBQYiIiEBOTg5aW1sRGhoKhUKBmpoabNq0CUFBQV0+xjx+/Hg8/fTTWLx4MRYsWAClUmkWo9Pp8N577yEjIwPFxcV2XyYjItsxYSGibjl58qRZAtLa2mp3Pb6+vvD19TUpc3FxgVKpRFhYWLfa5uTkhCNHjmDr1q04fPgw8vPzYTAYMGvWLKSnpyM1NRVubm5W60hMTERiYqJN69PpdFi8eHG32kpEtmHCQkR2e+utt3Dnzp1OlwcGBlr9fkFBAZKTk7tcj7UbbVesWIG8vDyz8o6kSa1WIzU1FampqUhISEBRURFyc3PR1NSE6upq/Pnnn7h27Rpmzpxp8v2WlhacOHGiy7ZZExAQYHa5jIh6hgkLEdktJSWlR9+PiopCbm5uj+oYO3asWVlVVRVCQkI6/c6TTz4J4H4i5OnpCV9fX7OzOAaDoccTwmVlZXU5ER4R2YcJCxF1W319PU6ePImoqCizyzrWBAcHIzg4uNfbo9frTe57USgUUCqVGDRoEFxdXaHVaqHRaODs7AydTmd8zPpBnp6e+O233zpdx+bNm5GdnY3t27cjIiLCYoynp2fPN4aITDBhIaJuKykpQXJyMgoLCzudMTYwMBCrV6/u9MyHh4cHDAaDTesbO3YsqqqqOl3u5ubW5SsBkpKSsHv3btTW1kKv1wMAcnNzodFoANy//8XaJS0vLy8A9++96erSFxH1HiYsRPRQjR49Gh988EGnyz/99FP8+++/XdbTG5dYfvrpJ3z11VfG9W7YsAEAMHv27B7XTUQPFxMWIupXttx8CwCfffZZt9fR3NyMvLw8rFmzBgEBAYiLi0NOTg4uXLiADRs28EwJ0SOACQsR9djBgwdx7do1qzE+Pj5ISEjooxYBV69exalTp3Do0CEUFhbi+vXrmD9/PvLy8jBs2DCEhYUhIyMDo0aNQkxMDJ555hmEh4cjKirK4nwxRNS/mLAQUY/l5+d3GRMTE9NnCUtbWxvi4uJw+vRpeHl5IT4+HikpKSZvWE5JSUFCQgJ27NiBnTt3IisrC1qtFufOneuTNhKRfRQiIv3dCCKi3lZXV4d79+5h9OjRNr04saWlBTdu3LDrpYhE1HeYsBAREZHDc+rvBhARERF1hQkLEREROTwmLEREROTwmLAQERGRw2PCQkRERA6PCQsRERE5PCYsRERE5PCYsBAREZHDY8JCREREDo8JCxERETm8/wEubm8LmPaH8QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선 출력(손실)\n",
    "\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='훈련')\n",
    "plt.plot(history[:,0], history[:,3], 'k', label='검증')\n",
    "plt.xlabel('반복 횟수')\n",
    "plt.ylabel('손실')\n",
    "plt.title('학습 곡선(손실)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 출력 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2])\n",
      "==================================================\n",
      "[[6.3 4.7]\n",
      " [5.  1.6]\n",
      " [6.4 5.6]]\n"
     ]
    }
   ],
   "source": [
    "# 정답 데이터의 0번째, 2번째, 3번째를 추출\n",
    "\n",
    "print(labels[[0,2,3]])\n",
    "\n",
    "# 이에 해당하는 입력값을 추출\n",
    "print(\"=\"*50)\n",
    "i3 = inputs[[0,2,3],:]\n",
    "print(i3.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.8071 14.1938 12.9986]\n",
      " [12.8262  9.8     0.1734]\n",
      " [ 6.7954 15.0928 17.1111]]\n",
      "[[0.0035 0.765  0.2315]\n",
      " [0.9537 0.0463 0.    ]\n",
      " [0.     0.1173 0.8827]]\n"
     ]
    }
   ],
   "source": [
    "# 출력값에 소프트맥스 함수를 적용한 결과를 취득\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "o3 = net(i3)\n",
    "k3 = softmax(o3)\n",
    "print(o3.data.numpy())\n",
    "print(k3.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 행렬과 바이어스 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0452, -2.5735],\n",
      "        [ 1.3573,  0.8481],\n",
      "        [-1.4026,  4.7253]])\n",
      "tensor([ 1.7178,  1.6563, -0.3741])\n"
     ]
    }
   ],
   "source": [
    "# 가중치 행렬\n",
    "print(net.l1.weight.data)\n",
    "\n",
    "# 바이어스\n",
    "print(net.l1.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력 변수 4개 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4) (75, 4) (75,) (75,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 검증 데이터로 분할(셔플도 동시에 실시함)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_org, y_org, train_size=75, test_size=75, \n",
    "    random_state=123)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# 입력 차원수\n",
    "n_input = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터(x)\n",
      "[[6.3 3.3 4.7 1.6]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.  3.  1.6 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.3 2.5 5.  1.9]]\n",
      "입력 차원수: 4\n"
     ]
    }
   ],
   "source": [
    "print('입력 데이터(x)')\n",
    "print(x_train[:5,:])\n",
    "print(f'입력 차원수: {n_input}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 x_train과 정답 데이터 y_train의 텐서 변수화\n",
    "inputs = torch.tensor(x_train).float()\n",
    "labels = torch.tensor(y_train).long()\n",
    "\n",
    "# 검증용 데이터의 텐서 변수화\n",
    "inputs_test = torch.tensor(x_test).float()\n",
    "labels_test = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "lr = 0.01\n",
    "\n",
    "# 초기화\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 손실 함수： 교차 엔트로피 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 알고리즘: 경사 하강법\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 반복 횟수\n",
    "num_epochs = 10000\n",
    "\n",
    "# 평가 결과 기록\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62080 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35506, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31853, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31489, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25921, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23287, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22577, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22357 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21483, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21396, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18622 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17228 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17588, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16939, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16093 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15997, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15081, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14266, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 훈련 페이즈\n",
    "    \n",
    "    # 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 경사 계산\n",
    "    loss.backward()\n",
    "    \n",
    "    # 파라미터 수정\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    # 예측 페이즈\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs_test = net(inputs_test)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기상태 : 손실 : 1.09158  정확도 : 0.26667\n",
      "최종상태 : 손실 : 0.13724  정확도 : 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 손실과 정확도 확인\n",
    "\n",
    "print(f'초기상태 : 손실 : {history[0,3]:.5f}  정확도 : {history[0,4]:.5f}' )\n",
    "print(f'최종상태 : 손실 : {history[-1,3]:.5f}  정확도 : {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선 출력(손실)\n",
    "\n",
    "plt.plot(history[:,0], history[:,1], 'b', label='훈련')\n",
    "plt.plot(history[:,0], history[:,3], 'k', label='검증')\n",
    "plt.xlabel('반복 횟수')\n",
    "plt.ylabel('손실')\n",
    "plt.title('학습 곡선(손실)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 곡선 출력(정확도)\n",
    "\n",
    "plt.plot(history[:,0], history[:,2], 'b', label='훈련')\n",
    "plt.plot(history[:,0], history[:,4], 'k', label='검증')\n",
    "plt.xlabel('반복 횟수')\n",
    "plt.ylabel('정확도')\n",
    "plt.title('학습 곡선(정확도)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLLLoss 함수 이해 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([0, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# 입력 변수 준비\n",
    "\n",
    "# 더미 출력 데이터\n",
    "outputs_np = np.array(range(1, 13)).reshape((4,3))\n",
    "# 더미 정답 데이터\n",
    "labels_np = np.array([0, 1, 2, 0])\n",
    "\n",
    "# 텐서화\n",
    "outputs_dummy = torch.tensor(outputs_np).float()\n",
    "labels_dummy = torch.tensor(labels_np).long()\n",
    "\n",
    "# 결과 확인\n",
    "print(outputs_dummy.data)\n",
    "print(labels_dummy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.25\n"
     ]
    }
   ],
   "source": [
    "# NLLLoss 함수 호출\n",
    "\n",
    "nllloss = nn.NLLLoss()\n",
    "loss = nllloss(outputs_dummy, labels_dummy) # -(1 + 5 + 9 + 10)/4 = -6.25\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 클래스측에 LogSoftmax 함수를 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "# 2입력 3출력 로지스틱 회귀 모델\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "        # logsoftmax 함수 정의\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "                \n",
    "        # 초깃값을 모두 1로 함\n",
    "        # \"딥러닝을 위한 수학\"과 조건을 맞추기 위한 목적        \n",
    "        # self.l1.weight.data.fill_(1.0)\n",
    "        # self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.logsoftmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "lr = 0.01\n",
    "\n",
    "# 초기화\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 손실 함수： NLLLoss 함수\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 최적화 함수: 경사 하강법\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.0 (20240811.2233)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"214pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 214.00 406.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 210,-402.75 210,4 -4,4\"/>\n",
       "<!-- 2250209478592 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2250209478592</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"130,-32.75 76,-32.75 76,0 130,0 130,-32.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 2250210510496 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2250210510496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"159,-89.5 47,-89.5 47,-68.75 159,-68.75 159,-89.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">NllLossBackward0</text>\n",
       "</g>\n",
       "<!-- 2250210510496&#45;&gt;2250209478592 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2250210510496&#45;&gt;2250209478592</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-68.36C103,-61.89 103,-53.05 103,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-44.55 103,-34.55 99.5,-44.55 106.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 2250210511888 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2250210511888</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168,-146.25 38,-146.25 38,-125.5 168,-125.5 168,-146.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">LogSoftmaxBackward0</text>\n",
       "</g>\n",
       "<!-- 2250210511888&#45;&gt;2250210510496 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2250210511888&#45;&gt;2250210510496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-125.09C103,-118.47 103,-109.47 103,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-101.34 103,-91.34 99.5,-101.34 106.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 2250210510400 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2250210510400</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-203 53,-203 53,-182.25 153,-182.25 153,-203\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 2250210510400&#45;&gt;2250210511888 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2250210510400&#45;&gt;2250210511888</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103,-181.84C103,-175.22 103,-166.22 103,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.5,-158.09 103,-148.09 99.5,-158.09 106.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 2250210511024 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2250210511024</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-259.75 0,-259.75 0,-239 100,-239 100,-259.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2250210511024&#45;&gt;2250210510400 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2250210511024&#45;&gt;2250210510400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.48,-238.59C66.79,-231.03 77.09,-220.39 85.84,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.11,-214.04 92.55,-204.42 83.08,-209.17 88.11,-214.04\"/>\n",
       "</g>\n",
       "<!-- 2250211029456 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2250211029456</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"79,-329.25 21,-329.25 21,-295.75 79,-295.75 79,-329.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-315.75\" font-family=\"monospace\" font-size=\"10.00\">l1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 2250211029456&#45;&gt;2250210511024 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2250211029456&#45;&gt;2250210511024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-295.44C50,-288.1 50,-279.32 50,-271.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.73 50,-261.73 46.5,-271.73 53.5,-271.73\"/>\n",
       "</g>\n",
       "<!-- 2250211006784 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2250211006784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"194,-259.75 118,-259.75 118,-239 194,-239 194,-259.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 2250211006784&#45;&gt;2250210510400 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2250211006784&#45;&gt;2250210510400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.52,-238.59C139.21,-231.03 128.91,-220.39 120.16,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.92,-209.17 113.45,-204.42 117.89,-214.04 122.92,-209.17\"/>\n",
       "</g>\n",
       "<!-- 2250211008368 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2250211008368</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"206,-322.88 106,-322.88 106,-302.12 206,-302.12 206,-322.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-309.38\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2250211008368&#45;&gt;2250211006784 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2250211008368&#45;&gt;2250211006784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156,-301.68C156,-293.52 156,-281.63 156,-271.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.5,-271.48 156,-261.48 152.5,-271.48 159.5,-271.48\"/>\n",
       "</g>\n",
       "<!-- 2250215653920 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2250215653920</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"191,-398.75 121,-398.75 121,-365.25 191,-365.25 191,-398.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-385.25\" font-family=\"monospace\" font-size=\"10.00\">l1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-372.5\" font-family=\"monospace\" font-size=\"10.00\"> (3, 4)</text>\n",
       "</g>\n",
       "<!-- 2250215653920&#45;&gt;2250211008368 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2250215653920&#45;&gt;2250211008368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156,-365C156,-355.9 156,-344.39 156,-334.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.5,-334.84 156,-324.84 152.5,-334.84 159.5,-334.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x20beaff8850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측 계산\n",
    "outputs = net(inputs)\n",
    "\n",
    "# 손실 계산\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# 손실의 계산 그래프 시각화\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "lr = 0.01\n",
    "\n",
    "# 초기화\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 손실 함수： NLLLoss 함수\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 최적화 함수: 경사 하강법\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 반복 횟수\n",
    "num_epochs = 10000\n",
    "\n",
    "# 평가 결과 기록\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.74435 acc: 0.32000 val_loss: 1.89647, val_acc: 0.57333\n",
      "Epoch [10/10000], loss: 1.04036 acc: 0.62667 val_loss: 1.09881, val_acc: 0.49333\n",
      "Epoch [20/10000], loss: 0.93898 acc: 0.66667 val_loss: 0.96434, val_acc: 0.54667\n",
      "Epoch [30/10000], loss: 0.89766 acc: 0.70667 val_loss: 0.91556, val_acc: 0.61333\n",
      "Epoch [40/10000], loss: 0.86195 acc: 0.70667 val_loss: 0.87572, val_acc: 0.61333\n",
      "Epoch [50/10000], loss: 0.83032 acc: 0.70667 val_loss: 0.84063, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.80220 acc: 0.70667 val_loss: 0.80956, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.77712 acc: 0.72000 val_loss: 0.78195, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.75465 acc: 0.72000 val_loss: 0.75730, val_acc: 0.62667\n",
      "Epoch [90/10000], loss: 0.73444 acc: 0.74667 val_loss: 0.73522, val_acc: 0.62667\n",
      "Epoch [100/10000], loss: 0.71617 acc: 0.74667 val_loss: 0.71533, val_acc: 0.65333\n",
      "Epoch [110/10000], loss: 0.69959 acc: 0.76000 val_loss: 0.69733, val_acc: 0.69333\n",
      "Epoch [120/10000], loss: 0.68448 acc: 0.78667 val_loss: 0.68098, val_acc: 0.77333\n",
      "Epoch [130/10000], loss: 0.67065 acc: 0.81333 val_loss: 0.66606, val_acc: 0.77333\n",
      "Epoch [140/10000], loss: 0.65793 acc: 0.82667 val_loss: 0.65239, val_acc: 0.80000\n",
      "Epoch [150/10000], loss: 0.64620 acc: 0.85333 val_loss: 0.63980, val_acc: 0.81333\n",
      "Epoch [160/10000], loss: 0.63533 acc: 0.88000 val_loss: 0.62818, val_acc: 0.81333\n",
      "Epoch [170/10000], loss: 0.62523 acc: 0.88000 val_loss: 0.61741, val_acc: 0.82667\n",
      "Epoch [180/10000], loss: 0.61581 acc: 0.89333 val_loss: 0.60740, val_acc: 0.82667\n",
      "Epoch [190/10000], loss: 0.60700 acc: 0.89333 val_loss: 0.59805, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.59874 acc: 0.90667 val_loss: 0.58931, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59096 acc: 0.89333 val_loss: 0.58110, val_acc: 0.84000\n",
      "Epoch [220/10000], loss: 0.58363 acc: 0.90667 val_loss: 0.57337, val_acc: 0.84000\n",
      "Epoch [230/10000], loss: 0.57669 acc: 0.90667 val_loss: 0.56608, val_acc: 0.84000\n",
      "Epoch [240/10000], loss: 0.57011 acc: 0.90667 val_loss: 0.55919, val_acc: 0.84000\n",
      "Epoch [250/10000], loss: 0.56386 acc: 0.90667 val_loss: 0.55266, val_acc: 0.84000\n",
      "Epoch [260/10000], loss: 0.55792 acc: 0.90667 val_loss: 0.54645, val_acc: 0.85333\n",
      "Epoch [270/10000], loss: 0.55224 acc: 0.90667 val_loss: 0.54054, val_acc: 0.86667\n",
      "Epoch [280/10000], loss: 0.54682 acc: 0.90667 val_loss: 0.53491, val_acc: 0.88000\n",
      "Epoch [290/10000], loss: 0.54162 acc: 0.90667 val_loss: 0.52952, val_acc: 0.88000\n",
      "Epoch [300/10000], loss: 0.53665 acc: 0.92000 val_loss: 0.52437, val_acc: 0.88000\n",
      "Epoch [310/10000], loss: 0.53186 acc: 0.92000 val_loss: 0.51943, val_acc: 0.89333\n",
      "Epoch [320/10000], loss: 0.52726 acc: 0.92000 val_loss: 0.51469, val_acc: 0.89333\n",
      "Epoch [330/10000], loss: 0.52283 acc: 0.92000 val_loss: 0.51013, val_acc: 0.89333\n",
      "Epoch [340/10000], loss: 0.51855 acc: 0.92000 val_loss: 0.50575, val_acc: 0.89333\n",
      "Epoch [350/10000], loss: 0.51442 acc: 0.93333 val_loss: 0.50152, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51043 acc: 0.93333 val_loss: 0.49743, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50657 acc: 0.94667 val_loss: 0.49349, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50282 acc: 0.94667 val_loss: 0.48967, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.49919 acc: 0.94667 val_loss: 0.48597, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49566 acc: 0.94667 val_loss: 0.48239, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49223 acc: 0.94667 val_loss: 0.47891, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48889 acc: 0.94667 val_loss: 0.47554, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48564 acc: 0.94667 val_loss: 0.47225, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48248 acc: 0.94667 val_loss: 0.46906, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.47939 acc: 0.94667 val_loss: 0.46595, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47638 acc: 0.94667 val_loss: 0.46292, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47344 acc: 0.94667 val_loss: 0.45997, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47057 acc: 0.94667 val_loss: 0.45709, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46776 acc: 0.94667 val_loss: 0.45428, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46501 acc: 0.94667 val_loss: 0.45153, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46232 acc: 0.94667 val_loss: 0.44884, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.45969 acc: 0.94667 val_loss: 0.44622, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45711 acc: 0.94667 val_loss: 0.44365, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45458 acc: 0.96000 val_loss: 0.44113, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45210 acc: 0.96000 val_loss: 0.43866, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44967 acc: 0.96000 val_loss: 0.43625, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44728 acc: 0.96000 val_loss: 0.43388, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44493 acc: 0.96000 val_loss: 0.43156, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44262 acc: 0.96000 val_loss: 0.42928, val_acc: 0.90667\n",
      "Epoch [600/10000], loss: 0.44036 acc: 0.96000 val_loss: 0.42704, val_acc: 0.90667\n",
      "Epoch [610/10000], loss: 0.43813 acc: 0.96000 val_loss: 0.42484, val_acc: 0.90667\n",
      "Epoch [620/10000], loss: 0.43594 acc: 0.96000 val_loss: 0.42268, val_acc: 0.90667\n",
      "Epoch [630/10000], loss: 0.43379 acc: 0.96000 val_loss: 0.42056, val_acc: 0.90667\n",
      "Epoch [640/10000], loss: 0.43167 acc: 0.96000 val_loss: 0.41848, val_acc: 0.90667\n",
      "Epoch [650/10000], loss: 0.42958 acc: 0.96000 val_loss: 0.41642, val_acc: 0.90667\n",
      "Epoch [660/10000], loss: 0.42752 acc: 0.96000 val_loss: 0.41441, val_acc: 0.90667\n",
      "Epoch [670/10000], loss: 0.42550 acc: 0.96000 val_loss: 0.41242, val_acc: 0.90667\n",
      "Epoch [680/10000], loss: 0.42350 acc: 0.96000 val_loss: 0.41047, val_acc: 0.90667\n",
      "Epoch [690/10000], loss: 0.42154 acc: 0.96000 val_loss: 0.40854, val_acc: 0.90667\n",
      "Epoch [700/10000], loss: 0.41960 acc: 0.96000 val_loss: 0.40665, val_acc: 0.90667\n",
      "Epoch [710/10000], loss: 0.41769 acc: 0.96000 val_loss: 0.40478, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41581 acc: 0.96000 val_loss: 0.40295, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41395 acc: 0.96000 val_loss: 0.40113, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41212 acc: 0.94667 val_loss: 0.39935, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41031 acc: 0.94667 val_loss: 0.39759, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40852 acc: 0.94667 val_loss: 0.39585, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40676 acc: 0.94667 val_loss: 0.39414, val_acc: 0.92000\n",
      "Epoch [780/10000], loss: 0.40502 acc: 0.94667 val_loss: 0.39245, val_acc: 0.92000\n",
      "Epoch [790/10000], loss: 0.40330 acc: 0.94667 val_loss: 0.39078, val_acc: 0.92000\n",
      "Epoch [800/10000], loss: 0.40160 acc: 0.94667 val_loss: 0.38913, val_acc: 0.92000\n",
      "Epoch [810/10000], loss: 0.39993 acc: 0.94667 val_loss: 0.38751, val_acc: 0.92000\n",
      "Epoch [820/10000], loss: 0.39827 acc: 0.94667 val_loss: 0.38590, val_acc: 0.92000\n",
      "Epoch [830/10000], loss: 0.39663 acc: 0.94667 val_loss: 0.38432, val_acc: 0.92000\n",
      "Epoch [840/10000], loss: 0.39502 acc: 0.94667 val_loss: 0.38275, val_acc: 0.92000\n",
      "Epoch [850/10000], loss: 0.39342 acc: 0.94667 val_loss: 0.38121, val_acc: 0.92000\n",
      "Epoch [860/10000], loss: 0.39184 acc: 0.94667 val_loss: 0.37968, val_acc: 0.92000\n",
      "Epoch [870/10000], loss: 0.39027 acc: 0.94667 val_loss: 0.37817, val_acc: 0.92000\n",
      "Epoch [880/10000], loss: 0.38873 acc: 0.94667 val_loss: 0.37668, val_acc: 0.93333\n",
      "Epoch [890/10000], loss: 0.38720 acc: 0.94667 val_loss: 0.37521, val_acc: 0.93333\n",
      "Epoch [900/10000], loss: 0.38569 acc: 0.94667 val_loss: 0.37375, val_acc: 0.93333\n",
      "Epoch [910/10000], loss: 0.38419 acc: 0.94667 val_loss: 0.37231, val_acc: 0.93333\n",
      "Epoch [920/10000], loss: 0.38271 acc: 0.94667 val_loss: 0.37089, val_acc: 0.93333\n",
      "Epoch [930/10000], loss: 0.38125 acc: 0.94667 val_loss: 0.36948, val_acc: 0.93333\n",
      "Epoch [940/10000], loss: 0.37980 acc: 0.94667 val_loss: 0.36809, val_acc: 0.93333\n",
      "Epoch [950/10000], loss: 0.37837 acc: 0.94667 val_loss: 0.36671, val_acc: 0.93333\n",
      "Epoch [960/10000], loss: 0.37695 acc: 0.94667 val_loss: 0.36535, val_acc: 0.93333\n",
      "Epoch [970/10000], loss: 0.37554 acc: 0.94667 val_loss: 0.36400, val_acc: 0.94667\n",
      "Epoch [980/10000], loss: 0.37415 acc: 0.94667 val_loss: 0.36267, val_acc: 0.94667\n",
      "Epoch [990/10000], loss: 0.37278 acc: 0.94667 val_loss: 0.36135, val_acc: 0.94667\n",
      "Epoch [1000/10000], loss: 0.37141 acc: 0.94667 val_loss: 0.36005, val_acc: 0.94667\n",
      "Epoch [1010/10000], loss: 0.37006 acc: 0.94667 val_loss: 0.35876, val_acc: 0.94667\n",
      "Epoch [1020/10000], loss: 0.36873 acc: 0.94667 val_loss: 0.35748, val_acc: 0.94667\n",
      "Epoch [1030/10000], loss: 0.36740 acc: 0.94667 val_loss: 0.35621, val_acc: 0.94667\n",
      "Epoch [1040/10000], loss: 0.36609 acc: 0.94667 val_loss: 0.35496, val_acc: 0.94667\n",
      "Epoch [1050/10000], loss: 0.36479 acc: 0.94667 val_loss: 0.35372, val_acc: 0.94667\n",
      "Epoch [1060/10000], loss: 0.36351 acc: 0.94667 val_loss: 0.35249, val_acc: 0.94667\n",
      "Epoch [1070/10000], loss: 0.36223 acc: 0.94667 val_loss: 0.35127, val_acc: 0.94667\n",
      "Epoch [1080/10000], loss: 0.36097 acc: 0.94667 val_loss: 0.35007, val_acc: 0.94667\n",
      "Epoch [1090/10000], loss: 0.35972 acc: 0.94667 val_loss: 0.34888, val_acc: 0.94667\n",
      "Epoch [1100/10000], loss: 0.35848 acc: 0.94667 val_loss: 0.34770, val_acc: 0.94667\n",
      "Epoch [1110/10000], loss: 0.35725 acc: 0.94667 val_loss: 0.34653, val_acc: 0.94667\n",
      "Epoch [1120/10000], loss: 0.35604 acc: 0.94667 val_loss: 0.34537, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35483 acc: 0.94667 val_loss: 0.34422, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35363 acc: 0.94667 val_loss: 0.34308, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35245 acc: 0.94667 val_loss: 0.34195, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35127 acc: 0.94667 val_loss: 0.34084, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.35011 acc: 0.96000 val_loss: 0.33973, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34895 acc: 0.96000 val_loss: 0.33863, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34781 acc: 0.96000 val_loss: 0.33755, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34668 acc: 0.96000 val_loss: 0.33647, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34555 acc: 0.96000 val_loss: 0.33540, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34443 acc: 0.96000 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34333 acc: 0.96000 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34223 acc: 0.96000 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34114 acc: 0.96000 val_loss: 0.33123, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.34006 acc: 0.96000 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33899 acc: 0.96000 val_loss: 0.32919, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33793 acc: 0.96000 val_loss: 0.32819, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33688 acc: 0.96000 val_loss: 0.32719, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33583 acc: 0.96000 val_loss: 0.32620, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33480 acc: 0.96000 val_loss: 0.32522, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33377 acc: 0.96000 val_loss: 0.32425, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33275 acc: 0.96000 val_loss: 0.32329, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33174 acc: 0.96000 val_loss: 0.32233, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33073 acc: 0.96000 val_loss: 0.32139, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32974 acc: 0.96000 val_loss: 0.32045, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32875 acc: 0.96000 val_loss: 0.31951, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32777 acc: 0.96000 val_loss: 0.31859, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32679 acc: 0.96000 val_loss: 0.31767, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32583 acc: 0.96000 val_loss: 0.31676, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32487 acc: 0.96000 val_loss: 0.31586, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32392 acc: 0.96000 val_loss: 0.31496, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32297 acc: 0.96000 val_loss: 0.31407, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32204 acc: 0.96000 val_loss: 0.31319, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32111 acc: 0.96000 val_loss: 0.31232, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.32018 acc: 0.96000 val_loss: 0.31145, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31927 acc: 0.96000 val_loss: 0.31059, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31836 acc: 0.96000 val_loss: 0.30973, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31745 acc: 0.96000 val_loss: 0.30888, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31656 acc: 0.96000 val_loss: 0.30804, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31567 acc: 0.96000 val_loss: 0.30720, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31478 acc: 0.96000 val_loss: 0.30638, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31391 acc: 0.96000 val_loss: 0.30555, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31304 acc: 0.96000 val_loss: 0.30473, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31217 acc: 0.96000 val_loss: 0.30392, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31131 acc: 0.96000 val_loss: 0.30312, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.31046 acc: 0.96000 val_loss: 0.30232, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30961 acc: 0.96000 val_loss: 0.30153, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30877 acc: 0.96000 val_loss: 0.30074, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30794 acc: 0.96000 val_loss: 0.29996, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30711 acc: 0.96000 val_loss: 0.29918, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30629 acc: 0.96000 val_loss: 0.29841, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30547 acc: 0.96000 val_loss: 0.29764, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30466 acc: 0.96000 val_loss: 0.29688, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30385 acc: 0.96000 val_loss: 0.29613, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30305 acc: 0.96000 val_loss: 0.29538, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30225 acc: 0.96000 val_loss: 0.29464, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30146 acc: 0.96000 val_loss: 0.29390, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30068 acc: 0.96000 val_loss: 0.29317, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29990 acc: 0.96000 val_loss: 0.29244, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29913 acc: 0.96000 val_loss: 0.29171, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29836 acc: 0.96000 val_loss: 0.29100, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29759 acc: 0.96000 val_loss: 0.29028, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29684 acc: 0.96000 val_loss: 0.28957, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29608 acc: 0.96000 val_loss: 0.28887, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29533 acc: 0.96000 val_loss: 0.28817, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29459 acc: 0.96000 val_loss: 0.28748, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29385 acc: 0.96000 val_loss: 0.28679, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29312 acc: 0.96000 val_loss: 0.28610, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29239 acc: 0.96000 val_loss: 0.28542, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29166 acc: 0.96000 val_loss: 0.28475, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29094 acc: 0.96000 val_loss: 0.28408, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.29023 acc: 0.96000 val_loss: 0.28341, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28951 acc: 0.96000 val_loss: 0.28275, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28881 acc: 0.96000 val_loss: 0.28209, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28811 acc: 0.96000 val_loss: 0.28144, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28741 acc: 0.96000 val_loss: 0.28079, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28672 acc: 0.96000 val_loss: 0.28014, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28603 acc: 0.96000 val_loss: 0.27950, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28534 acc: 0.96000 val_loss: 0.27887, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28466 acc: 0.96000 val_loss: 0.27823, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28399 acc: 0.96000 val_loss: 0.27761, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28332 acc: 0.96000 val_loss: 0.27698, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28265 acc: 0.96000 val_loss: 0.27636, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28198 acc: 0.96000 val_loss: 0.27575, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28133 acc: 0.96000 val_loss: 0.27513, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.28067 acc: 0.96000 val_loss: 0.27452, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.28002 acc: 0.96000 val_loss: 0.27392, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27937 acc: 0.96000 val_loss: 0.27332, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27873 acc: 0.96000 val_loss: 0.27272, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27809 acc: 0.96000 val_loss: 0.27213, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27745 acc: 0.96000 val_loss: 0.27154, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27682 acc: 0.96000 val_loss: 0.27095, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27619 acc: 0.96000 val_loss: 0.27037, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27557 acc: 0.96000 val_loss: 0.26979, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27495 acc: 0.96000 val_loss: 0.26922, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27433 acc: 0.96000 val_loss: 0.26864, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27372 acc: 0.96000 val_loss: 0.26808, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27311 acc: 0.96000 val_loss: 0.26751, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27250 acc: 0.96000 val_loss: 0.26695, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27190 acc: 0.96000 val_loss: 0.26639, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27130 acc: 0.96000 val_loss: 0.26584, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.27071 acc: 0.96000 val_loss: 0.26529, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.27011 acc: 0.96000 val_loss: 0.26474, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26952 acc: 0.96000 val_loss: 0.26419, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26894 acc: 0.96000 val_loss: 0.26365, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26836 acc: 0.96000 val_loss: 0.26311, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26778 acc: 0.96000 val_loss: 0.26258, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26720 acc: 0.96000 val_loss: 0.26205, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26663 acc: 0.96000 val_loss: 0.26152, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26606 acc: 0.96000 val_loss: 0.26099, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26550 acc: 0.96000 val_loss: 0.26047, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26494 acc: 0.96000 val_loss: 0.25995, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26438 acc: 0.96000 val_loss: 0.25944, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26382 acc: 0.96000 val_loss: 0.25892, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26327 acc: 0.96000 val_loss: 0.25841, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26272 acc: 0.96000 val_loss: 0.25790, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26217 acc: 0.96000 val_loss: 0.25740, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26163 acc: 0.96000 val_loss: 0.25690, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26109 acc: 0.96000 val_loss: 0.25640, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.26055 acc: 0.96000 val_loss: 0.25590, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.26002 acc: 0.96000 val_loss: 0.25541, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25948 acc: 0.96000 val_loss: 0.25492, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25896 acc: 0.96000 val_loss: 0.25443, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25843 acc: 0.96000 val_loss: 0.25395, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25791 acc: 0.96000 val_loss: 0.25347, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25739 acc: 0.96000 val_loss: 0.25299, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25687 acc: 0.96000 val_loss: 0.25251, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25635 acc: 0.96000 val_loss: 0.25204, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25584 acc: 0.96000 val_loss: 0.25156, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25533 acc: 0.96000 val_loss: 0.25110, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25483 acc: 0.96000 val_loss: 0.25063, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25432 acc: 0.96000 val_loss: 0.25017, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25382 acc: 0.96000 val_loss: 0.24971, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25332 acc: 0.96000 val_loss: 0.24925, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25283 acc: 0.96000 val_loss: 0.24879, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25234 acc: 0.96000 val_loss: 0.24834, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25185 acc: 0.96000 val_loss: 0.24789, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25136 acc: 0.96000 val_loss: 0.24744, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25087 acc: 0.96000 val_loss: 0.24699, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.25039 acc: 0.96000 val_loss: 0.24655, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24991 acc: 0.96000 val_loss: 0.24611, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24943 acc: 0.96000 val_loss: 0.24567, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24896 acc: 0.96000 val_loss: 0.24523, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24848 acc: 0.96000 val_loss: 0.24480, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24801 acc: 0.96000 val_loss: 0.24437, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24755 acc: 0.96000 val_loss: 0.24394, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24708 acc: 0.96000 val_loss: 0.24351, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24662 acc: 0.96000 val_loss: 0.24308, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24616 acc: 0.96000 val_loss: 0.24266, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24570 acc: 0.96000 val_loss: 0.24224, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24524 acc: 0.96000 val_loss: 0.24182, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24479 acc: 0.96000 val_loss: 0.24141, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24434 acc: 0.96000 val_loss: 0.24099, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24389 acc: 0.96000 val_loss: 0.24058, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24344 acc: 0.97333 val_loss: 0.24017, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24300 acc: 0.97333 val_loss: 0.23976, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24256 acc: 0.97333 val_loss: 0.23936, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24212 acc: 0.97333 val_loss: 0.23895, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24168 acc: 0.97333 val_loss: 0.23855, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24124 acc: 0.97333 val_loss: 0.23815, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24081 acc: 0.97333 val_loss: 0.23776, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.24038 acc: 0.97333 val_loss: 0.23736, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23995 acc: 0.97333 val_loss: 0.23697, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23952 acc: 0.97333 val_loss: 0.23658, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23909 acc: 0.97333 val_loss: 0.23619, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23867 acc: 0.97333 val_loss: 0.23580, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23825 acc: 0.97333 val_loss: 0.23542, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23783 acc: 0.97333 val_loss: 0.23503, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23742 acc: 0.97333 val_loss: 0.23465, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23700 acc: 0.97333 val_loss: 0.23427, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23659 acc: 0.97333 val_loss: 0.23389, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23618 acc: 0.97333 val_loss: 0.23352, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23577 acc: 0.97333 val_loss: 0.23314, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23536 acc: 0.97333 val_loss: 0.23277, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23496 acc: 0.97333 val_loss: 0.23240, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23455 acc: 0.97333 val_loss: 0.23203, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23415 acc: 0.97333 val_loss: 0.23167, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23375 acc: 0.97333 val_loss: 0.23130, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23335 acc: 0.97333 val_loss: 0.23094, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23296 acc: 0.97333 val_loss: 0.23058, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23257 acc: 0.97333 val_loss: 0.23022, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23217 acc: 0.97333 val_loss: 0.22986, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23178 acc: 0.97333 val_loss: 0.22951, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23140 acc: 0.97333 val_loss: 0.22915, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23101 acc: 0.97333 val_loss: 0.22880, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.23063 acc: 0.97333 val_loss: 0.22845, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.23024 acc: 0.97333 val_loss: 0.22810, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22986 acc: 0.97333 val_loss: 0.22775, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22948 acc: 0.97333 val_loss: 0.22741, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22911 acc: 0.97333 val_loss: 0.22706, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22873 acc: 0.97333 val_loss: 0.22672, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22836 acc: 0.97333 val_loss: 0.22638, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22798 acc: 0.97333 val_loss: 0.22604, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22761 acc: 0.97333 val_loss: 0.22570, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22724 acc: 0.97333 val_loss: 0.22537, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22688 acc: 0.97333 val_loss: 0.22503, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22651 acc: 0.97333 val_loss: 0.22470, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22615 acc: 0.97333 val_loss: 0.22437, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22579 acc: 0.97333 val_loss: 0.22404, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22543 acc: 0.97333 val_loss: 0.22371, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22507 acc: 0.97333 val_loss: 0.22338, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22471 acc: 0.97333 val_loss: 0.22306, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22435 acc: 0.97333 val_loss: 0.22273, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22400 acc: 0.97333 val_loss: 0.22241, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22365 acc: 0.97333 val_loss: 0.22209, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22330 acc: 0.97333 val_loss: 0.22177, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22295 acc: 0.97333 val_loss: 0.22145, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22260 acc: 0.97333 val_loss: 0.22114, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22225 acc: 0.97333 val_loss: 0.22082, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22191 acc: 0.97333 val_loss: 0.22051, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22156 acc: 0.97333 val_loss: 0.22020, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22122 acc: 0.97333 val_loss: 0.21989, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22088 acc: 0.97333 val_loss: 0.21958, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.22054 acc: 0.97333 val_loss: 0.21927, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.22021 acc: 0.97333 val_loss: 0.21896, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21987 acc: 0.97333 val_loss: 0.21866, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21954 acc: 0.97333 val_loss: 0.21836, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21920 acc: 0.97333 val_loss: 0.21805, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21887 acc: 0.97333 val_loss: 0.21775, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21854 acc: 0.97333 val_loss: 0.21745, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21821 acc: 0.97333 val_loss: 0.21715, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21789 acc: 0.97333 val_loss: 0.21686, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21756 acc: 0.97333 val_loss: 0.21656, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21724 acc: 0.97333 val_loss: 0.21627, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21691 acc: 0.97333 val_loss: 0.21597, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21659 acc: 0.97333 val_loss: 0.21568, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21627 acc: 0.97333 val_loss: 0.21539, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21595 acc: 0.97333 val_loss: 0.21510, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21563 acc: 0.97333 val_loss: 0.21482, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21532 acc: 0.97333 val_loss: 0.21453, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21500 acc: 0.97333 val_loss: 0.21424, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21469 acc: 0.97333 val_loss: 0.21396, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21438 acc: 0.97333 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21407 acc: 0.97333 val_loss: 0.21339, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21376 acc: 0.97333 val_loss: 0.21311, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21345 acc: 0.97333 val_loss: 0.21283, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21314 acc: 0.97333 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21284 acc: 0.97333 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21253 acc: 0.97333 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21223 acc: 0.97333 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21193 acc: 0.97333 val_loss: 0.21146, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21163 acc: 0.97333 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21133 acc: 0.97333 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21103 acc: 0.97333 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.21073 acc: 0.97333 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.21043 acc: 0.97333 val_loss: 0.21011, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.21014 acc: 0.97333 val_loss: 0.20984, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20985 acc: 0.97333 val_loss: 0.20958, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20955 acc: 0.97333 val_loss: 0.20931, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20926 acc: 0.97333 val_loss: 0.20905, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20897 acc: 0.97333 val_loss: 0.20879, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20868 acc: 0.97333 val_loss: 0.20852, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20840 acc: 0.97333 val_loss: 0.20826, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20811 acc: 0.98667 val_loss: 0.20801, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20782 acc: 0.98667 val_loss: 0.20775, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20754 acc: 0.98667 val_loss: 0.20749, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20726 acc: 0.98667 val_loss: 0.20724, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20698 acc: 0.98667 val_loss: 0.20698, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20669 acc: 0.98667 val_loss: 0.20673, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20641 acc: 0.98667 val_loss: 0.20648, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20614 acc: 0.98667 val_loss: 0.20622, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20586 acc: 0.98667 val_loss: 0.20597, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20558 acc: 0.98667 val_loss: 0.20572, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20531 acc: 0.98667 val_loss: 0.20548, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20503 acc: 0.98667 val_loss: 0.20523, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20476 acc: 0.98667 val_loss: 0.20498, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20449 acc: 0.98667 val_loss: 0.20474, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20422 acc: 0.98667 val_loss: 0.20449, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20395 acc: 0.98667 val_loss: 0.20425, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20368 acc: 0.98667 val_loss: 0.20401, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20341 acc: 0.98667 val_loss: 0.20377, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20314 acc: 0.98667 val_loss: 0.20353, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20288 acc: 0.98667 val_loss: 0.20329, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20261 acc: 0.98667 val_loss: 0.20305, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20235 acc: 0.98667 val_loss: 0.20281, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20209 acc: 0.98667 val_loss: 0.20257, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20182 acc: 0.98667 val_loss: 0.20234, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20156 acc: 0.98667 val_loss: 0.20210, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20130 acc: 0.98667 val_loss: 0.20187, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20104 acc: 0.98667 val_loss: 0.20164, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20079 acc: 0.98667 val_loss: 0.20140, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.20053 acc: 0.98667 val_loss: 0.20117, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.20027 acc: 0.98667 val_loss: 0.20094, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.20002 acc: 0.98667 val_loss: 0.20071, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19976 acc: 0.98667 val_loss: 0.20048, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19951 acc: 0.98667 val_loss: 0.20026, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19926 acc: 0.98667 val_loss: 0.20003, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19901 acc: 0.98667 val_loss: 0.19980, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19876 acc: 0.98667 val_loss: 0.19958, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19851 acc: 0.98667 val_loss: 0.19936, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19826 acc: 0.98667 val_loss: 0.19913, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19801 acc: 0.98667 val_loss: 0.19891, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19869, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19847, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19825, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19803, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19781, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19655 acc: 0.98667 val_loss: 0.19759, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19631 acc: 0.98667 val_loss: 0.19738, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19607 acc: 0.98667 val_loss: 0.19716, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19583 acc: 0.98667 val_loss: 0.19695, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19559 acc: 0.98667 val_loss: 0.19673, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19535 acc: 0.98667 val_loss: 0.19652, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19511 acc: 0.98667 val_loss: 0.19631, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19488 acc: 0.98667 val_loss: 0.19610, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19464 acc: 0.98667 val_loss: 0.19589, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19441 acc: 0.98667 val_loss: 0.19568, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19418 acc: 0.98667 val_loss: 0.19547, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19394 acc: 0.98667 val_loss: 0.19526, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19371 acc: 0.98667 val_loss: 0.19505, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19348 acc: 0.98667 val_loss: 0.19484, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19325 acc: 0.98667 val_loss: 0.19464, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19302 acc: 0.98667 val_loss: 0.19443, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19279 acc: 0.98667 val_loss: 0.19423, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19257 acc: 0.98667 val_loss: 0.19402, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19234 acc: 0.98667 val_loss: 0.19382, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19211 acc: 0.98667 val_loss: 0.19362, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19189 acc: 0.98667 val_loss: 0.19342, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19166 acc: 0.98667 val_loss: 0.19322, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19144 acc: 0.98667 val_loss: 0.19302, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19122 acc: 0.98667 val_loss: 0.19282, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19100 acc: 0.98667 val_loss: 0.19262, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19077 acc: 0.98667 val_loss: 0.19242, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.19055 acc: 0.98667 val_loss: 0.19222, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.19033 acc: 0.98667 val_loss: 0.19203, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.19012 acc: 0.98667 val_loss: 0.19183, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18990 acc: 0.98667 val_loss: 0.19164, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18968 acc: 0.98667 val_loss: 0.19144, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18946 acc: 0.98667 val_loss: 0.19125, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18925 acc: 0.98667 val_loss: 0.19105, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18903 acc: 0.98667 val_loss: 0.19086, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18882 acc: 0.98667 val_loss: 0.19067, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18860 acc: 0.98667 val_loss: 0.19048, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18839 acc: 0.98667 val_loss: 0.19029, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18818 acc: 0.98667 val_loss: 0.19010, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18797 acc: 0.98667 val_loss: 0.18991, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18776 acc: 0.98667 val_loss: 0.18972, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18755 acc: 0.98667 val_loss: 0.18953, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18734 acc: 0.98667 val_loss: 0.18935, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18713 acc: 0.98667 val_loss: 0.18916, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18692 acc: 0.98667 val_loss: 0.18898, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18671 acc: 0.98667 val_loss: 0.18879, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18651 acc: 0.98667 val_loss: 0.18861, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18630 acc: 0.98667 val_loss: 0.18842, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18610 acc: 0.98667 val_loss: 0.18824, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18589 acc: 0.98667 val_loss: 0.18806, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18569 acc: 0.98667 val_loss: 0.18788, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18549 acc: 0.98667 val_loss: 0.18769, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18528 acc: 0.98667 val_loss: 0.18751, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18508 acc: 0.98667 val_loss: 0.18733, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18488 acc: 0.98667 val_loss: 0.18716, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18468 acc: 0.98667 val_loss: 0.18698, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18448 acc: 0.98667 val_loss: 0.18680, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18428 acc: 0.98667 val_loss: 0.18662, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18408 acc: 0.98667 val_loss: 0.18644, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18388 acc: 0.98667 val_loss: 0.18627, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18369 acc: 0.98667 val_loss: 0.18609, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18349 acc: 0.98667 val_loss: 0.18592, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18330 acc: 0.98667 val_loss: 0.18574, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18310 acc: 0.98667 val_loss: 0.18557, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18291 acc: 0.98667 val_loss: 0.18540, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18271 acc: 0.98667 val_loss: 0.18522, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18252 acc: 0.98667 val_loss: 0.18505, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18233 acc: 0.98667 val_loss: 0.18488, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18213 acc: 0.98667 val_loss: 0.18471, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18194 acc: 0.98667 val_loss: 0.18454, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18175 acc: 0.98667 val_loss: 0.18437, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18156 acc: 0.98667 val_loss: 0.18420, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18137 acc: 0.98667 val_loss: 0.18403, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18118 acc: 0.98667 val_loss: 0.18386, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18100 acc: 0.98667 val_loss: 0.18370, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18081 acc: 0.98667 val_loss: 0.18353, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.18062 acc: 0.98667 val_loss: 0.18336, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.18043 acc: 0.98667 val_loss: 0.18320, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.18025 acc: 0.98667 val_loss: 0.18303, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.18006 acc: 0.98667 val_loss: 0.18287, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17988 acc: 0.98667 val_loss: 0.18270, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17969 acc: 0.98667 val_loss: 0.18254, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17951 acc: 0.98667 val_loss: 0.18238, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17933 acc: 0.98667 val_loss: 0.18221, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17914 acc: 0.98667 val_loss: 0.18205, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17896 acc: 0.98667 val_loss: 0.18189, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17878 acc: 0.98667 val_loss: 0.18173, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17860 acc: 0.98667 val_loss: 0.18157, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17842 acc: 0.98667 val_loss: 0.18141, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17824 acc: 0.98667 val_loss: 0.18125, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17806 acc: 0.98667 val_loss: 0.18109, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17788 acc: 0.98667 val_loss: 0.18093, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17771 acc: 0.98667 val_loss: 0.18078, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17753 acc: 0.98667 val_loss: 0.18062, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17735 acc: 0.98667 val_loss: 0.18046, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17718 acc: 0.98667 val_loss: 0.18031, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17700 acc: 0.98667 val_loss: 0.18015, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17683 acc: 0.98667 val_loss: 0.17999, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17665 acc: 0.98667 val_loss: 0.17984, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17648 acc: 0.98667 val_loss: 0.17969, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17630 acc: 0.98667 val_loss: 0.17953, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17613 acc: 0.98667 val_loss: 0.17938, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17596 acc: 0.98667 val_loss: 0.17923, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17579 acc: 0.98667 val_loss: 0.17907, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17561 acc: 0.98667 val_loss: 0.17892, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17544 acc: 0.98667 val_loss: 0.17877, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17527 acc: 0.98667 val_loss: 0.17862, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17510 acc: 0.98667 val_loss: 0.17847, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17493 acc: 0.98667 val_loss: 0.17832, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17477 acc: 0.98667 val_loss: 0.17817, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17460 acc: 0.98667 val_loss: 0.17802, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17443 acc: 0.98667 val_loss: 0.17787, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17426 acc: 0.98667 val_loss: 0.17772, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17758, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17743, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17376 acc: 0.98667 val_loss: 0.17728, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17714, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17699, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17685, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17311 acc: 0.98667 val_loss: 0.17670, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17656, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17278 acc: 0.98667 val_loss: 0.17641, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17262 acc: 0.98667 val_loss: 0.17627, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17613, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17229 acc: 0.98667 val_loss: 0.17598, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17213 acc: 0.98667 val_loss: 0.17584, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17197 acc: 0.98667 val_loss: 0.17570, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17181 acc: 0.98667 val_loss: 0.17556, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17165 acc: 0.98667 val_loss: 0.17542, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17149 acc: 0.98667 val_loss: 0.17528, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17133 acc: 0.98667 val_loss: 0.17514, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17118 acc: 0.98667 val_loss: 0.17500, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17102 acc: 0.98667 val_loss: 0.17486, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17086 acc: 0.98667 val_loss: 0.17472, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17071 acc: 0.98667 val_loss: 0.17458, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.17055 acc: 0.98667 val_loss: 0.17444, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.17039 acc: 0.98667 val_loss: 0.17431, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.17024 acc: 0.98667 val_loss: 0.17417, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.17008 acc: 0.98667 val_loss: 0.17403, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16993 acc: 0.98667 val_loss: 0.17390, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16977 acc: 0.98667 val_loss: 0.17376, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16962 acc: 0.98667 val_loss: 0.17363, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16947 acc: 0.98667 val_loss: 0.17349, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16932 acc: 0.98667 val_loss: 0.17336, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16916 acc: 0.98667 val_loss: 0.17322, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16901 acc: 0.98667 val_loss: 0.17309, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16886 acc: 0.98667 val_loss: 0.17296, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16871 acc: 0.98667 val_loss: 0.17282, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16856 acc: 0.98667 val_loss: 0.17269, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16841 acc: 0.98667 val_loss: 0.17256, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16826 acc: 0.98667 val_loss: 0.17243, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16811 acc: 0.98667 val_loss: 0.17229, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16796 acc: 0.98667 val_loss: 0.17216, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16781 acc: 0.98667 val_loss: 0.17203, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16766 acc: 0.98667 val_loss: 0.17190, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16752 acc: 0.98667 val_loss: 0.17177, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16737 acc: 0.98667 val_loss: 0.17164, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16722 acc: 0.98667 val_loss: 0.17151, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16708 acc: 0.98667 val_loss: 0.17139, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16693 acc: 0.98667 val_loss: 0.17126, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16679 acc: 0.98667 val_loss: 0.17113, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16664 acc: 0.98667 val_loss: 0.17100, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16650 acc: 0.98667 val_loss: 0.17087, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16635 acc: 0.98667 val_loss: 0.17075, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16621 acc: 0.98667 val_loss: 0.17062, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16606 acc: 0.98667 val_loss: 0.17050, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16592 acc: 0.98667 val_loss: 0.17037, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16578 acc: 0.98667 val_loss: 0.17024, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16564 acc: 0.98667 val_loss: 0.17012, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16549 acc: 0.98667 val_loss: 0.16999, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16535 acc: 0.98667 val_loss: 0.16987, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16521 acc: 0.98667 val_loss: 0.16975, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16507 acc: 0.98667 val_loss: 0.16962, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16493 acc: 0.98667 val_loss: 0.16950, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16479 acc: 0.98667 val_loss: 0.16938, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16465 acc: 0.98667 val_loss: 0.16925, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16451 acc: 0.98667 val_loss: 0.16913, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16437 acc: 0.98667 val_loss: 0.16901, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16423 acc: 0.98667 val_loss: 0.16889, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16410 acc: 0.98667 val_loss: 0.16877, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16396 acc: 0.98667 val_loss: 0.16865, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16382 acc: 0.98667 val_loss: 0.16853, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16368 acc: 0.98667 val_loss: 0.16841, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16355 acc: 0.98667 val_loss: 0.16829, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16341 acc: 0.98667 val_loss: 0.16817, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16328 acc: 0.98667 val_loss: 0.16805, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16314 acc: 0.98667 val_loss: 0.16793, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16301 acc: 0.98667 val_loss: 0.16781, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16287 acc: 0.98667 val_loss: 0.16769, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16274 acc: 0.98667 val_loss: 0.16758, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16260 acc: 0.98667 val_loss: 0.16746, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16247 acc: 0.98667 val_loss: 0.16734, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16233 acc: 0.98667 val_loss: 0.16722, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16220 acc: 0.98667 val_loss: 0.16711, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16207 acc: 0.98667 val_loss: 0.16699, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16194 acc: 0.98667 val_loss: 0.16688, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16181 acc: 0.98667 val_loss: 0.16676, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16167 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16154 acc: 0.98667 val_loss: 0.16653, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16141 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16128 acc: 0.98667 val_loss: 0.16630, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16115 acc: 0.98667 val_loss: 0.16619, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16102 acc: 0.98667 val_loss: 0.16607, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16089 acc: 0.98667 val_loss: 0.16596, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16076 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16063 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.16051 acc: 0.98667 val_loss: 0.16562, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.16038 acc: 0.98667 val_loss: 0.16551, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.16025 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.16012 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15999 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15987 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15974 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15962 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15949 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15936 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15924 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15911 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15899 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15887 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15874 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15862 acc: 0.98667 val_loss: 0.16397, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15849 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15837 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15825 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15813 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15800 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15788 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15776 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15764 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15752 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15740 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15728 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15716 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15704 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15692 acc: 0.98667 val_loss: 0.16250, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15680 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15668 acc: 0.98667 val_loss: 0.16229, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15656 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15633 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15621 acc: 0.98667 val_loss: 0.16188, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15609 acc: 0.98667 val_loss: 0.16178, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15574 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16137, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16127, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16117, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16107, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15517 acc: 0.98667 val_loss: 0.16097, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16087, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15494 acc: 0.98667 val_loss: 0.16077, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16067, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15471 acc: 0.98667 val_loss: 0.16057, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15460 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16038, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15437 acc: 0.98667 val_loss: 0.16028, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15426 acc: 0.98667 val_loss: 0.16018, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15415 acc: 0.98667 val_loss: 0.16008, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15403 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15392 acc: 0.98667 val_loss: 0.15989, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15381 acc: 0.98667 val_loss: 0.15979, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15370 acc: 0.98667 val_loss: 0.15969, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15359 acc: 0.98667 val_loss: 0.15960, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15348 acc: 0.98667 val_loss: 0.15950, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15337 acc: 0.98667 val_loss: 0.15941, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15326 acc: 0.98667 val_loss: 0.15931, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15315 acc: 0.98667 val_loss: 0.15921, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15304 acc: 0.98667 val_loss: 0.15912, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15293 acc: 0.98667 val_loss: 0.15902, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15282 acc: 0.98667 val_loss: 0.15893, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15271 acc: 0.98667 val_loss: 0.15883, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15260 acc: 0.98667 val_loss: 0.15874, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15249 acc: 0.98667 val_loss: 0.15865, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15238 acc: 0.98667 val_loss: 0.15855, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15228 acc: 0.98667 val_loss: 0.15846, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15217 acc: 0.98667 val_loss: 0.15837, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15206 acc: 0.98667 val_loss: 0.15827, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15195 acc: 0.98667 val_loss: 0.15818, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15185 acc: 0.98667 val_loss: 0.15809, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15174 acc: 0.98667 val_loss: 0.15800, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15163 acc: 0.98667 val_loss: 0.15790, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15153 acc: 0.98667 val_loss: 0.15781, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15142 acc: 0.98667 val_loss: 0.15772, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15132 acc: 0.98667 val_loss: 0.15763, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15121 acc: 0.98667 val_loss: 0.15754, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15111 acc: 0.98667 val_loss: 0.15745, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15100 acc: 0.98667 val_loss: 0.15736, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15090 acc: 0.98667 val_loss: 0.15726, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15079 acc: 0.98667 val_loss: 0.15717, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15069 acc: 0.98667 val_loss: 0.15708, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15058 acc: 0.98667 val_loss: 0.15699, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.15048 acc: 0.98667 val_loss: 0.15691, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.15038 acc: 0.98667 val_loss: 0.15682, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.15027 acc: 0.98667 val_loss: 0.15673, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.15017 acc: 0.98667 val_loss: 0.15664, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.15007 acc: 0.98667 val_loss: 0.15655, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14997 acc: 0.98667 val_loss: 0.15646, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14986 acc: 0.98667 val_loss: 0.15637, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14976 acc: 0.98667 val_loss: 0.15628, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14966 acc: 0.98667 val_loss: 0.15620, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14956 acc: 0.98667 val_loss: 0.15611, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14946 acc: 0.98667 val_loss: 0.15602, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14936 acc: 0.98667 val_loss: 0.15593, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14926 acc: 0.98667 val_loss: 0.15585, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14915 acc: 0.98667 val_loss: 0.15576, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14905 acc: 0.98667 val_loss: 0.15567, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14895 acc: 0.98667 val_loss: 0.15559, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14885 acc: 0.98667 val_loss: 0.15550, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14875 acc: 0.98667 val_loss: 0.15541, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14866 acc: 0.98667 val_loss: 0.15533, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14856 acc: 0.98667 val_loss: 0.15524, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14846 acc: 0.98667 val_loss: 0.15516, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14836 acc: 0.98667 val_loss: 0.15507, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14826 acc: 0.98667 val_loss: 0.15499, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14816 acc: 0.98667 val_loss: 0.15490, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14806 acc: 0.98667 val_loss: 0.15482, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14797 acc: 0.98667 val_loss: 0.15473, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14787 acc: 0.98667 val_loss: 0.15465, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14777 acc: 0.98667 val_loss: 0.15457, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14767 acc: 0.98667 val_loss: 0.15448, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14758 acc: 0.98667 val_loss: 0.15440, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14748 acc: 0.98667 val_loss: 0.15431, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14738 acc: 0.98667 val_loss: 0.15423, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14729 acc: 0.98667 val_loss: 0.15415, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14719 acc: 0.98667 val_loss: 0.15407, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14709 acc: 0.98667 val_loss: 0.15398, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14700 acc: 0.98667 val_loss: 0.15390, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14690 acc: 0.98667 val_loss: 0.15382, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14681 acc: 0.98667 val_loss: 0.15374, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14671 acc: 0.98667 val_loss: 0.15365, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14662 acc: 0.98667 val_loss: 0.15357, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14652 acc: 0.98667 val_loss: 0.15349, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14643 acc: 0.98667 val_loss: 0.15341, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14633 acc: 0.98667 val_loss: 0.15333, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14624 acc: 0.98667 val_loss: 0.15325, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14615 acc: 0.98667 val_loss: 0.15317, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14605 acc: 0.98667 val_loss: 0.15309, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14596 acc: 0.98667 val_loss: 0.15301, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14587 acc: 0.98667 val_loss: 0.15293, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14577 acc: 0.98667 val_loss: 0.15285, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14568 acc: 0.98667 val_loss: 0.15277, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14559 acc: 0.98667 val_loss: 0.15269, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14550 acc: 0.98667 val_loss: 0.15261, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14540 acc: 0.98667 val_loss: 0.15253, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14531 acc: 0.98667 val_loss: 0.15245, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14522 acc: 0.98667 val_loss: 0.15237, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14513 acc: 0.98667 val_loss: 0.15229, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14504 acc: 0.98667 val_loss: 0.15221, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14495 acc: 0.98667 val_loss: 0.15213, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14485 acc: 0.98667 val_loss: 0.15206, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14476 acc: 0.98667 val_loss: 0.15198, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14467 acc: 0.98667 val_loss: 0.15190, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14458 acc: 0.98667 val_loss: 0.15182, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14449 acc: 0.98667 val_loss: 0.15175, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14440 acc: 0.98667 val_loss: 0.15167, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14431 acc: 0.98667 val_loss: 0.15159, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14422 acc: 0.98667 val_loss: 0.15151, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14413 acc: 0.98667 val_loss: 0.15144, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14404 acc: 0.98667 val_loss: 0.15136, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14395 acc: 0.98667 val_loss: 0.15129, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14387 acc: 0.98667 val_loss: 0.15121, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14378 acc: 0.98667 val_loss: 0.15113, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14369 acc: 0.98667 val_loss: 0.15106, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14360 acc: 0.98667 val_loss: 0.15098, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14351 acc: 0.98667 val_loss: 0.15091, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14342 acc: 0.98667 val_loss: 0.15083, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14334 acc: 0.98667 val_loss: 0.15076, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14325 acc: 0.98667 val_loss: 0.15068, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14316 acc: 0.98667 val_loss: 0.15061, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14307 acc: 0.98667 val_loss: 0.15053, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14299 acc: 0.98667 val_loss: 0.15046, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14290 acc: 0.98667 val_loss: 0.15038, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14281 acc: 0.98667 val_loss: 0.15031, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14273 acc: 0.98667 val_loss: 0.15023, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14264 acc: 0.98667 val_loss: 0.15016, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15009, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14247 acc: 0.98667 val_loss: 0.15001, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14238 acc: 0.98667 val_loss: 0.14994, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.14987, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14221 acc: 0.98667 val_loss: 0.14979, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14972, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14204 acc: 0.98667 val_loss: 0.14965, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14957, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14187 acc: 0.98667 val_loss: 0.14950, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14943, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14170 acc: 0.98667 val_loss: 0.14936, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14929, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14921, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14914, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14907, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14129 acc: 0.98667 val_loss: 0.14900, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14893, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14886, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14104 acc: 0.98667 val_loss: 0.14879, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14872, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14865, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14079 acc: 0.98667 val_loss: 0.14858, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14071 acc: 0.98667 val_loss: 0.14851, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14844, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14837, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.14046 acc: 0.98667 val_loss: 0.14830, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.14038 acc: 0.98667 val_loss: 0.14823, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.14030 acc: 0.98667 val_loss: 0.14816, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.14022 acc: 0.98667 val_loss: 0.14809, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14802, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.14005 acc: 0.98667 val_loss: 0.14795, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13997 acc: 0.98667 val_loss: 0.14788, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13989 acc: 0.98667 val_loss: 0.14781, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13981 acc: 0.98667 val_loss: 0.14774, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13973 acc: 0.98667 val_loss: 0.14767, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13965 acc: 0.98667 val_loss: 0.14761, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13957 acc: 0.98667 val_loss: 0.14754, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13949 acc: 0.98667 val_loss: 0.14747, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13941 acc: 0.98667 val_loss: 0.14740, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13933 acc: 0.98667 val_loss: 0.14733, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13925 acc: 0.98667 val_loss: 0.14727, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13917 acc: 0.98667 val_loss: 0.14720, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13910 acc: 0.98667 val_loss: 0.14713, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13902 acc: 0.98667 val_loss: 0.14707, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13894 acc: 0.98667 val_loss: 0.14700, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13886 acc: 0.98667 val_loss: 0.14693, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13878 acc: 0.98667 val_loss: 0.14687, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13870 acc: 0.98667 val_loss: 0.14680, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13862 acc: 0.98667 val_loss: 0.14673, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13855 acc: 0.98667 val_loss: 0.14667, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13847 acc: 0.98667 val_loss: 0.14660, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13839 acc: 0.98667 val_loss: 0.14653, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13831 acc: 0.98667 val_loss: 0.14647, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13824 acc: 0.98667 val_loss: 0.14640, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13816 acc: 0.98667 val_loss: 0.14634, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13808 acc: 0.98667 val_loss: 0.14627, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13801 acc: 0.98667 val_loss: 0.14621, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13793 acc: 0.98667 val_loss: 0.14614, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13785 acc: 0.98667 val_loss: 0.14608, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13778 acc: 0.98667 val_loss: 0.14601, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13770 acc: 0.98667 val_loss: 0.14595, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13762 acc: 0.98667 val_loss: 0.14588, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13755 acc: 0.98667 val_loss: 0.14582, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13747 acc: 0.98667 val_loss: 0.14575, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13740 acc: 0.98667 val_loss: 0.14569, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13732 acc: 0.98667 val_loss: 0.14562, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13725 acc: 0.98667 val_loss: 0.14556, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13717 acc: 0.98667 val_loss: 0.14550, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13710 acc: 0.98667 val_loss: 0.14543, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13702 acc: 0.98667 val_loss: 0.14537, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13695 acc: 0.98667 val_loss: 0.14531, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13687 acc: 0.98667 val_loss: 0.14524, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13680 acc: 0.98667 val_loss: 0.14518, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13672 acc: 0.98667 val_loss: 0.14512, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13665 acc: 0.98667 val_loss: 0.14505, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13657 acc: 0.98667 val_loss: 0.14499, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13650 acc: 0.98667 val_loss: 0.14493, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13643 acc: 0.98667 val_loss: 0.14487, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13635 acc: 0.98667 val_loss: 0.14480, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13628 acc: 0.98667 val_loss: 0.14474, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13621 acc: 0.98667 val_loss: 0.14468, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13613 acc: 0.98667 val_loss: 0.14462, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13606 acc: 0.98667 val_loss: 0.14456, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13599 acc: 0.98667 val_loss: 0.14449, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13591 acc: 0.98667 val_loss: 0.14443, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13584 acc: 0.98667 val_loss: 0.14437, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13577 acc: 0.98667 val_loss: 0.14431, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13570 acc: 0.98667 val_loss: 0.14425, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13562 acc: 0.98667 val_loss: 0.14419, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13555 acc: 0.98667 val_loss: 0.14413, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13548 acc: 0.98667 val_loss: 0.14406, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13541 acc: 0.98667 val_loss: 0.14400, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13534 acc: 0.98667 val_loss: 0.14394, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13527 acc: 0.98667 val_loss: 0.14388, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13519 acc: 0.98667 val_loss: 0.14382, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13512 acc: 0.98667 val_loss: 0.14376, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13505 acc: 0.98667 val_loss: 0.14370, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13498 acc: 0.98667 val_loss: 0.14364, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13491 acc: 0.98667 val_loss: 0.14358, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13484 acc: 0.98667 val_loss: 0.14352, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13477 acc: 0.98667 val_loss: 0.14346, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13470 acc: 0.98667 val_loss: 0.14340, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13463 acc: 0.98667 val_loss: 0.14334, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13456 acc: 0.98667 val_loss: 0.14328, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13449 acc: 0.98667 val_loss: 0.14323, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13442 acc: 0.98667 val_loss: 0.14317, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13435 acc: 0.98667 val_loss: 0.14311, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13428 acc: 0.98667 val_loss: 0.14305, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13421 acc: 0.98667 val_loss: 0.14299, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13414 acc: 0.98667 val_loss: 0.14293, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13407 acc: 0.98667 val_loss: 0.14287, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13400 acc: 0.98667 val_loss: 0.14281, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13393 acc: 0.98667 val_loss: 0.14276, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13386 acc: 0.98667 val_loss: 0.14270, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13379 acc: 0.98667 val_loss: 0.14264, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13373 acc: 0.98667 val_loss: 0.14258, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13366 acc: 0.98667 val_loss: 0.14252, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13359 acc: 0.98667 val_loss: 0.14247, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13352 acc: 0.98667 val_loss: 0.14241, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13345 acc: 0.98667 val_loss: 0.14235, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13338 acc: 0.98667 val_loss: 0.14229, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13332 acc: 0.98667 val_loss: 0.14224, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13325 acc: 0.98667 val_loss: 0.14218, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13318 acc: 0.98667 val_loss: 0.14212, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13311 acc: 0.98667 val_loss: 0.14207, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13305 acc: 0.98667 val_loss: 0.14201, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13298 acc: 0.98667 val_loss: 0.14195, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13291 acc: 0.98667 val_loss: 0.14190, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13284 acc: 0.98667 val_loss: 0.14184, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13278 acc: 0.98667 val_loss: 0.14178, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13271 acc: 0.98667 val_loss: 0.14173, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13264 acc: 0.98667 val_loss: 0.14167, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13258 acc: 0.98667 val_loss: 0.14161, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13251 acc: 0.98667 val_loss: 0.14156, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13245 acc: 0.98667 val_loss: 0.14150, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13238 acc: 0.98667 val_loss: 0.14145, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13231 acc: 0.98667 val_loss: 0.14139, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13225 acc: 0.98667 val_loss: 0.14134, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13218 acc: 0.98667 val_loss: 0.14128, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13212 acc: 0.98667 val_loss: 0.14123, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13205 acc: 0.98667 val_loss: 0.14117, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13198 acc: 0.98667 val_loss: 0.14112, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13192 acc: 0.98667 val_loss: 0.14106, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13185 acc: 0.98667 val_loss: 0.14101, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13179 acc: 0.98667 val_loss: 0.14095, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13172 acc: 0.98667 val_loss: 0.14090, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13166 acc: 0.98667 val_loss: 0.14084, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13159 acc: 0.98667 val_loss: 0.14079, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13153 acc: 0.98667 val_loss: 0.14073, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14068, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13140 acc: 0.98667 val_loss: 0.14062, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13134 acc: 0.98667 val_loss: 0.14057, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13127 acc: 0.98667 val_loss: 0.14052, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13121 acc: 0.98667 val_loss: 0.14046, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13114 acc: 0.98667 val_loss: 0.14041, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13108 acc: 0.98667 val_loss: 0.14036, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14030, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13095 acc: 0.98667 val_loss: 0.14025, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13089 acc: 0.98667 val_loss: 0.14020, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14014, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13076 acc: 0.98667 val_loss: 0.14009, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14004, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.13998, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13057 acc: 0.98667 val_loss: 0.13993, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.13988, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.13983, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.13977, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.13032 acc: 0.98667 val_loss: 0.13972, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13967, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13962, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13956, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.13007 acc: 0.98667 val_loss: 0.13951, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13946, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13941, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13936, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13930, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12977 acc: 0.98667 val_loss: 0.13925, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13920, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13915, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13910, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13905, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13900, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13895, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12934 acc: 0.98667 val_loss: 0.13890, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12928 acc: 0.98667 val_loss: 0.13884, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12922 acc: 0.98667 val_loss: 0.13879, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12916 acc: 0.98667 val_loss: 0.13874, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12910 acc: 0.98667 val_loss: 0.13869, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12904 acc: 0.98667 val_loss: 0.13864, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12898 acc: 0.98667 val_loss: 0.13859, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12892 acc: 0.98667 val_loss: 0.13854, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12886 acc: 0.98667 val_loss: 0.13849, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12880 acc: 0.98667 val_loss: 0.13844, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12874 acc: 0.98667 val_loss: 0.13839, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12868 acc: 0.98667 val_loss: 0.13834, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12862 acc: 0.98667 val_loss: 0.13829, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12856 acc: 0.98667 val_loss: 0.13824, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12850 acc: 0.98667 val_loss: 0.13819, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12844 acc: 0.98667 val_loss: 0.13814, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12838 acc: 0.98667 val_loss: 0.13809, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12832 acc: 0.98667 val_loss: 0.13805, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12826 acc: 0.98667 val_loss: 0.13800, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12820 acc: 0.98667 val_loss: 0.13795, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12814 acc: 0.98667 val_loss: 0.13790, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12809 acc: 0.98667 val_loss: 0.13785, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12803 acc: 0.98667 val_loss: 0.13780, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12797 acc: 0.98667 val_loss: 0.13775, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12791 acc: 0.98667 val_loss: 0.13770, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12785 acc: 0.98667 val_loss: 0.13765, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12779 acc: 0.98667 val_loss: 0.13761, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12774 acc: 0.98667 val_loss: 0.13756, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12768 acc: 0.98667 val_loss: 0.13751, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12762 acc: 0.98667 val_loss: 0.13746, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12756 acc: 0.98667 val_loss: 0.13741, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12750 acc: 0.98667 val_loss: 0.13736, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 훈련 페이즈\n",
    "    \n",
    "    # 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 경사 계산\n",
    "    loss.backward()\n",
    "    \n",
    "    # 파라미터 수정\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    # 예측 페이즈\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs_test = net(inputs_test)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기상태 : 손실 : 1.89647  정확도 : 0.57333\n",
      "최종상태 : 손실 : 0.13736  정확도 : 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 손실과 정확도 확인\n",
    "\n",
    "print(f'초기상태 : 손실 : {history[0,3]:.5f}  정확도 : {history[0,4]:.5f}' )\n",
    "print(f'최종상태 : 손실 : {history[-1,3]:.5f}  정확도 : {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.0296  -0.1004  -2.4189]\n",
      " [ -4.8426  -0.022   -4.2776]\n",
      " [ -0.0583  -2.8716 -16.2088]\n",
      " [-11.7034  -3.2038  -0.0415]\n",
      " [ -9.1574  -1.7262  -0.1961]]\n",
      "[[0.0065 0.9044 0.089 ]\n",
      " [0.0079 0.9782 0.0139]\n",
      " [0.9434 0.0566 0.    ]\n",
      " [0.     0.0406 0.9594]\n",
      " [0.0001 0.178  0.8219]]\n"
     ]
    }
   ],
   "source": [
    "# 패턴 2 모델의 출력 결과\n",
    "w = outputs[:5,:].data\n",
    "print(w.numpy())\n",
    "\n",
    "# 확률값을 얻고 싶은 경우\n",
    "print(torch.exp(w).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 클래스측에 소프트맥스 함수 만 포함된 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "# 2입력 3출력 로지스틱 회귀 모델\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_output)\n",
    "        # 소프트맥스 함수 정의\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "                \n",
    "        # 초깃값을 모두 1로 함\n",
    "        # \"딥러닝을 위한 수학\"과 조건을 맞추기 위한 목적        \n",
    "        self.l1.weight.data.fill_(1.0)\n",
    "        self.l1.bias.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.softmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "lr = 0.01\n",
    "\n",
    "# 초기화\n",
    "net = Net(n_input, n_output)\n",
    "\n",
    "# 손실 함수： NLLLoss 함수\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 최적화 함수: 경사 하강법\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# 반복 횟수\n",
    "num_epochs = 10000\n",
    "\n",
    "# 평가 결과 기록\n",
    "history = np.zeros((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], loss: 1.09861 acc: 0.30667 val_loss: 1.09158, val_acc: 0.26667\n",
      "Epoch [10/10000], loss: 1.01848 acc: 0.40000 val_loss: 1.04171, val_acc: 0.26667\n",
      "Epoch [20/10000], loss: 0.96854 acc: 0.40000 val_loss: 0.98850, val_acc: 0.26667\n",
      "Epoch [30/10000], loss: 0.92459 acc: 0.65333 val_loss: 0.93996, val_acc: 0.57333\n",
      "Epoch [40/10000], loss: 0.88568 acc: 0.70667 val_loss: 0.89704, val_acc: 0.62667\n",
      "Epoch [50/10000], loss: 0.85120 acc: 0.70667 val_loss: 0.85918, val_acc: 0.62667\n",
      "Epoch [60/10000], loss: 0.82059 acc: 0.70667 val_loss: 0.82572, val_acc: 0.62667\n",
      "Epoch [70/10000], loss: 0.79335 acc: 0.72000 val_loss: 0.79607, val_acc: 0.62667\n",
      "Epoch [80/10000], loss: 0.76900 acc: 0.72000 val_loss: 0.76968, val_acc: 0.65333\n",
      "Epoch [90/10000], loss: 0.74717 acc: 0.72000 val_loss: 0.74610, val_acc: 0.65333\n",
      "Epoch [100/10000], loss: 0.72750 acc: 0.76000 val_loss: 0.72494, val_acc: 0.69333\n",
      "Epoch [110/10000], loss: 0.70970 acc: 0.77333 val_loss: 0.70585, val_acc: 0.74667\n",
      "Epoch [120/10000], loss: 0.69354 acc: 0.81333 val_loss: 0.68856, val_acc: 0.76000\n",
      "Epoch [130/10000], loss: 0.67878 acc: 0.84000 val_loss: 0.67283, val_acc: 0.76000\n",
      "Epoch [140/10000], loss: 0.66526 acc: 0.84000 val_loss: 0.65846, val_acc: 0.78667\n",
      "Epoch [150/10000], loss: 0.65283 acc: 0.86667 val_loss: 0.64528, val_acc: 0.78667\n",
      "Epoch [160/10000], loss: 0.64135 acc: 0.88000 val_loss: 0.63313, val_acc: 0.78667\n",
      "Epoch [170/10000], loss: 0.63070 acc: 0.89333 val_loss: 0.62190, val_acc: 0.81333\n",
      "Epoch [180/10000], loss: 0.62081 acc: 0.90667 val_loss: 0.61149, val_acc: 0.81333\n",
      "Epoch [190/10000], loss: 0.61157 acc: 0.90667 val_loss: 0.60179, val_acc: 0.84000\n",
      "Epoch [200/10000], loss: 0.60292 acc: 0.90667 val_loss: 0.59273, val_acc: 0.84000\n",
      "Epoch [210/10000], loss: 0.59481 acc: 0.90667 val_loss: 0.58425, val_acc: 0.88000\n",
      "Epoch [220/10000], loss: 0.58717 acc: 0.93333 val_loss: 0.57628, val_acc: 0.88000\n",
      "Epoch [230/10000], loss: 0.57996 acc: 0.93333 val_loss: 0.56877, val_acc: 0.89333\n",
      "Epoch [240/10000], loss: 0.57313 acc: 0.93333 val_loss: 0.56169, val_acc: 0.90667\n",
      "Epoch [250/10000], loss: 0.56666 acc: 0.93333 val_loss: 0.55498, val_acc: 0.90667\n",
      "Epoch [260/10000], loss: 0.56051 acc: 0.92000 val_loss: 0.54862, val_acc: 0.90667\n",
      "Epoch [270/10000], loss: 0.55465 acc: 0.92000 val_loss: 0.54257, val_acc: 0.90667\n",
      "Epoch [280/10000], loss: 0.54906 acc: 0.92000 val_loss: 0.53681, val_acc: 0.90667\n",
      "Epoch [290/10000], loss: 0.54371 acc: 0.92000 val_loss: 0.53131, val_acc: 0.90667\n",
      "Epoch [300/10000], loss: 0.53859 acc: 0.93333 val_loss: 0.52605, val_acc: 0.90667\n",
      "Epoch [310/10000], loss: 0.53368 acc: 0.93333 val_loss: 0.52102, val_acc: 0.90667\n",
      "Epoch [320/10000], loss: 0.52896 acc: 0.93333 val_loss: 0.51619, val_acc: 0.90667\n",
      "Epoch [330/10000], loss: 0.52442 acc: 0.93333 val_loss: 0.51155, val_acc: 0.90667\n",
      "Epoch [340/10000], loss: 0.52004 acc: 0.93333 val_loss: 0.50709, val_acc: 0.90667\n",
      "Epoch [350/10000], loss: 0.51582 acc: 0.93333 val_loss: 0.50280, val_acc: 0.90667\n",
      "Epoch [360/10000], loss: 0.51173 acc: 0.93333 val_loss: 0.49865, val_acc: 0.90667\n",
      "Epoch [370/10000], loss: 0.50779 acc: 0.93333 val_loss: 0.49465, val_acc: 0.90667\n",
      "Epoch [380/10000], loss: 0.50397 acc: 0.93333 val_loss: 0.49078, val_acc: 0.90667\n",
      "Epoch [390/10000], loss: 0.50026 acc: 0.93333 val_loss: 0.48703, val_acc: 0.90667\n",
      "Epoch [400/10000], loss: 0.49666 acc: 0.94667 val_loss: 0.48340, val_acc: 0.90667\n",
      "Epoch [410/10000], loss: 0.49317 acc: 0.94667 val_loss: 0.47988, val_acc: 0.90667\n",
      "Epoch [420/10000], loss: 0.48978 acc: 0.94667 val_loss: 0.47647, val_acc: 0.90667\n",
      "Epoch [430/10000], loss: 0.48647 acc: 0.96000 val_loss: 0.47315, val_acc: 0.90667\n",
      "Epoch [440/10000], loss: 0.48326 acc: 0.96000 val_loss: 0.46992, val_acc: 0.90667\n",
      "Epoch [450/10000], loss: 0.48012 acc: 0.96000 val_loss: 0.46678, val_acc: 0.90667\n",
      "Epoch [460/10000], loss: 0.47706 acc: 0.96000 val_loss: 0.46372, val_acc: 0.90667\n",
      "Epoch [470/10000], loss: 0.47408 acc: 0.96000 val_loss: 0.46073, val_acc: 0.90667\n",
      "Epoch [480/10000], loss: 0.47116 acc: 0.96000 val_loss: 0.45783, val_acc: 0.90667\n",
      "Epoch [490/10000], loss: 0.46831 acc: 0.96000 val_loss: 0.45499, val_acc: 0.90667\n",
      "Epoch [500/10000], loss: 0.46553 acc: 0.96000 val_loss: 0.45221, val_acc: 0.90667\n",
      "Epoch [510/10000], loss: 0.46280 acc: 0.96000 val_loss: 0.44951, val_acc: 0.90667\n",
      "Epoch [520/10000], loss: 0.46013 acc: 0.96000 val_loss: 0.44686, val_acc: 0.90667\n",
      "Epoch [530/10000], loss: 0.45752 acc: 0.96000 val_loss: 0.44426, val_acc: 0.90667\n",
      "Epoch [540/10000], loss: 0.45496 acc: 0.96000 val_loss: 0.44173, val_acc: 0.90667\n",
      "Epoch [550/10000], loss: 0.45245 acc: 0.96000 val_loss: 0.43924, val_acc: 0.90667\n",
      "Epoch [560/10000], loss: 0.44998 acc: 0.96000 val_loss: 0.43681, val_acc: 0.90667\n",
      "Epoch [570/10000], loss: 0.44757 acc: 0.96000 val_loss: 0.43442, val_acc: 0.90667\n",
      "Epoch [580/10000], loss: 0.44519 acc: 0.96000 val_loss: 0.43208, val_acc: 0.90667\n",
      "Epoch [590/10000], loss: 0.44286 acc: 0.96000 val_loss: 0.42979, val_acc: 0.92000\n",
      "Epoch [600/10000], loss: 0.44057 acc: 0.96000 val_loss: 0.42753, val_acc: 0.92000\n",
      "Epoch [610/10000], loss: 0.43832 acc: 0.96000 val_loss: 0.42532, val_acc: 0.92000\n",
      "Epoch [620/10000], loss: 0.43611 acc: 0.96000 val_loss: 0.42315, val_acc: 0.92000\n",
      "Epoch [630/10000], loss: 0.43393 acc: 0.96000 val_loss: 0.42101, val_acc: 0.92000\n",
      "Epoch [640/10000], loss: 0.43179 acc: 0.96000 val_loss: 0.41891, val_acc: 0.92000\n",
      "Epoch [650/10000], loss: 0.42968 acc: 0.96000 val_loss: 0.41685, val_acc: 0.92000\n",
      "Epoch [660/10000], loss: 0.42761 acc: 0.96000 val_loss: 0.41482, val_acc: 0.92000\n",
      "Epoch [670/10000], loss: 0.42556 acc: 0.96000 val_loss: 0.41282, val_acc: 0.92000\n",
      "Epoch [680/10000], loss: 0.42355 acc: 0.96000 val_loss: 0.41085, val_acc: 0.92000\n",
      "Epoch [690/10000], loss: 0.42157 acc: 0.96000 val_loss: 0.40892, val_acc: 0.92000\n",
      "Epoch [700/10000], loss: 0.41961 acc: 0.96000 val_loss: 0.40701, val_acc: 0.92000\n",
      "Epoch [710/10000], loss: 0.41768 acc: 0.96000 val_loss: 0.40513, val_acc: 0.92000\n",
      "Epoch [720/10000], loss: 0.41578 acc: 0.96000 val_loss: 0.40329, val_acc: 0.92000\n",
      "Epoch [730/10000], loss: 0.41391 acc: 0.96000 val_loss: 0.40146, val_acc: 0.92000\n",
      "Epoch [740/10000], loss: 0.41206 acc: 0.96000 val_loss: 0.39967, val_acc: 0.92000\n",
      "Epoch [750/10000], loss: 0.41024 acc: 0.96000 val_loss: 0.39789, val_acc: 0.92000\n",
      "Epoch [760/10000], loss: 0.40844 acc: 0.96000 val_loss: 0.39615, val_acc: 0.92000\n",
      "Epoch [770/10000], loss: 0.40666 acc: 0.96000 val_loss: 0.39443, val_acc: 0.93333\n",
      "Epoch [780/10000], loss: 0.40491 acc: 0.96000 val_loss: 0.39273, val_acc: 0.93333\n",
      "Epoch [790/10000], loss: 0.40317 acc: 0.96000 val_loss: 0.39105, val_acc: 0.93333\n",
      "Epoch [800/10000], loss: 0.40146 acc: 0.96000 val_loss: 0.38939, val_acc: 0.93333\n",
      "Epoch [810/10000], loss: 0.39977 acc: 0.96000 val_loss: 0.38776, val_acc: 0.93333\n",
      "Epoch [820/10000], loss: 0.39810 acc: 0.96000 val_loss: 0.38615, val_acc: 0.93333\n",
      "Epoch [830/10000], loss: 0.39646 acc: 0.96000 val_loss: 0.38456, val_acc: 0.93333\n",
      "Epoch [840/10000], loss: 0.39483 acc: 0.96000 val_loss: 0.38298, val_acc: 0.93333\n",
      "Epoch [850/10000], loss: 0.39321 acc: 0.97333 val_loss: 0.38143, val_acc: 0.94667\n",
      "Epoch [860/10000], loss: 0.39162 acc: 0.97333 val_loss: 0.37990, val_acc: 0.94667\n",
      "Epoch [870/10000], loss: 0.39005 acc: 0.97333 val_loss: 0.37838, val_acc: 0.94667\n",
      "Epoch [880/10000], loss: 0.38849 acc: 0.97333 val_loss: 0.37688, val_acc: 0.94667\n",
      "Epoch [890/10000], loss: 0.38695 acc: 0.97333 val_loss: 0.37540, val_acc: 0.94667\n",
      "Epoch [900/10000], loss: 0.38543 acc: 0.97333 val_loss: 0.37394, val_acc: 0.94667\n",
      "Epoch [910/10000], loss: 0.38392 acc: 0.97333 val_loss: 0.37249, val_acc: 0.94667\n",
      "Epoch [920/10000], loss: 0.38243 acc: 0.97333 val_loss: 0.37106, val_acc: 0.94667\n",
      "Epoch [930/10000], loss: 0.38096 acc: 0.97333 val_loss: 0.36965, val_acc: 0.94667\n",
      "Epoch [940/10000], loss: 0.37950 acc: 0.97333 val_loss: 0.36825, val_acc: 0.94667\n",
      "Epoch [950/10000], loss: 0.37806 acc: 0.97333 val_loss: 0.36686, val_acc: 0.94667\n",
      "Epoch [960/10000], loss: 0.37663 acc: 0.97333 val_loss: 0.36550, val_acc: 0.96000\n",
      "Epoch [970/10000], loss: 0.37522 acc: 0.97333 val_loss: 0.36414, val_acc: 0.96000\n",
      "Epoch [980/10000], loss: 0.37382 acc: 0.97333 val_loss: 0.36280, val_acc: 0.96000\n",
      "Epoch [990/10000], loss: 0.37243 acc: 0.97333 val_loss: 0.36148, val_acc: 0.96000\n",
      "Epoch [1000/10000], loss: 0.37106 acc: 0.97333 val_loss: 0.36017, val_acc: 0.96000\n",
      "Epoch [1010/10000], loss: 0.36970 acc: 0.97333 val_loss: 0.35887, val_acc: 0.96000\n",
      "Epoch [1020/10000], loss: 0.36836 acc: 0.97333 val_loss: 0.35758, val_acc: 0.96000\n",
      "Epoch [1030/10000], loss: 0.36703 acc: 0.97333 val_loss: 0.35631, val_acc: 0.96000\n",
      "Epoch [1040/10000], loss: 0.36571 acc: 0.97333 val_loss: 0.35505, val_acc: 0.96000\n",
      "Epoch [1050/10000], loss: 0.36440 acc: 0.97333 val_loss: 0.35381, val_acc: 0.96000\n",
      "Epoch [1060/10000], loss: 0.36311 acc: 0.97333 val_loss: 0.35258, val_acc: 0.96000\n",
      "Epoch [1070/10000], loss: 0.36183 acc: 0.97333 val_loss: 0.35135, val_acc: 0.96000\n",
      "Epoch [1080/10000], loss: 0.36056 acc: 0.97333 val_loss: 0.35014, val_acc: 0.96000\n",
      "Epoch [1090/10000], loss: 0.35930 acc: 0.97333 val_loss: 0.34895, val_acc: 0.96000\n",
      "Epoch [1100/10000], loss: 0.35805 acc: 0.97333 val_loss: 0.34776, val_acc: 0.96000\n",
      "Epoch [1110/10000], loss: 0.35682 acc: 0.97333 val_loss: 0.34659, val_acc: 0.96000\n",
      "Epoch [1120/10000], loss: 0.35559 acc: 0.97333 val_loss: 0.34542, val_acc: 0.96000\n",
      "Epoch [1130/10000], loss: 0.35438 acc: 0.97333 val_loss: 0.34427, val_acc: 0.96000\n",
      "Epoch [1140/10000], loss: 0.35318 acc: 0.97333 val_loss: 0.34313, val_acc: 0.96000\n",
      "Epoch [1150/10000], loss: 0.35199 acc: 0.97333 val_loss: 0.34199, val_acc: 0.96000\n",
      "Epoch [1160/10000], loss: 0.35081 acc: 0.97333 val_loss: 0.34087, val_acc: 0.96000\n",
      "Epoch [1170/10000], loss: 0.34964 acc: 0.97333 val_loss: 0.33976, val_acc: 0.96000\n",
      "Epoch [1180/10000], loss: 0.34848 acc: 0.97333 val_loss: 0.33866, val_acc: 0.96000\n",
      "Epoch [1190/10000], loss: 0.34732 acc: 0.97333 val_loss: 0.33757, val_acc: 0.96000\n",
      "Epoch [1200/10000], loss: 0.34618 acc: 0.97333 val_loss: 0.33649, val_acc: 0.96000\n",
      "Epoch [1210/10000], loss: 0.34505 acc: 0.97333 val_loss: 0.33542, val_acc: 0.96000\n",
      "Epoch [1220/10000], loss: 0.34393 acc: 0.97333 val_loss: 0.33435, val_acc: 0.96000\n",
      "Epoch [1230/10000], loss: 0.34282 acc: 0.97333 val_loss: 0.33330, val_acc: 0.96000\n",
      "Epoch [1240/10000], loss: 0.34172 acc: 0.97333 val_loss: 0.33226, val_acc: 0.96000\n",
      "Epoch [1250/10000], loss: 0.34062 acc: 0.97333 val_loss: 0.33122, val_acc: 0.96000\n",
      "Epoch [1260/10000], loss: 0.33954 acc: 0.97333 val_loss: 0.33020, val_acc: 0.96000\n",
      "Epoch [1270/10000], loss: 0.33846 acc: 0.97333 val_loss: 0.32918, val_acc: 0.96000\n",
      "Epoch [1280/10000], loss: 0.33740 acc: 0.97333 val_loss: 0.32817, val_acc: 0.96000\n",
      "Epoch [1290/10000], loss: 0.33634 acc: 0.97333 val_loss: 0.32717, val_acc: 0.96000\n",
      "Epoch [1300/10000], loss: 0.33529 acc: 0.97333 val_loss: 0.32618, val_acc: 0.96000\n",
      "Epoch [1310/10000], loss: 0.33425 acc: 0.97333 val_loss: 0.32520, val_acc: 0.96000\n",
      "Epoch [1320/10000], loss: 0.33321 acc: 0.97333 val_loss: 0.32422, val_acc: 0.96000\n",
      "Epoch [1330/10000], loss: 0.33219 acc: 0.97333 val_loss: 0.32325, val_acc: 0.96000\n",
      "Epoch [1340/10000], loss: 0.33117 acc: 0.97333 val_loss: 0.32229, val_acc: 0.96000\n",
      "Epoch [1350/10000], loss: 0.33016 acc: 0.97333 val_loss: 0.32134, val_acc: 0.96000\n",
      "Epoch [1360/10000], loss: 0.32916 acc: 0.97333 val_loss: 0.32040, val_acc: 0.96000\n",
      "Epoch [1370/10000], loss: 0.32817 acc: 0.97333 val_loss: 0.31946, val_acc: 0.96000\n",
      "Epoch [1380/10000], loss: 0.32719 acc: 0.97333 val_loss: 0.31854, val_acc: 0.96000\n",
      "Epoch [1390/10000], loss: 0.32621 acc: 0.97333 val_loss: 0.31761, val_acc: 0.96000\n",
      "Epoch [1400/10000], loss: 0.32524 acc: 0.97333 val_loss: 0.31670, val_acc: 0.96000\n",
      "Epoch [1410/10000], loss: 0.32428 acc: 0.97333 val_loss: 0.31579, val_acc: 0.96000\n",
      "Epoch [1420/10000], loss: 0.32332 acc: 0.97333 val_loss: 0.31489, val_acc: 0.96000\n",
      "Epoch [1430/10000], loss: 0.32237 acc: 0.97333 val_loss: 0.31400, val_acc: 0.96000\n",
      "Epoch [1440/10000], loss: 0.32143 acc: 0.97333 val_loss: 0.31312, val_acc: 0.96000\n",
      "Epoch [1450/10000], loss: 0.32050 acc: 0.97333 val_loss: 0.31224, val_acc: 0.96000\n",
      "Epoch [1460/10000], loss: 0.31957 acc: 0.97333 val_loss: 0.31137, val_acc: 0.96000\n",
      "Epoch [1470/10000], loss: 0.31865 acc: 0.97333 val_loss: 0.31050, val_acc: 0.96000\n",
      "Epoch [1480/10000], loss: 0.31774 acc: 0.97333 val_loss: 0.30964, val_acc: 0.96000\n",
      "Epoch [1490/10000], loss: 0.31683 acc: 0.97333 val_loss: 0.30879, val_acc: 0.96000\n",
      "Epoch [1500/10000], loss: 0.31593 acc: 0.97333 val_loss: 0.30795, val_acc: 0.96000\n",
      "Epoch [1510/10000], loss: 0.31504 acc: 0.97333 val_loss: 0.30711, val_acc: 0.96000\n",
      "Epoch [1520/10000], loss: 0.31415 acc: 0.97333 val_loss: 0.30628, val_acc: 0.96000\n",
      "Epoch [1530/10000], loss: 0.31327 acc: 0.97333 val_loss: 0.30545, val_acc: 0.96000\n",
      "Epoch [1540/10000], loss: 0.31240 acc: 0.97333 val_loss: 0.30463, val_acc: 0.96000\n",
      "Epoch [1550/10000], loss: 0.31153 acc: 0.97333 val_loss: 0.30382, val_acc: 0.96000\n",
      "Epoch [1560/10000], loss: 0.31067 acc: 0.97333 val_loss: 0.30301, val_acc: 0.96000\n",
      "Epoch [1570/10000], loss: 0.30981 acc: 0.97333 val_loss: 0.30221, val_acc: 0.96000\n",
      "Epoch [1580/10000], loss: 0.30896 acc: 0.97333 val_loss: 0.30141, val_acc: 0.96000\n",
      "Epoch [1590/10000], loss: 0.30812 acc: 0.97333 val_loss: 0.30062, val_acc: 0.96000\n",
      "Epoch [1600/10000], loss: 0.30728 acc: 0.97333 val_loss: 0.29984, val_acc: 0.96000\n",
      "Epoch [1610/10000], loss: 0.30645 acc: 0.97333 val_loss: 0.29906, val_acc: 0.96000\n",
      "Epoch [1620/10000], loss: 0.30562 acc: 0.97333 val_loss: 0.29828, val_acc: 0.96000\n",
      "Epoch [1630/10000], loss: 0.30480 acc: 0.97333 val_loss: 0.29752, val_acc: 0.96000\n",
      "Epoch [1640/10000], loss: 0.30399 acc: 0.97333 val_loss: 0.29675, val_acc: 0.96000\n",
      "Epoch [1650/10000], loss: 0.30318 acc: 0.97333 val_loss: 0.29600, val_acc: 0.96000\n",
      "Epoch [1660/10000], loss: 0.30237 acc: 0.97333 val_loss: 0.29525, val_acc: 0.96000\n",
      "Epoch [1670/10000], loss: 0.30158 acc: 0.97333 val_loss: 0.29450, val_acc: 0.96000\n",
      "Epoch [1680/10000], loss: 0.30078 acc: 0.97333 val_loss: 0.29376, val_acc: 0.96000\n",
      "Epoch [1690/10000], loss: 0.30000 acc: 0.97333 val_loss: 0.29302, val_acc: 0.96000\n",
      "Epoch [1700/10000], loss: 0.29922 acc: 0.97333 val_loss: 0.29229, val_acc: 0.96000\n",
      "Epoch [1710/10000], loss: 0.29844 acc: 0.97333 val_loss: 0.29157, val_acc: 0.96000\n",
      "Epoch [1720/10000], loss: 0.29767 acc: 0.97333 val_loss: 0.29085, val_acc: 0.96000\n",
      "Epoch [1730/10000], loss: 0.29690 acc: 0.97333 val_loss: 0.29013, val_acc: 0.96000\n",
      "Epoch [1740/10000], loss: 0.29614 acc: 0.97333 val_loss: 0.28942, val_acc: 0.96000\n",
      "Epoch [1750/10000], loss: 0.29538 acc: 0.97333 val_loss: 0.28872, val_acc: 0.96000\n",
      "Epoch [1760/10000], loss: 0.29463 acc: 0.97333 val_loss: 0.28801, val_acc: 0.96000\n",
      "Epoch [1770/10000], loss: 0.29389 acc: 0.97333 val_loss: 0.28732, val_acc: 0.96000\n",
      "Epoch [1780/10000], loss: 0.29315 acc: 0.97333 val_loss: 0.28663, val_acc: 0.96000\n",
      "Epoch [1790/10000], loss: 0.29241 acc: 0.97333 val_loss: 0.28594, val_acc: 0.96000\n",
      "Epoch [1800/10000], loss: 0.29168 acc: 0.97333 val_loss: 0.28526, val_acc: 0.96000\n",
      "Epoch [1810/10000], loss: 0.29095 acc: 0.97333 val_loss: 0.28458, val_acc: 0.96000\n",
      "Epoch [1820/10000], loss: 0.29023 acc: 0.97333 val_loss: 0.28391, val_acc: 0.96000\n",
      "Epoch [1830/10000], loss: 0.28951 acc: 0.97333 val_loss: 0.28324, val_acc: 0.96000\n",
      "Epoch [1840/10000], loss: 0.28880 acc: 0.97333 val_loss: 0.28258, val_acc: 0.96000\n",
      "Epoch [1850/10000], loss: 0.28809 acc: 0.97333 val_loss: 0.28192, val_acc: 0.96000\n",
      "Epoch [1860/10000], loss: 0.28739 acc: 0.97333 val_loss: 0.28126, val_acc: 0.96000\n",
      "Epoch [1870/10000], loss: 0.28669 acc: 0.97333 val_loss: 0.28061, val_acc: 0.96000\n",
      "Epoch [1880/10000], loss: 0.28599 acc: 0.97333 val_loss: 0.27996, val_acc: 0.96000\n",
      "Epoch [1890/10000], loss: 0.28530 acc: 0.97333 val_loss: 0.27932, val_acc: 0.96000\n",
      "Epoch [1900/10000], loss: 0.28462 acc: 0.97333 val_loss: 0.27868, val_acc: 0.96000\n",
      "Epoch [1910/10000], loss: 0.28394 acc: 0.97333 val_loss: 0.27805, val_acc: 0.96000\n",
      "Epoch [1920/10000], loss: 0.28326 acc: 0.97333 val_loss: 0.27742, val_acc: 0.96000\n",
      "Epoch [1930/10000], loss: 0.28258 acc: 0.97333 val_loss: 0.27679, val_acc: 0.96000\n",
      "Epoch [1940/10000], loss: 0.28192 acc: 0.97333 val_loss: 0.27617, val_acc: 0.96000\n",
      "Epoch [1950/10000], loss: 0.28125 acc: 0.97333 val_loss: 0.27555, val_acc: 0.96000\n",
      "Epoch [1960/10000], loss: 0.28059 acc: 0.97333 val_loss: 0.27494, val_acc: 0.96000\n",
      "Epoch [1970/10000], loss: 0.27993 acc: 0.97333 val_loss: 0.27433, val_acc: 0.96000\n",
      "Epoch [1980/10000], loss: 0.27928 acc: 0.97333 val_loss: 0.27372, val_acc: 0.96000\n",
      "Epoch [1990/10000], loss: 0.27863 acc: 0.97333 val_loss: 0.27312, val_acc: 0.96000\n",
      "Epoch [2000/10000], loss: 0.27799 acc: 0.97333 val_loss: 0.27252, val_acc: 0.96000\n",
      "Epoch [2010/10000], loss: 0.27735 acc: 0.97333 val_loss: 0.27193, val_acc: 0.96000\n",
      "Epoch [2020/10000], loss: 0.27671 acc: 0.97333 val_loss: 0.27134, val_acc: 0.96000\n",
      "Epoch [2030/10000], loss: 0.27608 acc: 0.97333 val_loss: 0.27075, val_acc: 0.96000\n",
      "Epoch [2040/10000], loss: 0.27545 acc: 0.97333 val_loss: 0.27016, val_acc: 0.96000\n",
      "Epoch [2050/10000], loss: 0.27482 acc: 0.97333 val_loss: 0.26958, val_acc: 0.96000\n",
      "Epoch [2060/10000], loss: 0.27420 acc: 0.97333 val_loss: 0.26901, val_acc: 0.96000\n",
      "Epoch [2070/10000], loss: 0.27358 acc: 0.97333 val_loss: 0.26843, val_acc: 0.96000\n",
      "Epoch [2080/10000], loss: 0.27297 acc: 0.97333 val_loss: 0.26786, val_acc: 0.96000\n",
      "Epoch [2090/10000], loss: 0.27236 acc: 0.97333 val_loss: 0.26730, val_acc: 0.96000\n",
      "Epoch [2100/10000], loss: 0.27175 acc: 0.97333 val_loss: 0.26674, val_acc: 0.96000\n",
      "Epoch [2110/10000], loss: 0.27115 acc: 0.97333 val_loss: 0.26618, val_acc: 0.96000\n",
      "Epoch [2120/10000], loss: 0.27055 acc: 0.97333 val_loss: 0.26562, val_acc: 0.96000\n",
      "Epoch [2130/10000], loss: 0.26995 acc: 0.97333 val_loss: 0.26507, val_acc: 0.96000\n",
      "Epoch [2140/10000], loss: 0.26936 acc: 0.97333 val_loss: 0.26452, val_acc: 0.96000\n",
      "Epoch [2150/10000], loss: 0.26877 acc: 0.97333 val_loss: 0.26397, val_acc: 0.96000\n",
      "Epoch [2160/10000], loss: 0.26818 acc: 0.97333 val_loss: 0.26343, val_acc: 0.96000\n",
      "Epoch [2170/10000], loss: 0.26760 acc: 0.97333 val_loss: 0.26289, val_acc: 0.96000\n",
      "Epoch [2180/10000], loss: 0.26702 acc: 0.97333 val_loss: 0.26236, val_acc: 0.96000\n",
      "Epoch [2190/10000], loss: 0.26644 acc: 0.97333 val_loss: 0.26182, val_acc: 0.96000\n",
      "Epoch [2200/10000], loss: 0.26587 acc: 0.97333 val_loss: 0.26129, val_acc: 0.96000\n",
      "Epoch [2210/10000], loss: 0.26530 acc: 0.97333 val_loss: 0.26077, val_acc: 0.96000\n",
      "Epoch [2220/10000], loss: 0.26473 acc: 0.97333 val_loss: 0.26024, val_acc: 0.96000\n",
      "Epoch [2230/10000], loss: 0.26417 acc: 0.97333 val_loss: 0.25972, val_acc: 0.96000\n",
      "Epoch [2240/10000], loss: 0.26361 acc: 0.97333 val_loss: 0.25920, val_acc: 0.96000\n",
      "Epoch [2250/10000], loss: 0.26305 acc: 0.97333 val_loss: 0.25869, val_acc: 0.96000\n",
      "Epoch [2260/10000], loss: 0.26250 acc: 0.97333 val_loss: 0.25818, val_acc: 0.96000\n",
      "Epoch [2270/10000], loss: 0.26195 acc: 0.97333 val_loss: 0.25767, val_acc: 0.96000\n",
      "Epoch [2280/10000], loss: 0.26140 acc: 0.97333 val_loss: 0.25717, val_acc: 0.96000\n",
      "Epoch [2290/10000], loss: 0.26086 acc: 0.97333 val_loss: 0.25666, val_acc: 0.96000\n",
      "Epoch [2300/10000], loss: 0.26032 acc: 0.97333 val_loss: 0.25616, val_acc: 0.96000\n",
      "Epoch [2310/10000], loss: 0.25978 acc: 0.97333 val_loss: 0.25567, val_acc: 0.96000\n",
      "Epoch [2320/10000], loss: 0.25924 acc: 0.97333 val_loss: 0.25517, val_acc: 0.96000\n",
      "Epoch [2330/10000], loss: 0.25871 acc: 0.97333 val_loss: 0.25468, val_acc: 0.96000\n",
      "Epoch [2340/10000], loss: 0.25818 acc: 0.97333 val_loss: 0.25419, val_acc: 0.96000\n",
      "Epoch [2350/10000], loss: 0.25766 acc: 0.97333 val_loss: 0.25371, val_acc: 0.96000\n",
      "Epoch [2360/10000], loss: 0.25713 acc: 0.97333 val_loss: 0.25322, val_acc: 0.96000\n",
      "Epoch [2370/10000], loss: 0.25661 acc: 0.97333 val_loss: 0.25274, val_acc: 0.96000\n",
      "Epoch [2380/10000], loss: 0.25609 acc: 0.97333 val_loss: 0.25227, val_acc: 0.96000\n",
      "Epoch [2390/10000], loss: 0.25558 acc: 0.97333 val_loss: 0.25179, val_acc: 0.96000\n",
      "Epoch [2400/10000], loss: 0.25507 acc: 0.97333 val_loss: 0.25132, val_acc: 0.96000\n",
      "Epoch [2410/10000], loss: 0.25456 acc: 0.97333 val_loss: 0.25085, val_acc: 0.96000\n",
      "Epoch [2420/10000], loss: 0.25405 acc: 0.97333 val_loss: 0.25038, val_acc: 0.96000\n",
      "Epoch [2430/10000], loss: 0.25355 acc: 0.97333 val_loss: 0.24992, val_acc: 0.96000\n",
      "Epoch [2440/10000], loss: 0.25304 acc: 0.97333 val_loss: 0.24946, val_acc: 0.96000\n",
      "Epoch [2450/10000], loss: 0.25255 acc: 0.97333 val_loss: 0.24900, val_acc: 0.96000\n",
      "Epoch [2460/10000], loss: 0.25205 acc: 0.97333 val_loss: 0.24854, val_acc: 0.96000\n",
      "Epoch [2470/10000], loss: 0.25156 acc: 0.97333 val_loss: 0.24809, val_acc: 0.96000\n",
      "Epoch [2480/10000], loss: 0.25107 acc: 0.97333 val_loss: 0.24764, val_acc: 0.96000\n",
      "Epoch [2490/10000], loss: 0.25058 acc: 0.97333 val_loss: 0.24719, val_acc: 0.96000\n",
      "Epoch [2500/10000], loss: 0.25009 acc: 0.97333 val_loss: 0.24674, val_acc: 0.96000\n",
      "Epoch [2510/10000], loss: 0.24961 acc: 0.97333 val_loss: 0.24630, val_acc: 0.96000\n",
      "Epoch [2520/10000], loss: 0.24913 acc: 0.97333 val_loss: 0.24585, val_acc: 0.96000\n",
      "Epoch [2530/10000], loss: 0.24865 acc: 0.97333 val_loss: 0.24541, val_acc: 0.96000\n",
      "Epoch [2540/10000], loss: 0.24818 acc: 0.97333 val_loss: 0.24498, val_acc: 0.96000\n",
      "Epoch [2550/10000], loss: 0.24770 acc: 0.97333 val_loss: 0.24454, val_acc: 0.96000\n",
      "Epoch [2560/10000], loss: 0.24723 acc: 0.97333 val_loss: 0.24411, val_acc: 0.96000\n",
      "Epoch [2570/10000], loss: 0.24676 acc: 0.97333 val_loss: 0.24368, val_acc: 0.96000\n",
      "Epoch [2580/10000], loss: 0.24630 acc: 0.98667 val_loss: 0.24325, val_acc: 0.96000\n",
      "Epoch [2590/10000], loss: 0.24584 acc: 0.98667 val_loss: 0.24283, val_acc: 0.96000\n",
      "Epoch [2600/10000], loss: 0.24537 acc: 0.98667 val_loss: 0.24240, val_acc: 0.96000\n",
      "Epoch [2610/10000], loss: 0.24492 acc: 0.98667 val_loss: 0.24198, val_acc: 0.96000\n",
      "Epoch [2620/10000], loss: 0.24446 acc: 0.98667 val_loss: 0.24156, val_acc: 0.96000\n",
      "Epoch [2630/10000], loss: 0.24401 acc: 0.98667 val_loss: 0.24115, val_acc: 0.96000\n",
      "Epoch [2640/10000], loss: 0.24355 acc: 0.98667 val_loss: 0.24073, val_acc: 0.96000\n",
      "Epoch [2650/10000], loss: 0.24311 acc: 0.98667 val_loss: 0.24032, val_acc: 0.96000\n",
      "Epoch [2660/10000], loss: 0.24266 acc: 0.98667 val_loss: 0.23991, val_acc: 0.96000\n",
      "Epoch [2670/10000], loss: 0.24221 acc: 0.98667 val_loss: 0.23950, val_acc: 0.96000\n",
      "Epoch [2680/10000], loss: 0.24177 acc: 0.98667 val_loss: 0.23909, val_acc: 0.96000\n",
      "Epoch [2690/10000], loss: 0.24133 acc: 0.98667 val_loss: 0.23869, val_acc: 0.96000\n",
      "Epoch [2700/10000], loss: 0.24089 acc: 0.98667 val_loss: 0.23829, val_acc: 0.96000\n",
      "Epoch [2710/10000], loss: 0.24046 acc: 0.98667 val_loss: 0.23789, val_acc: 0.96000\n",
      "Epoch [2720/10000], loss: 0.24002 acc: 0.98667 val_loss: 0.23749, val_acc: 0.96000\n",
      "Epoch [2730/10000], loss: 0.23959 acc: 0.98667 val_loss: 0.23710, val_acc: 0.96000\n",
      "Epoch [2740/10000], loss: 0.23916 acc: 0.98667 val_loss: 0.23670, val_acc: 0.96000\n",
      "Epoch [2750/10000], loss: 0.23874 acc: 0.98667 val_loss: 0.23631, val_acc: 0.96000\n",
      "Epoch [2760/10000], loss: 0.23831 acc: 0.98667 val_loss: 0.23592, val_acc: 0.96000\n",
      "Epoch [2770/10000], loss: 0.23789 acc: 0.98667 val_loss: 0.23553, val_acc: 0.96000\n",
      "Epoch [2780/10000], loss: 0.23747 acc: 0.98667 val_loss: 0.23515, val_acc: 0.96000\n",
      "Epoch [2790/10000], loss: 0.23705 acc: 0.98667 val_loss: 0.23476, val_acc: 0.96000\n",
      "Epoch [2800/10000], loss: 0.23663 acc: 0.98667 val_loss: 0.23438, val_acc: 0.96000\n",
      "Epoch [2810/10000], loss: 0.23622 acc: 0.98667 val_loss: 0.23400, val_acc: 0.96000\n",
      "Epoch [2820/10000], loss: 0.23580 acc: 0.98667 val_loss: 0.23363, val_acc: 0.96000\n",
      "Epoch [2830/10000], loss: 0.23539 acc: 0.98667 val_loss: 0.23325, val_acc: 0.96000\n",
      "Epoch [2840/10000], loss: 0.23498 acc: 0.98667 val_loss: 0.23288, val_acc: 0.96000\n",
      "Epoch [2850/10000], loss: 0.23458 acc: 0.98667 val_loss: 0.23250, val_acc: 0.96000\n",
      "Epoch [2860/10000], loss: 0.23417 acc: 0.98667 val_loss: 0.23213, val_acc: 0.96000\n",
      "Epoch [2870/10000], loss: 0.23377 acc: 0.98667 val_loss: 0.23176, val_acc: 0.96000\n",
      "Epoch [2880/10000], loss: 0.23337 acc: 0.98667 val_loss: 0.23140, val_acc: 0.96000\n",
      "Epoch [2890/10000], loss: 0.23297 acc: 0.98667 val_loss: 0.23103, val_acc: 0.96000\n",
      "Epoch [2900/10000], loss: 0.23257 acc: 0.98667 val_loss: 0.23067, val_acc: 0.96000\n",
      "Epoch [2910/10000], loss: 0.23218 acc: 0.98667 val_loss: 0.23031, val_acc: 0.96000\n",
      "Epoch [2920/10000], loss: 0.23178 acc: 0.98667 val_loss: 0.22995, val_acc: 0.96000\n",
      "Epoch [2930/10000], loss: 0.23139 acc: 0.98667 val_loss: 0.22959, val_acc: 0.96000\n",
      "Epoch [2940/10000], loss: 0.23100 acc: 0.98667 val_loss: 0.22923, val_acc: 0.96000\n",
      "Epoch [2950/10000], loss: 0.23061 acc: 0.98667 val_loss: 0.22888, val_acc: 0.96000\n",
      "Epoch [2960/10000], loss: 0.23023 acc: 0.98667 val_loss: 0.22853, val_acc: 0.96000\n",
      "Epoch [2970/10000], loss: 0.22984 acc: 0.98667 val_loss: 0.22818, val_acc: 0.96000\n",
      "Epoch [2980/10000], loss: 0.22946 acc: 0.98667 val_loss: 0.22783, val_acc: 0.96000\n",
      "Epoch [2990/10000], loss: 0.22908 acc: 0.98667 val_loss: 0.22748, val_acc: 0.96000\n",
      "Epoch [3000/10000], loss: 0.22870 acc: 0.98667 val_loss: 0.22713, val_acc: 0.96000\n",
      "Epoch [3010/10000], loss: 0.22832 acc: 0.98667 val_loss: 0.22679, val_acc: 0.96000\n",
      "Epoch [3020/10000], loss: 0.22795 acc: 0.98667 val_loss: 0.22645, val_acc: 0.96000\n",
      "Epoch [3030/10000], loss: 0.22757 acc: 0.98667 val_loss: 0.22610, val_acc: 0.96000\n",
      "Epoch [3040/10000], loss: 0.22720 acc: 0.98667 val_loss: 0.22576, val_acc: 0.96000\n",
      "Epoch [3050/10000], loss: 0.22683 acc: 0.98667 val_loss: 0.22543, val_acc: 0.96000\n",
      "Epoch [3060/10000], loss: 0.22646 acc: 0.98667 val_loss: 0.22509, val_acc: 0.96000\n",
      "Epoch [3070/10000], loss: 0.22610 acc: 0.98667 val_loss: 0.22476, val_acc: 0.96000\n",
      "Epoch [3080/10000], loss: 0.22573 acc: 0.98667 val_loss: 0.22442, val_acc: 0.96000\n",
      "Epoch [3090/10000], loss: 0.22537 acc: 0.98667 val_loss: 0.22409, val_acc: 0.96000\n",
      "Epoch [3100/10000], loss: 0.22501 acc: 0.98667 val_loss: 0.22376, val_acc: 0.96000\n",
      "Epoch [3110/10000], loss: 0.22465 acc: 0.98667 val_loss: 0.22343, val_acc: 0.96000\n",
      "Epoch [3120/10000], loss: 0.22429 acc: 0.98667 val_loss: 0.22311, val_acc: 0.96000\n",
      "Epoch [3130/10000], loss: 0.22393 acc: 0.98667 val_loss: 0.22278, val_acc: 0.96000\n",
      "Epoch [3140/10000], loss: 0.22357 acc: 0.98667 val_loss: 0.22246, val_acc: 0.96000\n",
      "Epoch [3150/10000], loss: 0.22322 acc: 0.98667 val_loss: 0.22214, val_acc: 0.96000\n",
      "Epoch [3160/10000], loss: 0.22287 acc: 0.98667 val_loss: 0.22181, val_acc: 0.96000\n",
      "Epoch [3170/10000], loss: 0.22252 acc: 0.98667 val_loss: 0.22150, val_acc: 0.96000\n",
      "Epoch [3180/10000], loss: 0.22217 acc: 0.98667 val_loss: 0.22118, val_acc: 0.96000\n",
      "Epoch [3190/10000], loss: 0.22182 acc: 0.98667 val_loss: 0.22086, val_acc: 0.96000\n",
      "Epoch [3200/10000], loss: 0.22148 acc: 0.98667 val_loss: 0.22055, val_acc: 0.96000\n",
      "Epoch [3210/10000], loss: 0.22113 acc: 0.98667 val_loss: 0.22023, val_acc: 0.96000\n",
      "Epoch [3220/10000], loss: 0.22079 acc: 0.98667 val_loss: 0.21992, val_acc: 0.96000\n",
      "Epoch [3230/10000], loss: 0.22045 acc: 0.98667 val_loss: 0.21961, val_acc: 0.96000\n",
      "Epoch [3240/10000], loss: 0.22011 acc: 0.98667 val_loss: 0.21930, val_acc: 0.96000\n",
      "Epoch [3250/10000], loss: 0.21977 acc: 0.98667 val_loss: 0.21899, val_acc: 0.96000\n",
      "Epoch [3260/10000], loss: 0.21943 acc: 0.98667 val_loss: 0.21869, val_acc: 0.96000\n",
      "Epoch [3270/10000], loss: 0.21910 acc: 0.98667 val_loss: 0.21838, val_acc: 0.96000\n",
      "Epoch [3280/10000], loss: 0.21876 acc: 0.98667 val_loss: 0.21808, val_acc: 0.96000\n",
      "Epoch [3290/10000], loss: 0.21843 acc: 0.98667 val_loss: 0.21778, val_acc: 0.96000\n",
      "Epoch [3300/10000], loss: 0.21810 acc: 0.98667 val_loss: 0.21747, val_acc: 0.96000\n",
      "Epoch [3310/10000], loss: 0.21777 acc: 0.98667 val_loss: 0.21717, val_acc: 0.96000\n",
      "Epoch [3320/10000], loss: 0.21744 acc: 0.98667 val_loss: 0.21688, val_acc: 0.96000\n",
      "Epoch [3330/10000], loss: 0.21711 acc: 0.98667 val_loss: 0.21658, val_acc: 0.96000\n",
      "Epoch [3340/10000], loss: 0.21679 acc: 0.98667 val_loss: 0.21628, val_acc: 0.96000\n",
      "Epoch [3350/10000], loss: 0.21646 acc: 0.98667 val_loss: 0.21599, val_acc: 0.96000\n",
      "Epoch [3360/10000], loss: 0.21614 acc: 0.98667 val_loss: 0.21570, val_acc: 0.96000\n",
      "Epoch [3370/10000], loss: 0.21582 acc: 0.98667 val_loss: 0.21540, val_acc: 0.96000\n",
      "Epoch [3380/10000], loss: 0.21550 acc: 0.98667 val_loss: 0.21511, val_acc: 0.96000\n",
      "Epoch [3390/10000], loss: 0.21518 acc: 0.98667 val_loss: 0.21482, val_acc: 0.96000\n",
      "Epoch [3400/10000], loss: 0.21487 acc: 0.98667 val_loss: 0.21454, val_acc: 0.96000\n",
      "Epoch [3410/10000], loss: 0.21455 acc: 0.98667 val_loss: 0.21425, val_acc: 0.96000\n",
      "Epoch [3420/10000], loss: 0.21424 acc: 0.98667 val_loss: 0.21397, val_acc: 0.96000\n",
      "Epoch [3430/10000], loss: 0.21392 acc: 0.98667 val_loss: 0.21368, val_acc: 0.96000\n",
      "Epoch [3440/10000], loss: 0.21361 acc: 0.98667 val_loss: 0.21340, val_acc: 0.96000\n",
      "Epoch [3450/10000], loss: 0.21330 acc: 0.98667 val_loss: 0.21312, val_acc: 0.96000\n",
      "Epoch [3460/10000], loss: 0.21299 acc: 0.98667 val_loss: 0.21284, val_acc: 0.96000\n",
      "Epoch [3470/10000], loss: 0.21268 acc: 0.98667 val_loss: 0.21256, val_acc: 0.96000\n",
      "Epoch [3480/10000], loss: 0.21238 acc: 0.98667 val_loss: 0.21228, val_acc: 0.96000\n",
      "Epoch [3490/10000], loss: 0.21207 acc: 0.98667 val_loss: 0.21200, val_acc: 0.96000\n",
      "Epoch [3500/10000], loss: 0.21177 acc: 0.98667 val_loss: 0.21173, val_acc: 0.96000\n",
      "Epoch [3510/10000], loss: 0.21146 acc: 0.98667 val_loss: 0.21145, val_acc: 0.96000\n",
      "Epoch [3520/10000], loss: 0.21116 acc: 0.98667 val_loss: 0.21118, val_acc: 0.96000\n",
      "Epoch [3530/10000], loss: 0.21086 acc: 0.98667 val_loss: 0.21091, val_acc: 0.96000\n",
      "Epoch [3540/10000], loss: 0.21056 acc: 0.98667 val_loss: 0.21064, val_acc: 0.96000\n",
      "Epoch [3550/10000], loss: 0.21026 acc: 0.98667 val_loss: 0.21037, val_acc: 0.96000\n",
      "Epoch [3560/10000], loss: 0.20997 acc: 0.98667 val_loss: 0.21010, val_acc: 0.96000\n",
      "Epoch [3570/10000], loss: 0.20967 acc: 0.98667 val_loss: 0.20983, val_acc: 0.96000\n",
      "Epoch [3580/10000], loss: 0.20938 acc: 0.98667 val_loss: 0.20956, val_acc: 0.96000\n",
      "Epoch [3590/10000], loss: 0.20909 acc: 0.98667 val_loss: 0.20930, val_acc: 0.96000\n",
      "Epoch [3600/10000], loss: 0.20879 acc: 0.98667 val_loss: 0.20903, val_acc: 0.96000\n",
      "Epoch [3610/10000], loss: 0.20850 acc: 0.98667 val_loss: 0.20877, val_acc: 0.96000\n",
      "Epoch [3620/10000], loss: 0.20821 acc: 0.98667 val_loss: 0.20851, val_acc: 0.96000\n",
      "Epoch [3630/10000], loss: 0.20793 acc: 0.98667 val_loss: 0.20825, val_acc: 0.96000\n",
      "Epoch [3640/10000], loss: 0.20764 acc: 0.98667 val_loss: 0.20799, val_acc: 0.96000\n",
      "Epoch [3650/10000], loss: 0.20735 acc: 0.98667 val_loss: 0.20773, val_acc: 0.96000\n",
      "Epoch [3660/10000], loss: 0.20707 acc: 0.98667 val_loss: 0.20747, val_acc: 0.96000\n",
      "Epoch [3670/10000], loss: 0.20678 acc: 0.98667 val_loss: 0.20721, val_acc: 0.96000\n",
      "Epoch [3680/10000], loss: 0.20650 acc: 0.98667 val_loss: 0.20696, val_acc: 0.96000\n",
      "Epoch [3690/10000], loss: 0.20622 acc: 0.98667 val_loss: 0.20670, val_acc: 0.96000\n",
      "Epoch [3700/10000], loss: 0.20594 acc: 0.98667 val_loss: 0.20645, val_acc: 0.96000\n",
      "Epoch [3710/10000], loss: 0.20566 acc: 0.98667 val_loss: 0.20620, val_acc: 0.96000\n",
      "Epoch [3720/10000], loss: 0.20538 acc: 0.98667 val_loss: 0.20595, val_acc: 0.96000\n",
      "Epoch [3730/10000], loss: 0.20511 acc: 0.98667 val_loss: 0.20570, val_acc: 0.96000\n",
      "Epoch [3740/10000], loss: 0.20483 acc: 0.98667 val_loss: 0.20545, val_acc: 0.96000\n",
      "Epoch [3750/10000], loss: 0.20455 acc: 0.98667 val_loss: 0.20520, val_acc: 0.96000\n",
      "Epoch [3760/10000], loss: 0.20428 acc: 0.98667 val_loss: 0.20495, val_acc: 0.96000\n",
      "Epoch [3770/10000], loss: 0.20401 acc: 0.98667 val_loss: 0.20471, val_acc: 0.96000\n",
      "Epoch [3780/10000], loss: 0.20374 acc: 0.98667 val_loss: 0.20446, val_acc: 0.96000\n",
      "Epoch [3790/10000], loss: 0.20347 acc: 0.98667 val_loss: 0.20422, val_acc: 0.96000\n",
      "Epoch [3800/10000], loss: 0.20320 acc: 0.98667 val_loss: 0.20397, val_acc: 0.96000\n",
      "Epoch [3810/10000], loss: 0.20293 acc: 0.98667 val_loss: 0.20373, val_acc: 0.96000\n",
      "Epoch [3820/10000], loss: 0.20266 acc: 0.98667 val_loss: 0.20349, val_acc: 0.96000\n",
      "Epoch [3830/10000], loss: 0.20239 acc: 0.98667 val_loss: 0.20325, val_acc: 0.96000\n",
      "Epoch [3840/10000], loss: 0.20213 acc: 0.98667 val_loss: 0.20301, val_acc: 0.96000\n",
      "Epoch [3850/10000], loss: 0.20186 acc: 0.98667 val_loss: 0.20277, val_acc: 0.96000\n",
      "Epoch [3860/10000], loss: 0.20160 acc: 0.98667 val_loss: 0.20253, val_acc: 0.96000\n",
      "Epoch [3870/10000], loss: 0.20134 acc: 0.98667 val_loss: 0.20230, val_acc: 0.96000\n",
      "Epoch [3880/10000], loss: 0.20108 acc: 0.98667 val_loss: 0.20206, val_acc: 0.96000\n",
      "Epoch [3890/10000], loss: 0.20082 acc: 0.98667 val_loss: 0.20183, val_acc: 0.96000\n",
      "Epoch [3900/10000], loss: 0.20056 acc: 0.98667 val_loss: 0.20159, val_acc: 0.96000\n",
      "Epoch [3910/10000], loss: 0.20030 acc: 0.98667 val_loss: 0.20136, val_acc: 0.96000\n",
      "Epoch [3920/10000], loss: 0.20004 acc: 0.98667 val_loss: 0.20113, val_acc: 0.96000\n",
      "Epoch [3930/10000], loss: 0.19979 acc: 0.98667 val_loss: 0.20090, val_acc: 0.96000\n",
      "Epoch [3940/10000], loss: 0.19953 acc: 0.98667 val_loss: 0.20067, val_acc: 0.96000\n",
      "Epoch [3950/10000], loss: 0.19928 acc: 0.98667 val_loss: 0.20044, val_acc: 0.96000\n",
      "Epoch [3960/10000], loss: 0.19902 acc: 0.98667 val_loss: 0.20021, val_acc: 0.96000\n",
      "Epoch [3970/10000], loss: 0.19877 acc: 0.98667 val_loss: 0.19998, val_acc: 0.96000\n",
      "Epoch [3980/10000], loss: 0.19852 acc: 0.98667 val_loss: 0.19976, val_acc: 0.96000\n",
      "Epoch [3990/10000], loss: 0.19827 acc: 0.98667 val_loss: 0.19953, val_acc: 0.96000\n",
      "Epoch [4000/10000], loss: 0.19802 acc: 0.98667 val_loss: 0.19931, val_acc: 0.96000\n",
      "Epoch [4010/10000], loss: 0.19777 acc: 0.98667 val_loss: 0.19908, val_acc: 0.96000\n",
      "Epoch [4020/10000], loss: 0.19752 acc: 0.98667 val_loss: 0.19886, val_acc: 0.96000\n",
      "Epoch [4030/10000], loss: 0.19728 acc: 0.98667 val_loss: 0.19864, val_acc: 0.96000\n",
      "Epoch [4040/10000], loss: 0.19703 acc: 0.98667 val_loss: 0.19842, val_acc: 0.96000\n",
      "Epoch [4050/10000], loss: 0.19679 acc: 0.98667 val_loss: 0.19820, val_acc: 0.96000\n",
      "Epoch [4060/10000], loss: 0.19654 acc: 0.98667 val_loss: 0.19798, val_acc: 0.96000\n",
      "Epoch [4070/10000], loss: 0.19630 acc: 0.98667 val_loss: 0.19776, val_acc: 0.96000\n",
      "Epoch [4080/10000], loss: 0.19606 acc: 0.98667 val_loss: 0.19754, val_acc: 0.96000\n",
      "Epoch [4090/10000], loss: 0.19582 acc: 0.98667 val_loss: 0.19732, val_acc: 0.96000\n",
      "Epoch [4100/10000], loss: 0.19557 acc: 0.98667 val_loss: 0.19711, val_acc: 0.96000\n",
      "Epoch [4110/10000], loss: 0.19534 acc: 0.98667 val_loss: 0.19689, val_acc: 0.96000\n",
      "Epoch [4120/10000], loss: 0.19510 acc: 0.98667 val_loss: 0.19668, val_acc: 0.96000\n",
      "Epoch [4130/10000], loss: 0.19486 acc: 0.98667 val_loss: 0.19646, val_acc: 0.96000\n",
      "Epoch [4140/10000], loss: 0.19462 acc: 0.98667 val_loss: 0.19625, val_acc: 0.96000\n",
      "Epoch [4150/10000], loss: 0.19439 acc: 0.98667 val_loss: 0.19604, val_acc: 0.96000\n",
      "Epoch [4160/10000], loss: 0.19415 acc: 0.98667 val_loss: 0.19583, val_acc: 0.96000\n",
      "Epoch [4170/10000], loss: 0.19392 acc: 0.98667 val_loss: 0.19562, val_acc: 0.96000\n",
      "Epoch [4180/10000], loss: 0.19368 acc: 0.98667 val_loss: 0.19541, val_acc: 0.96000\n",
      "Epoch [4190/10000], loss: 0.19345 acc: 0.98667 val_loss: 0.19520, val_acc: 0.96000\n",
      "Epoch [4200/10000], loss: 0.19322 acc: 0.98667 val_loss: 0.19499, val_acc: 0.96000\n",
      "Epoch [4210/10000], loss: 0.19299 acc: 0.98667 val_loss: 0.19478, val_acc: 0.96000\n",
      "Epoch [4220/10000], loss: 0.19276 acc: 0.98667 val_loss: 0.19457, val_acc: 0.96000\n",
      "Epoch [4230/10000], loss: 0.19253 acc: 0.98667 val_loss: 0.19437, val_acc: 0.96000\n",
      "Epoch [4240/10000], loss: 0.19230 acc: 0.98667 val_loss: 0.19416, val_acc: 0.96000\n",
      "Epoch [4250/10000], loss: 0.19207 acc: 0.98667 val_loss: 0.19396, val_acc: 0.96000\n",
      "Epoch [4260/10000], loss: 0.19184 acc: 0.98667 val_loss: 0.19376, val_acc: 0.96000\n",
      "Epoch [4270/10000], loss: 0.19162 acc: 0.98667 val_loss: 0.19355, val_acc: 0.96000\n",
      "Epoch [4280/10000], loss: 0.19139 acc: 0.98667 val_loss: 0.19335, val_acc: 0.96000\n",
      "Epoch [4290/10000], loss: 0.19117 acc: 0.98667 val_loss: 0.19315, val_acc: 0.96000\n",
      "Epoch [4300/10000], loss: 0.19094 acc: 0.98667 val_loss: 0.19295, val_acc: 0.96000\n",
      "Epoch [4310/10000], loss: 0.19072 acc: 0.98667 val_loss: 0.19275, val_acc: 0.96000\n",
      "Epoch [4320/10000], loss: 0.19050 acc: 0.98667 val_loss: 0.19255, val_acc: 0.96000\n",
      "Epoch [4330/10000], loss: 0.19028 acc: 0.98667 val_loss: 0.19235, val_acc: 0.96000\n",
      "Epoch [4340/10000], loss: 0.19006 acc: 0.98667 val_loss: 0.19215, val_acc: 0.96000\n",
      "Epoch [4350/10000], loss: 0.18984 acc: 0.98667 val_loss: 0.19196, val_acc: 0.96000\n",
      "Epoch [4360/10000], loss: 0.18962 acc: 0.98667 val_loss: 0.19176, val_acc: 0.96000\n",
      "Epoch [4370/10000], loss: 0.18940 acc: 0.98667 val_loss: 0.19156, val_acc: 0.96000\n",
      "Epoch [4380/10000], loss: 0.18918 acc: 0.98667 val_loss: 0.19137, val_acc: 0.96000\n",
      "Epoch [4390/10000], loss: 0.18897 acc: 0.98667 val_loss: 0.19118, val_acc: 0.96000\n",
      "Epoch [4400/10000], loss: 0.18875 acc: 0.98667 val_loss: 0.19098, val_acc: 0.96000\n",
      "Epoch [4410/10000], loss: 0.18853 acc: 0.98667 val_loss: 0.19079, val_acc: 0.96000\n",
      "Epoch [4420/10000], loss: 0.18832 acc: 0.98667 val_loss: 0.19060, val_acc: 0.96000\n",
      "Epoch [4430/10000], loss: 0.18811 acc: 0.98667 val_loss: 0.19041, val_acc: 0.96000\n",
      "Epoch [4440/10000], loss: 0.18789 acc: 0.98667 val_loss: 0.19021, val_acc: 0.96000\n",
      "Epoch [4450/10000], loss: 0.18768 acc: 0.98667 val_loss: 0.19002, val_acc: 0.96000\n",
      "Epoch [4460/10000], loss: 0.18747 acc: 0.98667 val_loss: 0.18984, val_acc: 0.96000\n",
      "Epoch [4470/10000], loss: 0.18726 acc: 0.98667 val_loss: 0.18965, val_acc: 0.96000\n",
      "Epoch [4480/10000], loss: 0.18705 acc: 0.98667 val_loss: 0.18946, val_acc: 0.96000\n",
      "Epoch [4490/10000], loss: 0.18684 acc: 0.98667 val_loss: 0.18927, val_acc: 0.96000\n",
      "Epoch [4500/10000], loss: 0.18663 acc: 0.98667 val_loss: 0.18908, val_acc: 0.96000\n",
      "Epoch [4510/10000], loss: 0.18642 acc: 0.98667 val_loss: 0.18890, val_acc: 0.96000\n",
      "Epoch [4520/10000], loss: 0.18621 acc: 0.98667 val_loss: 0.18871, val_acc: 0.96000\n",
      "Epoch [4530/10000], loss: 0.18601 acc: 0.98667 val_loss: 0.18853, val_acc: 0.96000\n",
      "Epoch [4540/10000], loss: 0.18580 acc: 0.98667 val_loss: 0.18834, val_acc: 0.96000\n",
      "Epoch [4550/10000], loss: 0.18560 acc: 0.98667 val_loss: 0.18816, val_acc: 0.96000\n",
      "Epoch [4560/10000], loss: 0.18539 acc: 0.98667 val_loss: 0.18798, val_acc: 0.96000\n",
      "Epoch [4570/10000], loss: 0.18519 acc: 0.98667 val_loss: 0.18780, val_acc: 0.96000\n",
      "Epoch [4580/10000], loss: 0.18499 acc: 0.98667 val_loss: 0.18762, val_acc: 0.96000\n",
      "Epoch [4590/10000], loss: 0.18478 acc: 0.98667 val_loss: 0.18743, val_acc: 0.96000\n",
      "Epoch [4600/10000], loss: 0.18458 acc: 0.98667 val_loss: 0.18725, val_acc: 0.96000\n",
      "Epoch [4610/10000], loss: 0.18438 acc: 0.98667 val_loss: 0.18707, val_acc: 0.96000\n",
      "Epoch [4620/10000], loss: 0.18418 acc: 0.98667 val_loss: 0.18690, val_acc: 0.96000\n",
      "Epoch [4630/10000], loss: 0.18398 acc: 0.98667 val_loss: 0.18672, val_acc: 0.96000\n",
      "Epoch [4640/10000], loss: 0.18378 acc: 0.98667 val_loss: 0.18654, val_acc: 0.96000\n",
      "Epoch [4650/10000], loss: 0.18358 acc: 0.98667 val_loss: 0.18636, val_acc: 0.96000\n",
      "Epoch [4660/10000], loss: 0.18339 acc: 0.98667 val_loss: 0.18619, val_acc: 0.96000\n",
      "Epoch [4670/10000], loss: 0.18319 acc: 0.98667 val_loss: 0.18601, val_acc: 0.96000\n",
      "Epoch [4680/10000], loss: 0.18299 acc: 0.98667 val_loss: 0.18583, val_acc: 0.96000\n",
      "Epoch [4690/10000], loss: 0.18280 acc: 0.98667 val_loss: 0.18566, val_acc: 0.96000\n",
      "Epoch [4700/10000], loss: 0.18260 acc: 0.98667 val_loss: 0.18549, val_acc: 0.96000\n",
      "Epoch [4710/10000], loss: 0.18241 acc: 0.98667 val_loss: 0.18531, val_acc: 0.96000\n",
      "Epoch [4720/10000], loss: 0.18221 acc: 0.98667 val_loss: 0.18514, val_acc: 0.96000\n",
      "Epoch [4730/10000], loss: 0.18202 acc: 0.98667 val_loss: 0.18497, val_acc: 0.96000\n",
      "Epoch [4740/10000], loss: 0.18183 acc: 0.98667 val_loss: 0.18479, val_acc: 0.96000\n",
      "Epoch [4750/10000], loss: 0.18164 acc: 0.98667 val_loss: 0.18462, val_acc: 0.96000\n",
      "Epoch [4760/10000], loss: 0.18144 acc: 0.98667 val_loss: 0.18445, val_acc: 0.96000\n",
      "Epoch [4770/10000], loss: 0.18125 acc: 0.98667 val_loss: 0.18428, val_acc: 0.96000\n",
      "Epoch [4780/10000], loss: 0.18106 acc: 0.98667 val_loss: 0.18411, val_acc: 0.96000\n",
      "Epoch [4790/10000], loss: 0.18087 acc: 0.98667 val_loss: 0.18395, val_acc: 0.96000\n",
      "Epoch [4800/10000], loss: 0.18068 acc: 0.98667 val_loss: 0.18378, val_acc: 0.96000\n",
      "Epoch [4810/10000], loss: 0.18050 acc: 0.98667 val_loss: 0.18361, val_acc: 0.96000\n",
      "Epoch [4820/10000], loss: 0.18031 acc: 0.98667 val_loss: 0.18344, val_acc: 0.96000\n",
      "Epoch [4830/10000], loss: 0.18012 acc: 0.98667 val_loss: 0.18328, val_acc: 0.96000\n",
      "Epoch [4840/10000], loss: 0.17994 acc: 0.98667 val_loss: 0.18311, val_acc: 0.96000\n",
      "Epoch [4850/10000], loss: 0.17975 acc: 0.98667 val_loss: 0.18294, val_acc: 0.96000\n",
      "Epoch [4860/10000], loss: 0.17956 acc: 0.98667 val_loss: 0.18278, val_acc: 0.96000\n",
      "Epoch [4870/10000], loss: 0.17938 acc: 0.98667 val_loss: 0.18261, val_acc: 0.96000\n",
      "Epoch [4880/10000], loss: 0.17920 acc: 0.98667 val_loss: 0.18245, val_acc: 0.96000\n",
      "Epoch [4890/10000], loss: 0.17901 acc: 0.98667 val_loss: 0.18229, val_acc: 0.96000\n",
      "Epoch [4900/10000], loss: 0.17883 acc: 0.98667 val_loss: 0.18212, val_acc: 0.96000\n",
      "Epoch [4910/10000], loss: 0.17865 acc: 0.98667 val_loss: 0.18196, val_acc: 0.96000\n",
      "Epoch [4920/10000], loss: 0.17846 acc: 0.98667 val_loss: 0.18180, val_acc: 0.96000\n",
      "Epoch [4930/10000], loss: 0.17828 acc: 0.98667 val_loss: 0.18164, val_acc: 0.96000\n",
      "Epoch [4940/10000], loss: 0.17810 acc: 0.98667 val_loss: 0.18148, val_acc: 0.96000\n",
      "Epoch [4950/10000], loss: 0.17792 acc: 0.98667 val_loss: 0.18132, val_acc: 0.96000\n",
      "Epoch [4960/10000], loss: 0.17774 acc: 0.98667 val_loss: 0.18116, val_acc: 0.96000\n",
      "Epoch [4970/10000], loss: 0.17756 acc: 0.98667 val_loss: 0.18100, val_acc: 0.96000\n",
      "Epoch [4980/10000], loss: 0.17739 acc: 0.98667 val_loss: 0.18084, val_acc: 0.96000\n",
      "Epoch [4990/10000], loss: 0.17721 acc: 0.98667 val_loss: 0.18068, val_acc: 0.96000\n",
      "Epoch [5000/10000], loss: 0.17703 acc: 0.98667 val_loss: 0.18053, val_acc: 0.96000\n",
      "Epoch [5010/10000], loss: 0.17685 acc: 0.98667 val_loss: 0.18037, val_acc: 0.96000\n",
      "Epoch [5020/10000], loss: 0.17668 acc: 0.98667 val_loss: 0.18021, val_acc: 0.96000\n",
      "Epoch [5030/10000], loss: 0.17650 acc: 0.98667 val_loss: 0.18006, val_acc: 0.96000\n",
      "Epoch [5040/10000], loss: 0.17633 acc: 0.98667 val_loss: 0.17990, val_acc: 0.96000\n",
      "Epoch [5050/10000], loss: 0.17615 acc: 0.98667 val_loss: 0.17975, val_acc: 0.96000\n",
      "Epoch [5060/10000], loss: 0.17598 acc: 0.98667 val_loss: 0.17959, val_acc: 0.96000\n",
      "Epoch [5070/10000], loss: 0.17581 acc: 0.98667 val_loss: 0.17944, val_acc: 0.96000\n",
      "Epoch [5080/10000], loss: 0.17563 acc: 0.98667 val_loss: 0.17928, val_acc: 0.96000\n",
      "Epoch [5090/10000], loss: 0.17546 acc: 0.98667 val_loss: 0.17913, val_acc: 0.96000\n",
      "Epoch [5100/10000], loss: 0.17529 acc: 0.98667 val_loss: 0.17898, val_acc: 0.96000\n",
      "Epoch [5110/10000], loss: 0.17512 acc: 0.98667 val_loss: 0.17883, val_acc: 0.96000\n",
      "Epoch [5120/10000], loss: 0.17495 acc: 0.98667 val_loss: 0.17867, val_acc: 0.96000\n",
      "Epoch [5130/10000], loss: 0.17478 acc: 0.98667 val_loss: 0.17852, val_acc: 0.96000\n",
      "Epoch [5140/10000], loss: 0.17461 acc: 0.98667 val_loss: 0.17837, val_acc: 0.96000\n",
      "Epoch [5150/10000], loss: 0.17444 acc: 0.98667 val_loss: 0.17822, val_acc: 0.96000\n",
      "Epoch [5160/10000], loss: 0.17427 acc: 0.98667 val_loss: 0.17807, val_acc: 0.96000\n",
      "Epoch [5170/10000], loss: 0.17410 acc: 0.98667 val_loss: 0.17792, val_acc: 0.96000\n",
      "Epoch [5180/10000], loss: 0.17393 acc: 0.98667 val_loss: 0.17778, val_acc: 0.96000\n",
      "Epoch [5190/10000], loss: 0.17377 acc: 0.98667 val_loss: 0.17763, val_acc: 0.96000\n",
      "Epoch [5200/10000], loss: 0.17360 acc: 0.98667 val_loss: 0.17748, val_acc: 0.96000\n",
      "Epoch [5210/10000], loss: 0.17343 acc: 0.98667 val_loss: 0.17733, val_acc: 0.96000\n",
      "Epoch [5220/10000], loss: 0.17327 acc: 0.98667 val_loss: 0.17719, val_acc: 0.96000\n",
      "Epoch [5230/10000], loss: 0.17310 acc: 0.98667 val_loss: 0.17704, val_acc: 0.96000\n",
      "Epoch [5240/10000], loss: 0.17294 acc: 0.98667 val_loss: 0.17689, val_acc: 0.96000\n",
      "Epoch [5250/10000], loss: 0.17277 acc: 0.98667 val_loss: 0.17675, val_acc: 0.96000\n",
      "Epoch [5260/10000], loss: 0.17261 acc: 0.98667 val_loss: 0.17660, val_acc: 0.96000\n",
      "Epoch [5270/10000], loss: 0.17245 acc: 0.98667 val_loss: 0.17646, val_acc: 0.96000\n",
      "Epoch [5280/10000], loss: 0.17228 acc: 0.98667 val_loss: 0.17631, val_acc: 0.96000\n",
      "Epoch [5290/10000], loss: 0.17212 acc: 0.98667 val_loss: 0.17617, val_acc: 0.96000\n",
      "Epoch [5300/10000], loss: 0.17196 acc: 0.98667 val_loss: 0.17603, val_acc: 0.96000\n",
      "Epoch [5310/10000], loss: 0.17180 acc: 0.98667 val_loss: 0.17589, val_acc: 0.96000\n",
      "Epoch [5320/10000], loss: 0.17164 acc: 0.98667 val_loss: 0.17574, val_acc: 0.96000\n",
      "Epoch [5330/10000], loss: 0.17148 acc: 0.98667 val_loss: 0.17560, val_acc: 0.96000\n",
      "Epoch [5340/10000], loss: 0.17132 acc: 0.98667 val_loss: 0.17546, val_acc: 0.96000\n",
      "Epoch [5350/10000], loss: 0.17116 acc: 0.98667 val_loss: 0.17532, val_acc: 0.96000\n",
      "Epoch [5360/10000], loss: 0.17100 acc: 0.98667 val_loss: 0.17518, val_acc: 0.96000\n",
      "Epoch [5370/10000], loss: 0.17084 acc: 0.98667 val_loss: 0.17504, val_acc: 0.96000\n",
      "Epoch [5380/10000], loss: 0.17068 acc: 0.98667 val_loss: 0.17490, val_acc: 0.96000\n",
      "Epoch [5390/10000], loss: 0.17053 acc: 0.98667 val_loss: 0.17476, val_acc: 0.96000\n",
      "Epoch [5400/10000], loss: 0.17037 acc: 0.98667 val_loss: 0.17462, val_acc: 0.96000\n",
      "Epoch [5410/10000], loss: 0.17021 acc: 0.98667 val_loss: 0.17448, val_acc: 0.96000\n",
      "Epoch [5420/10000], loss: 0.17006 acc: 0.98667 val_loss: 0.17434, val_acc: 0.96000\n",
      "Epoch [5430/10000], loss: 0.16990 acc: 0.98667 val_loss: 0.17421, val_acc: 0.96000\n",
      "Epoch [5440/10000], loss: 0.16975 acc: 0.98667 val_loss: 0.17407, val_acc: 0.96000\n",
      "Epoch [5450/10000], loss: 0.16959 acc: 0.98667 val_loss: 0.17393, val_acc: 0.96000\n",
      "Epoch [5460/10000], loss: 0.16944 acc: 0.98667 val_loss: 0.17380, val_acc: 0.96000\n",
      "Epoch [5470/10000], loss: 0.16928 acc: 0.98667 val_loss: 0.17366, val_acc: 0.96000\n",
      "Epoch [5480/10000], loss: 0.16913 acc: 0.98667 val_loss: 0.17352, val_acc: 0.96000\n",
      "Epoch [5490/10000], loss: 0.16898 acc: 0.98667 val_loss: 0.17339, val_acc: 0.96000\n",
      "Epoch [5500/10000], loss: 0.16883 acc: 0.98667 val_loss: 0.17325, val_acc: 0.96000\n",
      "Epoch [5510/10000], loss: 0.16867 acc: 0.98667 val_loss: 0.17312, val_acc: 0.96000\n",
      "Epoch [5520/10000], loss: 0.16852 acc: 0.98667 val_loss: 0.17299, val_acc: 0.96000\n",
      "Epoch [5530/10000], loss: 0.16837 acc: 0.98667 val_loss: 0.17285, val_acc: 0.96000\n",
      "Epoch [5540/10000], loss: 0.16822 acc: 0.98667 val_loss: 0.17272, val_acc: 0.96000\n",
      "Epoch [5550/10000], loss: 0.16807 acc: 0.98667 val_loss: 0.17259, val_acc: 0.96000\n",
      "Epoch [5560/10000], loss: 0.16792 acc: 0.98667 val_loss: 0.17246, val_acc: 0.96000\n",
      "Epoch [5570/10000], loss: 0.16777 acc: 0.98667 val_loss: 0.17232, val_acc: 0.96000\n",
      "Epoch [5580/10000], loss: 0.16762 acc: 0.98667 val_loss: 0.17219, val_acc: 0.96000\n",
      "Epoch [5590/10000], loss: 0.16747 acc: 0.98667 val_loss: 0.17206, val_acc: 0.96000\n",
      "Epoch [5600/10000], loss: 0.16732 acc: 0.98667 val_loss: 0.17193, val_acc: 0.96000\n",
      "Epoch [5610/10000], loss: 0.16718 acc: 0.98667 val_loss: 0.17180, val_acc: 0.96000\n",
      "Epoch [5620/10000], loss: 0.16703 acc: 0.98667 val_loss: 0.17167, val_acc: 0.96000\n",
      "Epoch [5630/10000], loss: 0.16688 acc: 0.98667 val_loss: 0.17154, val_acc: 0.96000\n",
      "Epoch [5640/10000], loss: 0.16674 acc: 0.98667 val_loss: 0.17141, val_acc: 0.96000\n",
      "Epoch [5650/10000], loss: 0.16659 acc: 0.98667 val_loss: 0.17128, val_acc: 0.96000\n",
      "Epoch [5660/10000], loss: 0.16644 acc: 0.98667 val_loss: 0.17115, val_acc: 0.96000\n",
      "Epoch [5670/10000], loss: 0.16630 acc: 0.98667 val_loss: 0.17103, val_acc: 0.96000\n",
      "Epoch [5680/10000], loss: 0.16615 acc: 0.98667 val_loss: 0.17090, val_acc: 0.96000\n",
      "Epoch [5690/10000], loss: 0.16601 acc: 0.98667 val_loss: 0.17077, val_acc: 0.96000\n",
      "Epoch [5700/10000], loss: 0.16587 acc: 0.98667 val_loss: 0.17064, val_acc: 0.96000\n",
      "Epoch [5710/10000], loss: 0.16572 acc: 0.98667 val_loss: 0.17052, val_acc: 0.96000\n",
      "Epoch [5720/10000], loss: 0.16558 acc: 0.98667 val_loss: 0.17039, val_acc: 0.96000\n",
      "Epoch [5730/10000], loss: 0.16544 acc: 0.98667 val_loss: 0.17027, val_acc: 0.96000\n",
      "Epoch [5740/10000], loss: 0.16529 acc: 0.98667 val_loss: 0.17014, val_acc: 0.96000\n",
      "Epoch [5750/10000], loss: 0.16515 acc: 0.98667 val_loss: 0.17001, val_acc: 0.96000\n",
      "Epoch [5760/10000], loss: 0.16501 acc: 0.98667 val_loss: 0.16989, val_acc: 0.96000\n",
      "Epoch [5770/10000], loss: 0.16487 acc: 0.98667 val_loss: 0.16977, val_acc: 0.96000\n",
      "Epoch [5780/10000], loss: 0.16473 acc: 0.98667 val_loss: 0.16964, val_acc: 0.96000\n",
      "Epoch [5790/10000], loss: 0.16459 acc: 0.98667 val_loss: 0.16952, val_acc: 0.96000\n",
      "Epoch [5800/10000], loss: 0.16445 acc: 0.98667 val_loss: 0.16940, val_acc: 0.96000\n",
      "Epoch [5810/10000], loss: 0.16431 acc: 0.98667 val_loss: 0.16927, val_acc: 0.96000\n",
      "Epoch [5820/10000], loss: 0.16417 acc: 0.98667 val_loss: 0.16915, val_acc: 0.96000\n",
      "Epoch [5830/10000], loss: 0.16403 acc: 0.98667 val_loss: 0.16903, val_acc: 0.96000\n",
      "Epoch [5840/10000], loss: 0.16389 acc: 0.98667 val_loss: 0.16891, val_acc: 0.96000\n",
      "Epoch [5850/10000], loss: 0.16375 acc: 0.98667 val_loss: 0.16878, val_acc: 0.96000\n",
      "Epoch [5860/10000], loss: 0.16361 acc: 0.98667 val_loss: 0.16866, val_acc: 0.96000\n",
      "Epoch [5870/10000], loss: 0.16348 acc: 0.98667 val_loss: 0.16854, val_acc: 0.96000\n",
      "Epoch [5880/10000], loss: 0.16334 acc: 0.98667 val_loss: 0.16842, val_acc: 0.96000\n",
      "Epoch [5890/10000], loss: 0.16320 acc: 0.98667 val_loss: 0.16830, val_acc: 0.96000\n",
      "Epoch [5900/10000], loss: 0.16307 acc: 0.98667 val_loss: 0.16818, val_acc: 0.96000\n",
      "Epoch [5910/10000], loss: 0.16293 acc: 0.98667 val_loss: 0.16806, val_acc: 0.96000\n",
      "Epoch [5920/10000], loss: 0.16280 acc: 0.98667 val_loss: 0.16794, val_acc: 0.96000\n",
      "Epoch [5930/10000], loss: 0.16266 acc: 0.98667 val_loss: 0.16782, val_acc: 0.96000\n",
      "Epoch [5940/10000], loss: 0.16253 acc: 0.98667 val_loss: 0.16771, val_acc: 0.96000\n",
      "Epoch [5950/10000], loss: 0.16239 acc: 0.98667 val_loss: 0.16759, val_acc: 0.96000\n",
      "Epoch [5960/10000], loss: 0.16226 acc: 0.98667 val_loss: 0.16747, val_acc: 0.96000\n",
      "Epoch [5970/10000], loss: 0.16212 acc: 0.98667 val_loss: 0.16735, val_acc: 0.96000\n",
      "Epoch [5980/10000], loss: 0.16199 acc: 0.98667 val_loss: 0.16724, val_acc: 0.96000\n",
      "Epoch [5990/10000], loss: 0.16186 acc: 0.98667 val_loss: 0.16712, val_acc: 0.96000\n",
      "Epoch [6000/10000], loss: 0.16172 acc: 0.98667 val_loss: 0.16700, val_acc: 0.96000\n",
      "Epoch [6010/10000], loss: 0.16159 acc: 0.98667 val_loss: 0.16689, val_acc: 0.96000\n",
      "Epoch [6020/10000], loss: 0.16146 acc: 0.98667 val_loss: 0.16677, val_acc: 0.96000\n",
      "Epoch [6030/10000], loss: 0.16133 acc: 0.98667 val_loss: 0.16665, val_acc: 0.96000\n",
      "Epoch [6040/10000], loss: 0.16120 acc: 0.98667 val_loss: 0.16654, val_acc: 0.96000\n",
      "Epoch [6050/10000], loss: 0.16107 acc: 0.98667 val_loss: 0.16642, val_acc: 0.96000\n",
      "Epoch [6060/10000], loss: 0.16093 acc: 0.98667 val_loss: 0.16631, val_acc: 0.96000\n",
      "Epoch [6070/10000], loss: 0.16080 acc: 0.98667 val_loss: 0.16620, val_acc: 0.96000\n",
      "Epoch [6080/10000], loss: 0.16067 acc: 0.98667 val_loss: 0.16608, val_acc: 0.96000\n",
      "Epoch [6090/10000], loss: 0.16055 acc: 0.98667 val_loss: 0.16597, val_acc: 0.96000\n",
      "Epoch [6100/10000], loss: 0.16042 acc: 0.98667 val_loss: 0.16585, val_acc: 0.96000\n",
      "Epoch [6110/10000], loss: 0.16029 acc: 0.98667 val_loss: 0.16574, val_acc: 0.96000\n",
      "Epoch [6120/10000], loss: 0.16016 acc: 0.98667 val_loss: 0.16563, val_acc: 0.96000\n",
      "Epoch [6130/10000], loss: 0.16003 acc: 0.98667 val_loss: 0.16552, val_acc: 0.96000\n",
      "Epoch [6140/10000], loss: 0.15990 acc: 0.98667 val_loss: 0.16540, val_acc: 0.96000\n",
      "Epoch [6150/10000], loss: 0.15978 acc: 0.98667 val_loss: 0.16529, val_acc: 0.96000\n",
      "Epoch [6160/10000], loss: 0.15965 acc: 0.98667 val_loss: 0.16518, val_acc: 0.96000\n",
      "Epoch [6170/10000], loss: 0.15952 acc: 0.98667 val_loss: 0.16507, val_acc: 0.96000\n",
      "Epoch [6180/10000], loss: 0.15939 acc: 0.98667 val_loss: 0.16496, val_acc: 0.96000\n",
      "Epoch [6190/10000], loss: 0.15927 acc: 0.98667 val_loss: 0.16485, val_acc: 0.96000\n",
      "Epoch [6200/10000], loss: 0.15914 acc: 0.98667 val_loss: 0.16474, val_acc: 0.96000\n",
      "Epoch [6210/10000], loss: 0.15902 acc: 0.98667 val_loss: 0.16463, val_acc: 0.96000\n",
      "Epoch [6220/10000], loss: 0.15889 acc: 0.98667 val_loss: 0.16452, val_acc: 0.96000\n",
      "Epoch [6230/10000], loss: 0.15877 acc: 0.98667 val_loss: 0.16441, val_acc: 0.96000\n",
      "Epoch [6240/10000], loss: 0.15864 acc: 0.98667 val_loss: 0.16430, val_acc: 0.96000\n",
      "Epoch [6250/10000], loss: 0.15852 acc: 0.98667 val_loss: 0.16419, val_acc: 0.96000\n",
      "Epoch [6260/10000], loss: 0.15839 acc: 0.98667 val_loss: 0.16408, val_acc: 0.96000\n",
      "Epoch [6270/10000], loss: 0.15827 acc: 0.98667 val_loss: 0.16398, val_acc: 0.96000\n",
      "Epoch [6280/10000], loss: 0.15815 acc: 0.98667 val_loss: 0.16387, val_acc: 0.96000\n",
      "Epoch [6290/10000], loss: 0.15802 acc: 0.98667 val_loss: 0.16376, val_acc: 0.96000\n",
      "Epoch [6300/10000], loss: 0.15790 acc: 0.98667 val_loss: 0.16365, val_acc: 0.96000\n",
      "Epoch [6310/10000], loss: 0.15778 acc: 0.98667 val_loss: 0.16355, val_acc: 0.96000\n",
      "Epoch [6320/10000], loss: 0.15766 acc: 0.98667 val_loss: 0.16344, val_acc: 0.96000\n",
      "Epoch [6330/10000], loss: 0.15754 acc: 0.98667 val_loss: 0.16333, val_acc: 0.96000\n",
      "Epoch [6340/10000], loss: 0.15741 acc: 0.98667 val_loss: 0.16323, val_acc: 0.96000\n",
      "Epoch [6350/10000], loss: 0.15729 acc: 0.98667 val_loss: 0.16312, val_acc: 0.96000\n",
      "Epoch [6360/10000], loss: 0.15717 acc: 0.98667 val_loss: 0.16302, val_acc: 0.96000\n",
      "Epoch [6370/10000], loss: 0.15705 acc: 0.98667 val_loss: 0.16291, val_acc: 0.96000\n",
      "Epoch [6380/10000], loss: 0.15693 acc: 0.98667 val_loss: 0.16281, val_acc: 0.96000\n",
      "Epoch [6390/10000], loss: 0.15681 acc: 0.98667 val_loss: 0.16270, val_acc: 0.96000\n",
      "Epoch [6400/10000], loss: 0.15669 acc: 0.98667 val_loss: 0.16260, val_acc: 0.96000\n",
      "Epoch [6410/10000], loss: 0.15657 acc: 0.98667 val_loss: 0.16249, val_acc: 0.96000\n",
      "Epoch [6420/10000], loss: 0.15645 acc: 0.98667 val_loss: 0.16239, val_acc: 0.96000\n",
      "Epoch [6430/10000], loss: 0.15634 acc: 0.98667 val_loss: 0.16228, val_acc: 0.96000\n",
      "Epoch [6440/10000], loss: 0.15622 acc: 0.98667 val_loss: 0.16218, val_acc: 0.96000\n",
      "Epoch [6450/10000], loss: 0.15610 acc: 0.98667 val_loss: 0.16208, val_acc: 0.96000\n",
      "Epoch [6460/10000], loss: 0.15598 acc: 0.98667 val_loss: 0.16198, val_acc: 0.96000\n",
      "Epoch [6470/10000], loss: 0.15586 acc: 0.98667 val_loss: 0.16187, val_acc: 0.96000\n",
      "Epoch [6480/10000], loss: 0.15575 acc: 0.98667 val_loss: 0.16177, val_acc: 0.96000\n",
      "Epoch [6490/10000], loss: 0.15563 acc: 0.98667 val_loss: 0.16167, val_acc: 0.96000\n",
      "Epoch [6500/10000], loss: 0.15551 acc: 0.98667 val_loss: 0.16157, val_acc: 0.96000\n",
      "Epoch [6510/10000], loss: 0.15540 acc: 0.98667 val_loss: 0.16147, val_acc: 0.96000\n",
      "Epoch [6520/10000], loss: 0.15528 acc: 0.98667 val_loss: 0.16136, val_acc: 0.96000\n",
      "Epoch [6530/10000], loss: 0.15516 acc: 0.98667 val_loss: 0.16126, val_acc: 0.96000\n",
      "Epoch [6540/10000], loss: 0.15505 acc: 0.98667 val_loss: 0.16116, val_acc: 0.96000\n",
      "Epoch [6550/10000], loss: 0.15493 acc: 0.98667 val_loss: 0.16106, val_acc: 0.96000\n",
      "Epoch [6560/10000], loss: 0.15482 acc: 0.98667 val_loss: 0.16096, val_acc: 0.96000\n",
      "Epoch [6570/10000], loss: 0.15470 acc: 0.98667 val_loss: 0.16086, val_acc: 0.96000\n",
      "Epoch [6580/10000], loss: 0.15459 acc: 0.98667 val_loss: 0.16076, val_acc: 0.96000\n",
      "Epoch [6590/10000], loss: 0.15448 acc: 0.98667 val_loss: 0.16066, val_acc: 0.96000\n",
      "Epoch [6600/10000], loss: 0.15436 acc: 0.98667 val_loss: 0.16056, val_acc: 0.96000\n",
      "Epoch [6610/10000], loss: 0.15425 acc: 0.98667 val_loss: 0.16047, val_acc: 0.96000\n",
      "Epoch [6620/10000], loss: 0.15414 acc: 0.98667 val_loss: 0.16037, val_acc: 0.96000\n",
      "Epoch [6630/10000], loss: 0.15402 acc: 0.98667 val_loss: 0.16027, val_acc: 0.96000\n",
      "Epoch [6640/10000], loss: 0.15391 acc: 0.98667 val_loss: 0.16017, val_acc: 0.96000\n",
      "Epoch [6650/10000], loss: 0.15380 acc: 0.98667 val_loss: 0.16007, val_acc: 0.96000\n",
      "Epoch [6660/10000], loss: 0.15369 acc: 0.98667 val_loss: 0.15998, val_acc: 0.96000\n",
      "Epoch [6670/10000], loss: 0.15357 acc: 0.98667 val_loss: 0.15988, val_acc: 0.96000\n",
      "Epoch [6680/10000], loss: 0.15346 acc: 0.98667 val_loss: 0.15978, val_acc: 0.96000\n",
      "Epoch [6690/10000], loss: 0.15335 acc: 0.98667 val_loss: 0.15968, val_acc: 0.96000\n",
      "Epoch [6700/10000], loss: 0.15324 acc: 0.98667 val_loss: 0.15959, val_acc: 0.96000\n",
      "Epoch [6710/10000], loss: 0.15313 acc: 0.98667 val_loss: 0.15949, val_acc: 0.96000\n",
      "Epoch [6720/10000], loss: 0.15302 acc: 0.98667 val_loss: 0.15939, val_acc: 0.96000\n",
      "Epoch [6730/10000], loss: 0.15291 acc: 0.98667 val_loss: 0.15930, val_acc: 0.96000\n",
      "Epoch [6740/10000], loss: 0.15280 acc: 0.98667 val_loss: 0.15920, val_acc: 0.96000\n",
      "Epoch [6750/10000], loss: 0.15269 acc: 0.98667 val_loss: 0.15911, val_acc: 0.96000\n",
      "Epoch [6760/10000], loss: 0.15258 acc: 0.98667 val_loss: 0.15901, val_acc: 0.96000\n",
      "Epoch [6770/10000], loss: 0.15247 acc: 0.98667 val_loss: 0.15892, val_acc: 0.96000\n",
      "Epoch [6780/10000], loss: 0.15236 acc: 0.98667 val_loss: 0.15882, val_acc: 0.96000\n",
      "Epoch [6790/10000], loss: 0.15225 acc: 0.98667 val_loss: 0.15873, val_acc: 0.96000\n",
      "Epoch [6800/10000], loss: 0.15215 acc: 0.98667 val_loss: 0.15863, val_acc: 0.96000\n",
      "Epoch [6810/10000], loss: 0.15204 acc: 0.98667 val_loss: 0.15854, val_acc: 0.96000\n",
      "Epoch [6820/10000], loss: 0.15193 acc: 0.98667 val_loss: 0.15845, val_acc: 0.96000\n",
      "Epoch [6830/10000], loss: 0.15182 acc: 0.98667 val_loss: 0.15835, val_acc: 0.96000\n",
      "Epoch [6840/10000], loss: 0.15171 acc: 0.98667 val_loss: 0.15826, val_acc: 0.96000\n",
      "Epoch [6850/10000], loss: 0.15161 acc: 0.98667 val_loss: 0.15817, val_acc: 0.96000\n",
      "Epoch [6860/10000], loss: 0.15150 acc: 0.98667 val_loss: 0.15807, val_acc: 0.96000\n",
      "Epoch [6870/10000], loss: 0.15139 acc: 0.98667 val_loss: 0.15798, val_acc: 0.96000\n",
      "Epoch [6880/10000], loss: 0.15129 acc: 0.98667 val_loss: 0.15789, val_acc: 0.96000\n",
      "Epoch [6890/10000], loss: 0.15118 acc: 0.98667 val_loss: 0.15780, val_acc: 0.96000\n",
      "Epoch [6900/10000], loss: 0.15108 acc: 0.98667 val_loss: 0.15771, val_acc: 0.96000\n",
      "Epoch [6910/10000], loss: 0.15097 acc: 0.98667 val_loss: 0.15761, val_acc: 0.96000\n",
      "Epoch [6920/10000], loss: 0.15086 acc: 0.98667 val_loss: 0.15752, val_acc: 0.96000\n",
      "Epoch [6930/10000], loss: 0.15076 acc: 0.98667 val_loss: 0.15743, val_acc: 0.96000\n",
      "Epoch [6940/10000], loss: 0.15065 acc: 0.98667 val_loss: 0.15734, val_acc: 0.96000\n",
      "Epoch [6950/10000], loss: 0.15055 acc: 0.98667 val_loss: 0.15725, val_acc: 0.96000\n",
      "Epoch [6960/10000], loss: 0.15045 acc: 0.98667 val_loss: 0.15716, val_acc: 0.96000\n",
      "Epoch [6970/10000], loss: 0.15034 acc: 0.98667 val_loss: 0.15707, val_acc: 0.96000\n",
      "Epoch [6980/10000], loss: 0.15024 acc: 0.98667 val_loss: 0.15698, val_acc: 0.96000\n",
      "Epoch [6990/10000], loss: 0.15013 acc: 0.98667 val_loss: 0.15689, val_acc: 0.96000\n",
      "Epoch [7000/10000], loss: 0.15003 acc: 0.98667 val_loss: 0.15680, val_acc: 0.96000\n",
      "Epoch [7010/10000], loss: 0.14993 acc: 0.98667 val_loss: 0.15671, val_acc: 0.96000\n",
      "Epoch [7020/10000], loss: 0.14983 acc: 0.98667 val_loss: 0.15662, val_acc: 0.96000\n",
      "Epoch [7030/10000], loss: 0.14972 acc: 0.98667 val_loss: 0.15653, val_acc: 0.96000\n",
      "Epoch [7040/10000], loss: 0.14962 acc: 0.98667 val_loss: 0.15644, val_acc: 0.96000\n",
      "Epoch [7050/10000], loss: 0.14952 acc: 0.98667 val_loss: 0.15636, val_acc: 0.96000\n",
      "Epoch [7060/10000], loss: 0.14942 acc: 0.98667 val_loss: 0.15627, val_acc: 0.96000\n",
      "Epoch [7070/10000], loss: 0.14931 acc: 0.98667 val_loss: 0.15618, val_acc: 0.96000\n",
      "Epoch [7080/10000], loss: 0.14921 acc: 0.98667 val_loss: 0.15609, val_acc: 0.96000\n",
      "Epoch [7090/10000], loss: 0.14911 acc: 0.98667 val_loss: 0.15600, val_acc: 0.96000\n",
      "Epoch [7100/10000], loss: 0.14901 acc: 0.98667 val_loss: 0.15592, val_acc: 0.96000\n",
      "Epoch [7110/10000], loss: 0.14891 acc: 0.98667 val_loss: 0.15583, val_acc: 0.96000\n",
      "Epoch [7120/10000], loss: 0.14881 acc: 0.98667 val_loss: 0.15574, val_acc: 0.96000\n",
      "Epoch [7130/10000], loss: 0.14871 acc: 0.98667 val_loss: 0.15565, val_acc: 0.96000\n",
      "Epoch [7140/10000], loss: 0.14861 acc: 0.98667 val_loss: 0.15557, val_acc: 0.96000\n",
      "Epoch [7150/10000], loss: 0.14851 acc: 0.98667 val_loss: 0.15548, val_acc: 0.96000\n",
      "Epoch [7160/10000], loss: 0.14841 acc: 0.98667 val_loss: 0.15540, val_acc: 0.96000\n",
      "Epoch [7170/10000], loss: 0.14831 acc: 0.98667 val_loss: 0.15531, val_acc: 0.96000\n",
      "Epoch [7180/10000], loss: 0.14821 acc: 0.98667 val_loss: 0.15522, val_acc: 0.96000\n",
      "Epoch [7190/10000], loss: 0.14811 acc: 0.98667 val_loss: 0.15514, val_acc: 0.96000\n",
      "Epoch [7200/10000], loss: 0.14801 acc: 0.98667 val_loss: 0.15505, val_acc: 0.96000\n",
      "Epoch [7210/10000], loss: 0.14792 acc: 0.98667 val_loss: 0.15497, val_acc: 0.96000\n",
      "Epoch [7220/10000], loss: 0.14782 acc: 0.98667 val_loss: 0.15488, val_acc: 0.96000\n",
      "Epoch [7230/10000], loss: 0.14772 acc: 0.98667 val_loss: 0.15480, val_acc: 0.96000\n",
      "Epoch [7240/10000], loss: 0.14762 acc: 0.98667 val_loss: 0.15471, val_acc: 0.96000\n",
      "Epoch [7250/10000], loss: 0.14752 acc: 0.98667 val_loss: 0.15463, val_acc: 0.96000\n",
      "Epoch [7260/10000], loss: 0.14743 acc: 0.98667 val_loss: 0.15455, val_acc: 0.96000\n",
      "Epoch [7270/10000], loss: 0.14733 acc: 0.98667 val_loss: 0.15446, val_acc: 0.96000\n",
      "Epoch [7280/10000], loss: 0.14723 acc: 0.98667 val_loss: 0.15438, val_acc: 0.96000\n",
      "Epoch [7290/10000], loss: 0.14714 acc: 0.98667 val_loss: 0.15429, val_acc: 0.96000\n",
      "Epoch [7300/10000], loss: 0.14704 acc: 0.98667 val_loss: 0.15421, val_acc: 0.96000\n",
      "Epoch [7310/10000], loss: 0.14694 acc: 0.98667 val_loss: 0.15413, val_acc: 0.96000\n",
      "Epoch [7320/10000], loss: 0.14685 acc: 0.98667 val_loss: 0.15404, val_acc: 0.96000\n",
      "Epoch [7330/10000], loss: 0.14675 acc: 0.98667 val_loss: 0.15396, val_acc: 0.96000\n",
      "Epoch [7340/10000], loss: 0.14666 acc: 0.98667 val_loss: 0.15388, val_acc: 0.96000\n",
      "Epoch [7350/10000], loss: 0.14656 acc: 0.98667 val_loss: 0.15380, val_acc: 0.96000\n",
      "Epoch [7360/10000], loss: 0.14646 acc: 0.98667 val_loss: 0.15371, val_acc: 0.96000\n",
      "Epoch [7370/10000], loss: 0.14637 acc: 0.98667 val_loss: 0.15363, val_acc: 0.96000\n",
      "Epoch [7380/10000], loss: 0.14627 acc: 0.98667 val_loss: 0.15355, val_acc: 0.96000\n",
      "Epoch [7390/10000], loss: 0.14618 acc: 0.98667 val_loss: 0.15347, val_acc: 0.96000\n",
      "Epoch [7400/10000], loss: 0.14609 acc: 0.98667 val_loss: 0.15339, val_acc: 0.96000\n",
      "Epoch [7410/10000], loss: 0.14599 acc: 0.98667 val_loss: 0.15331, val_acc: 0.96000\n",
      "Epoch [7420/10000], loss: 0.14590 acc: 0.98667 val_loss: 0.15323, val_acc: 0.96000\n",
      "Epoch [7430/10000], loss: 0.14580 acc: 0.98667 val_loss: 0.15314, val_acc: 0.96000\n",
      "Epoch [7440/10000], loss: 0.14571 acc: 0.98667 val_loss: 0.15306, val_acc: 0.96000\n",
      "Epoch [7450/10000], loss: 0.14562 acc: 0.98667 val_loss: 0.15298, val_acc: 0.96000\n",
      "Epoch [7460/10000], loss: 0.14552 acc: 0.98667 val_loss: 0.15290, val_acc: 0.96000\n",
      "Epoch [7470/10000], loss: 0.14543 acc: 0.98667 val_loss: 0.15282, val_acc: 0.96000\n",
      "Epoch [7480/10000], loss: 0.14534 acc: 0.98667 val_loss: 0.15274, val_acc: 0.96000\n",
      "Epoch [7490/10000], loss: 0.14525 acc: 0.98667 val_loss: 0.15266, val_acc: 0.96000\n",
      "Epoch [7500/10000], loss: 0.14515 acc: 0.98667 val_loss: 0.15258, val_acc: 0.96000\n",
      "Epoch [7510/10000], loss: 0.14506 acc: 0.98667 val_loss: 0.15250, val_acc: 0.96000\n",
      "Epoch [7520/10000], loss: 0.14497 acc: 0.98667 val_loss: 0.15243, val_acc: 0.96000\n",
      "Epoch [7530/10000], loss: 0.14488 acc: 0.98667 val_loss: 0.15235, val_acc: 0.96000\n",
      "Epoch [7540/10000], loss: 0.14479 acc: 0.98667 val_loss: 0.15227, val_acc: 0.96000\n",
      "Epoch [7550/10000], loss: 0.14470 acc: 0.98667 val_loss: 0.15219, val_acc: 0.96000\n",
      "Epoch [7560/10000], loss: 0.14460 acc: 0.98667 val_loss: 0.15211, val_acc: 0.96000\n",
      "Epoch [7570/10000], loss: 0.14451 acc: 0.98667 val_loss: 0.15203, val_acc: 0.96000\n",
      "Epoch [7580/10000], loss: 0.14442 acc: 0.98667 val_loss: 0.15195, val_acc: 0.96000\n",
      "Epoch [7590/10000], loss: 0.14433 acc: 0.98667 val_loss: 0.15188, val_acc: 0.96000\n",
      "Epoch [7600/10000], loss: 0.14424 acc: 0.98667 val_loss: 0.15180, val_acc: 0.96000\n",
      "Epoch [7610/10000], loss: 0.14415 acc: 0.98667 val_loss: 0.15172, val_acc: 0.96000\n",
      "Epoch [7620/10000], loss: 0.14406 acc: 0.98667 val_loss: 0.15164, val_acc: 0.96000\n",
      "Epoch [7630/10000], loss: 0.14397 acc: 0.98667 val_loss: 0.15157, val_acc: 0.96000\n",
      "Epoch [7640/10000], loss: 0.14388 acc: 0.98667 val_loss: 0.15149, val_acc: 0.96000\n",
      "Epoch [7650/10000], loss: 0.14379 acc: 0.98667 val_loss: 0.15141, val_acc: 0.96000\n",
      "Epoch [7660/10000], loss: 0.14370 acc: 0.98667 val_loss: 0.15134, val_acc: 0.96000\n",
      "Epoch [7670/10000], loss: 0.14362 acc: 0.98667 val_loss: 0.15126, val_acc: 0.96000\n",
      "Epoch [7680/10000], loss: 0.14353 acc: 0.98667 val_loss: 0.15118, val_acc: 0.96000\n",
      "Epoch [7690/10000], loss: 0.14344 acc: 0.98667 val_loss: 0.15111, val_acc: 0.96000\n",
      "Epoch [7700/10000], loss: 0.14335 acc: 0.98667 val_loss: 0.15103, val_acc: 0.96000\n",
      "Epoch [7710/10000], loss: 0.14326 acc: 0.98667 val_loss: 0.15096, val_acc: 0.96000\n",
      "Epoch [7720/10000], loss: 0.14317 acc: 0.98667 val_loss: 0.15088, val_acc: 0.96000\n",
      "Epoch [7730/10000], loss: 0.14309 acc: 0.98667 val_loss: 0.15081, val_acc: 0.96000\n",
      "Epoch [7740/10000], loss: 0.14300 acc: 0.98667 val_loss: 0.15073, val_acc: 0.96000\n",
      "Epoch [7750/10000], loss: 0.14291 acc: 0.98667 val_loss: 0.15065, val_acc: 0.96000\n",
      "Epoch [7760/10000], loss: 0.14282 acc: 0.98667 val_loss: 0.15058, val_acc: 0.96000\n",
      "Epoch [7770/10000], loss: 0.14274 acc: 0.98667 val_loss: 0.15050, val_acc: 0.96000\n",
      "Epoch [7780/10000], loss: 0.14265 acc: 0.98667 val_loss: 0.15043, val_acc: 0.96000\n",
      "Epoch [7790/10000], loss: 0.14256 acc: 0.98667 val_loss: 0.15036, val_acc: 0.96000\n",
      "Epoch [7800/10000], loss: 0.14248 acc: 0.98667 val_loss: 0.15028, val_acc: 0.96000\n",
      "Epoch [7810/10000], loss: 0.14239 acc: 0.98667 val_loss: 0.15021, val_acc: 0.96000\n",
      "Epoch [7820/10000], loss: 0.14230 acc: 0.98667 val_loss: 0.15013, val_acc: 0.96000\n",
      "Epoch [7830/10000], loss: 0.14222 acc: 0.98667 val_loss: 0.15006, val_acc: 0.96000\n",
      "Epoch [7840/10000], loss: 0.14213 acc: 0.98667 val_loss: 0.14999, val_acc: 0.96000\n",
      "Epoch [7850/10000], loss: 0.14205 acc: 0.98667 val_loss: 0.14991, val_acc: 0.96000\n",
      "Epoch [7860/10000], loss: 0.14196 acc: 0.98667 val_loss: 0.14984, val_acc: 0.96000\n",
      "Epoch [7870/10000], loss: 0.14188 acc: 0.98667 val_loss: 0.14977, val_acc: 0.96000\n",
      "Epoch [7880/10000], loss: 0.14179 acc: 0.98667 val_loss: 0.14969, val_acc: 0.96000\n",
      "Epoch [7890/10000], loss: 0.14171 acc: 0.98667 val_loss: 0.14962, val_acc: 0.96000\n",
      "Epoch [7900/10000], loss: 0.14162 acc: 0.98667 val_loss: 0.14955, val_acc: 0.96000\n",
      "Epoch [7910/10000], loss: 0.14154 acc: 0.98667 val_loss: 0.14948, val_acc: 0.96000\n",
      "Epoch [7920/10000], loss: 0.14145 acc: 0.98667 val_loss: 0.14940, val_acc: 0.96000\n",
      "Epoch [7930/10000], loss: 0.14137 acc: 0.98667 val_loss: 0.14933, val_acc: 0.96000\n",
      "Epoch [7940/10000], loss: 0.14128 acc: 0.98667 val_loss: 0.14926, val_acc: 0.96000\n",
      "Epoch [7950/10000], loss: 0.14120 acc: 0.98667 val_loss: 0.14919, val_acc: 0.96000\n",
      "Epoch [7960/10000], loss: 0.14112 acc: 0.98667 val_loss: 0.14912, val_acc: 0.96000\n",
      "Epoch [7970/10000], loss: 0.14103 acc: 0.98667 val_loss: 0.14904, val_acc: 0.96000\n",
      "Epoch [7980/10000], loss: 0.14095 acc: 0.98667 val_loss: 0.14897, val_acc: 0.96000\n",
      "Epoch [7990/10000], loss: 0.14087 acc: 0.98667 val_loss: 0.14890, val_acc: 0.96000\n",
      "Epoch [8000/10000], loss: 0.14078 acc: 0.98667 val_loss: 0.14883, val_acc: 0.96000\n",
      "Epoch [8010/10000], loss: 0.14070 acc: 0.98667 val_loss: 0.14876, val_acc: 0.96000\n",
      "Epoch [8020/10000], loss: 0.14062 acc: 0.98667 val_loss: 0.14869, val_acc: 0.96000\n",
      "Epoch [8030/10000], loss: 0.14054 acc: 0.98667 val_loss: 0.14862, val_acc: 0.96000\n",
      "Epoch [8040/10000], loss: 0.14045 acc: 0.98667 val_loss: 0.14855, val_acc: 0.96000\n",
      "Epoch [8050/10000], loss: 0.14037 acc: 0.98667 val_loss: 0.14848, val_acc: 0.96000\n",
      "Epoch [8060/10000], loss: 0.14029 acc: 0.98667 val_loss: 0.14841, val_acc: 0.96000\n",
      "Epoch [8070/10000], loss: 0.14021 acc: 0.98667 val_loss: 0.14834, val_acc: 0.96000\n",
      "Epoch [8080/10000], loss: 0.14013 acc: 0.98667 val_loss: 0.14827, val_acc: 0.96000\n",
      "Epoch [8090/10000], loss: 0.14004 acc: 0.98667 val_loss: 0.14820, val_acc: 0.96000\n",
      "Epoch [8100/10000], loss: 0.13996 acc: 0.98667 val_loss: 0.14813, val_acc: 0.96000\n",
      "Epoch [8110/10000], loss: 0.13988 acc: 0.98667 val_loss: 0.14806, val_acc: 0.96000\n",
      "Epoch [8120/10000], loss: 0.13980 acc: 0.98667 val_loss: 0.14799, val_acc: 0.96000\n",
      "Epoch [8130/10000], loss: 0.13972 acc: 0.98667 val_loss: 0.14792, val_acc: 0.96000\n",
      "Epoch [8140/10000], loss: 0.13964 acc: 0.98667 val_loss: 0.14785, val_acc: 0.96000\n",
      "Epoch [8150/10000], loss: 0.13956 acc: 0.98667 val_loss: 0.14778, val_acc: 0.96000\n",
      "Epoch [8160/10000], loss: 0.13948 acc: 0.98667 val_loss: 0.14771, val_acc: 0.96000\n",
      "Epoch [8170/10000], loss: 0.13940 acc: 0.98667 val_loss: 0.14765, val_acc: 0.96000\n",
      "Epoch [8180/10000], loss: 0.13932 acc: 0.98667 val_loss: 0.14758, val_acc: 0.96000\n",
      "Epoch [8190/10000], loss: 0.13924 acc: 0.98667 val_loss: 0.14751, val_acc: 0.96000\n",
      "Epoch [8200/10000], loss: 0.13916 acc: 0.98667 val_loss: 0.14744, val_acc: 0.96000\n",
      "Epoch [8210/10000], loss: 0.13908 acc: 0.98667 val_loss: 0.14737, val_acc: 0.96000\n",
      "Epoch [8220/10000], loss: 0.13900 acc: 0.98667 val_loss: 0.14731, val_acc: 0.96000\n",
      "Epoch [8230/10000], loss: 0.13892 acc: 0.98667 val_loss: 0.14724, val_acc: 0.96000\n",
      "Epoch [8240/10000], loss: 0.13884 acc: 0.98667 val_loss: 0.14717, val_acc: 0.96000\n",
      "Epoch [8250/10000], loss: 0.13876 acc: 0.98667 val_loss: 0.14710, val_acc: 0.96000\n",
      "Epoch [8260/10000], loss: 0.13869 acc: 0.98667 val_loss: 0.14704, val_acc: 0.96000\n",
      "Epoch [8270/10000], loss: 0.13861 acc: 0.98667 val_loss: 0.14697, val_acc: 0.96000\n",
      "Epoch [8280/10000], loss: 0.13853 acc: 0.98667 val_loss: 0.14690, val_acc: 0.96000\n",
      "Epoch [8290/10000], loss: 0.13845 acc: 0.98667 val_loss: 0.14684, val_acc: 0.96000\n",
      "Epoch [8300/10000], loss: 0.13837 acc: 0.98667 val_loss: 0.14677, val_acc: 0.96000\n",
      "Epoch [8310/10000], loss: 0.13829 acc: 0.98667 val_loss: 0.14670, val_acc: 0.96000\n",
      "Epoch [8320/10000], loss: 0.13822 acc: 0.98667 val_loss: 0.14664, val_acc: 0.96000\n",
      "Epoch [8330/10000], loss: 0.13814 acc: 0.98667 val_loss: 0.14657, val_acc: 0.96000\n",
      "Epoch [8340/10000], loss: 0.13806 acc: 0.98667 val_loss: 0.14650, val_acc: 0.96000\n",
      "Epoch [8350/10000], loss: 0.13798 acc: 0.98667 val_loss: 0.14644, val_acc: 0.96000\n",
      "Epoch [8360/10000], loss: 0.13791 acc: 0.98667 val_loss: 0.14637, val_acc: 0.96000\n",
      "Epoch [8370/10000], loss: 0.13783 acc: 0.98667 val_loss: 0.14631, val_acc: 0.96000\n",
      "Epoch [8380/10000], loss: 0.13775 acc: 0.98667 val_loss: 0.14624, val_acc: 0.96000\n",
      "Epoch [8390/10000], loss: 0.13768 acc: 0.98667 val_loss: 0.14618, val_acc: 0.96000\n",
      "Epoch [8400/10000], loss: 0.13760 acc: 0.98667 val_loss: 0.14611, val_acc: 0.96000\n",
      "Epoch [8410/10000], loss: 0.13752 acc: 0.98667 val_loss: 0.14605, val_acc: 0.96000\n",
      "Epoch [8420/10000], loss: 0.13745 acc: 0.98667 val_loss: 0.14598, val_acc: 0.96000\n",
      "Epoch [8430/10000], loss: 0.13737 acc: 0.98667 val_loss: 0.14592, val_acc: 0.96000\n",
      "Epoch [8440/10000], loss: 0.13730 acc: 0.98667 val_loss: 0.14585, val_acc: 0.96000\n",
      "Epoch [8450/10000], loss: 0.13722 acc: 0.98667 val_loss: 0.14579, val_acc: 0.96000\n",
      "Epoch [8460/10000], loss: 0.13714 acc: 0.98667 val_loss: 0.14572, val_acc: 0.96000\n",
      "Epoch [8470/10000], loss: 0.13707 acc: 0.98667 val_loss: 0.14566, val_acc: 0.96000\n",
      "Epoch [8480/10000], loss: 0.13699 acc: 0.98667 val_loss: 0.14559, val_acc: 0.96000\n",
      "Epoch [8490/10000], loss: 0.13692 acc: 0.98667 val_loss: 0.14553, val_acc: 0.96000\n",
      "Epoch [8500/10000], loss: 0.13684 acc: 0.98667 val_loss: 0.14547, val_acc: 0.96000\n",
      "Epoch [8510/10000], loss: 0.13677 acc: 0.98667 val_loss: 0.14540, val_acc: 0.96000\n",
      "Epoch [8520/10000], loss: 0.13669 acc: 0.98667 val_loss: 0.14534, val_acc: 0.96000\n",
      "Epoch [8530/10000], loss: 0.13662 acc: 0.98667 val_loss: 0.14528, val_acc: 0.96000\n",
      "Epoch [8540/10000], loss: 0.13654 acc: 0.98667 val_loss: 0.14521, val_acc: 0.96000\n",
      "Epoch [8550/10000], loss: 0.13647 acc: 0.98667 val_loss: 0.14515, val_acc: 0.96000\n",
      "Epoch [8560/10000], loss: 0.13640 acc: 0.98667 val_loss: 0.14509, val_acc: 0.96000\n",
      "Epoch [8570/10000], loss: 0.13632 acc: 0.98667 val_loss: 0.14502, val_acc: 0.96000\n",
      "Epoch [8580/10000], loss: 0.13625 acc: 0.98667 val_loss: 0.14496, val_acc: 0.96000\n",
      "Epoch [8590/10000], loss: 0.13617 acc: 0.98667 val_loss: 0.14490, val_acc: 0.96000\n",
      "Epoch [8600/10000], loss: 0.13610 acc: 0.98667 val_loss: 0.14483, val_acc: 0.96000\n",
      "Epoch [8610/10000], loss: 0.13603 acc: 0.98667 val_loss: 0.14477, val_acc: 0.96000\n",
      "Epoch [8620/10000], loss: 0.13595 acc: 0.98667 val_loss: 0.14471, val_acc: 0.96000\n",
      "Epoch [8630/10000], loss: 0.13588 acc: 0.98667 val_loss: 0.14465, val_acc: 0.96000\n",
      "Epoch [8640/10000], loss: 0.13581 acc: 0.98667 val_loss: 0.14459, val_acc: 0.96000\n",
      "Epoch [8650/10000], loss: 0.13574 acc: 0.98667 val_loss: 0.14452, val_acc: 0.96000\n",
      "Epoch [8660/10000], loss: 0.13566 acc: 0.98667 val_loss: 0.14446, val_acc: 0.96000\n",
      "Epoch [8670/10000], loss: 0.13559 acc: 0.98667 val_loss: 0.14440, val_acc: 0.96000\n",
      "Epoch [8680/10000], loss: 0.13552 acc: 0.98667 val_loss: 0.14434, val_acc: 0.96000\n",
      "Epoch [8690/10000], loss: 0.13545 acc: 0.98667 val_loss: 0.14428, val_acc: 0.96000\n",
      "Epoch [8700/10000], loss: 0.13537 acc: 0.98667 val_loss: 0.14422, val_acc: 0.96000\n",
      "Epoch [8710/10000], loss: 0.13530 acc: 0.98667 val_loss: 0.14415, val_acc: 0.96000\n",
      "Epoch [8720/10000], loss: 0.13523 acc: 0.98667 val_loss: 0.14409, val_acc: 0.96000\n",
      "Epoch [8730/10000], loss: 0.13516 acc: 0.98667 val_loss: 0.14403, val_acc: 0.96000\n",
      "Epoch [8740/10000], loss: 0.13509 acc: 0.98667 val_loss: 0.14397, val_acc: 0.96000\n",
      "Epoch [8750/10000], loss: 0.13501 acc: 0.98667 val_loss: 0.14391, val_acc: 0.96000\n",
      "Epoch [8760/10000], loss: 0.13494 acc: 0.98667 val_loss: 0.14385, val_acc: 0.96000\n",
      "Epoch [8770/10000], loss: 0.13487 acc: 0.98667 val_loss: 0.14379, val_acc: 0.96000\n",
      "Epoch [8780/10000], loss: 0.13480 acc: 0.98667 val_loss: 0.14373, val_acc: 0.96000\n",
      "Epoch [8790/10000], loss: 0.13473 acc: 0.98667 val_loss: 0.14367, val_acc: 0.96000\n",
      "Epoch [8800/10000], loss: 0.13466 acc: 0.98667 val_loss: 0.14361, val_acc: 0.96000\n",
      "Epoch [8810/10000], loss: 0.13459 acc: 0.98667 val_loss: 0.14355, val_acc: 0.96000\n",
      "Epoch [8820/10000], loss: 0.13452 acc: 0.98667 val_loss: 0.14349, val_acc: 0.96000\n",
      "Epoch [8830/10000], loss: 0.13445 acc: 0.98667 val_loss: 0.14343, val_acc: 0.96000\n",
      "Epoch [8840/10000], loss: 0.13438 acc: 0.98667 val_loss: 0.14337, val_acc: 0.96000\n",
      "Epoch [8850/10000], loss: 0.13431 acc: 0.98667 val_loss: 0.14331, val_acc: 0.96000\n",
      "Epoch [8860/10000], loss: 0.13424 acc: 0.98667 val_loss: 0.14325, val_acc: 0.96000\n",
      "Epoch [8870/10000], loss: 0.13417 acc: 0.98667 val_loss: 0.14319, val_acc: 0.96000\n",
      "Epoch [8880/10000], loss: 0.13410 acc: 0.98667 val_loss: 0.14313, val_acc: 0.96000\n",
      "Epoch [8890/10000], loss: 0.13403 acc: 0.98667 val_loss: 0.14308, val_acc: 0.96000\n",
      "Epoch [8900/10000], loss: 0.13396 acc: 0.98667 val_loss: 0.14302, val_acc: 0.96000\n",
      "Epoch [8910/10000], loss: 0.13389 acc: 0.98667 val_loss: 0.14296, val_acc: 0.96000\n",
      "Epoch [8920/10000], loss: 0.13382 acc: 0.98667 val_loss: 0.14290, val_acc: 0.96000\n",
      "Epoch [8930/10000], loss: 0.13375 acc: 0.98667 val_loss: 0.14284, val_acc: 0.96000\n",
      "Epoch [8940/10000], loss: 0.13368 acc: 0.98667 val_loss: 0.14278, val_acc: 0.96000\n",
      "Epoch [8950/10000], loss: 0.13361 acc: 0.98667 val_loss: 0.14272, val_acc: 0.96000\n",
      "Epoch [8960/10000], loss: 0.13354 acc: 0.98667 val_loss: 0.14267, val_acc: 0.96000\n",
      "Epoch [8970/10000], loss: 0.13347 acc: 0.98667 val_loss: 0.14261, val_acc: 0.96000\n",
      "Epoch [8980/10000], loss: 0.13341 acc: 0.98667 val_loss: 0.14255, val_acc: 0.96000\n",
      "Epoch [8990/10000], loss: 0.13334 acc: 0.98667 val_loss: 0.14249, val_acc: 0.96000\n",
      "Epoch [9000/10000], loss: 0.13327 acc: 0.98667 val_loss: 0.14243, val_acc: 0.96000\n",
      "Epoch [9010/10000], loss: 0.13320 acc: 0.98667 val_loss: 0.14238, val_acc: 0.96000\n",
      "Epoch [9020/10000], loss: 0.13313 acc: 0.98667 val_loss: 0.14232, val_acc: 0.96000\n",
      "Epoch [9030/10000], loss: 0.13307 acc: 0.98667 val_loss: 0.14226, val_acc: 0.96000\n",
      "Epoch [9040/10000], loss: 0.13300 acc: 0.98667 val_loss: 0.14220, val_acc: 0.96000\n",
      "Epoch [9050/10000], loss: 0.13293 acc: 0.98667 val_loss: 0.14215, val_acc: 0.96000\n",
      "Epoch [9060/10000], loss: 0.13286 acc: 0.98667 val_loss: 0.14209, val_acc: 0.96000\n",
      "Epoch [9070/10000], loss: 0.13280 acc: 0.98667 val_loss: 0.14203, val_acc: 0.96000\n",
      "Epoch [9080/10000], loss: 0.13273 acc: 0.98667 val_loss: 0.14198, val_acc: 0.96000\n",
      "Epoch [9090/10000], loss: 0.13266 acc: 0.98667 val_loss: 0.14192, val_acc: 0.96000\n",
      "Epoch [9100/10000], loss: 0.13259 acc: 0.98667 val_loss: 0.14186, val_acc: 0.96000\n",
      "Epoch [9110/10000], loss: 0.13253 acc: 0.98667 val_loss: 0.14181, val_acc: 0.96000\n",
      "Epoch [9120/10000], loss: 0.13246 acc: 0.98667 val_loss: 0.14175, val_acc: 0.96000\n",
      "Epoch [9130/10000], loss: 0.13239 acc: 0.98667 val_loss: 0.14169, val_acc: 0.96000\n",
      "Epoch [9140/10000], loss: 0.13233 acc: 0.98667 val_loss: 0.14164, val_acc: 0.96000\n",
      "Epoch [9150/10000], loss: 0.13226 acc: 0.98667 val_loss: 0.14158, val_acc: 0.96000\n",
      "Epoch [9160/10000], loss: 0.13220 acc: 0.98667 val_loss: 0.14153, val_acc: 0.96000\n",
      "Epoch [9170/10000], loss: 0.13213 acc: 0.98667 val_loss: 0.14147, val_acc: 0.96000\n",
      "Epoch [9180/10000], loss: 0.13206 acc: 0.98667 val_loss: 0.14141, val_acc: 0.96000\n",
      "Epoch [9190/10000], loss: 0.13200 acc: 0.98667 val_loss: 0.14136, val_acc: 0.96000\n",
      "Epoch [9200/10000], loss: 0.13193 acc: 0.98667 val_loss: 0.14130, val_acc: 0.96000\n",
      "Epoch [9210/10000], loss: 0.13187 acc: 0.98667 val_loss: 0.14125, val_acc: 0.96000\n",
      "Epoch [9220/10000], loss: 0.13180 acc: 0.98667 val_loss: 0.14119, val_acc: 0.96000\n",
      "Epoch [9230/10000], loss: 0.13174 acc: 0.98667 val_loss: 0.14114, val_acc: 0.96000\n",
      "Epoch [9240/10000], loss: 0.13167 acc: 0.98667 val_loss: 0.14108, val_acc: 0.96000\n",
      "Epoch [9250/10000], loss: 0.13160 acc: 0.98667 val_loss: 0.14103, val_acc: 0.96000\n",
      "Epoch [9260/10000], loss: 0.13154 acc: 0.98667 val_loss: 0.14097, val_acc: 0.96000\n",
      "Epoch [9270/10000], loss: 0.13147 acc: 0.98667 val_loss: 0.14092, val_acc: 0.96000\n",
      "Epoch [9280/10000], loss: 0.13141 acc: 0.98667 val_loss: 0.14086, val_acc: 0.96000\n",
      "Epoch [9290/10000], loss: 0.13135 acc: 0.98667 val_loss: 0.14081, val_acc: 0.96000\n",
      "Epoch [9300/10000], loss: 0.13128 acc: 0.98667 val_loss: 0.14075, val_acc: 0.96000\n",
      "Epoch [9310/10000], loss: 0.13122 acc: 0.98667 val_loss: 0.14070, val_acc: 0.96000\n",
      "Epoch [9320/10000], loss: 0.13115 acc: 0.98667 val_loss: 0.14065, val_acc: 0.96000\n",
      "Epoch [9330/10000], loss: 0.13109 acc: 0.98667 val_loss: 0.14059, val_acc: 0.96000\n",
      "Epoch [9340/10000], loss: 0.13102 acc: 0.98667 val_loss: 0.14054, val_acc: 0.96000\n",
      "Epoch [9350/10000], loss: 0.13096 acc: 0.98667 val_loss: 0.14048, val_acc: 0.96000\n",
      "Epoch [9360/10000], loss: 0.13090 acc: 0.98667 val_loss: 0.14043, val_acc: 0.96000\n",
      "Epoch [9370/10000], loss: 0.13083 acc: 0.98667 val_loss: 0.14038, val_acc: 0.96000\n",
      "Epoch [9380/10000], loss: 0.13077 acc: 0.98667 val_loss: 0.14032, val_acc: 0.96000\n",
      "Epoch [9390/10000], loss: 0.13070 acc: 0.98667 val_loss: 0.14027, val_acc: 0.96000\n",
      "Epoch [9400/10000], loss: 0.13064 acc: 0.98667 val_loss: 0.14022, val_acc: 0.96000\n",
      "Epoch [9410/10000], loss: 0.13058 acc: 0.98667 val_loss: 0.14016, val_acc: 0.96000\n",
      "Epoch [9420/10000], loss: 0.13051 acc: 0.98667 val_loss: 0.14011, val_acc: 0.96000\n",
      "Epoch [9430/10000], loss: 0.13045 acc: 0.98667 val_loss: 0.14006, val_acc: 0.96000\n",
      "Epoch [9440/10000], loss: 0.13039 acc: 0.98667 val_loss: 0.14000, val_acc: 0.96000\n",
      "Epoch [9450/10000], loss: 0.13033 acc: 0.98667 val_loss: 0.13995, val_acc: 0.96000\n",
      "Epoch [9460/10000], loss: 0.13026 acc: 0.98667 val_loss: 0.13990, val_acc: 0.96000\n",
      "Epoch [9470/10000], loss: 0.13020 acc: 0.98667 val_loss: 0.13984, val_acc: 0.96000\n",
      "Epoch [9480/10000], loss: 0.13014 acc: 0.98667 val_loss: 0.13979, val_acc: 0.96000\n",
      "Epoch [9490/10000], loss: 0.13008 acc: 0.98667 val_loss: 0.13974, val_acc: 0.96000\n",
      "Epoch [9500/10000], loss: 0.13001 acc: 0.98667 val_loss: 0.13969, val_acc: 0.96000\n",
      "Epoch [9510/10000], loss: 0.12995 acc: 0.98667 val_loss: 0.13963, val_acc: 0.96000\n",
      "Epoch [9520/10000], loss: 0.12989 acc: 0.98667 val_loss: 0.13958, val_acc: 0.96000\n",
      "Epoch [9530/10000], loss: 0.12983 acc: 0.98667 val_loss: 0.13953, val_acc: 0.96000\n",
      "Epoch [9540/10000], loss: 0.12976 acc: 0.98667 val_loss: 0.13948, val_acc: 0.96000\n",
      "Epoch [9550/10000], loss: 0.12970 acc: 0.98667 val_loss: 0.13943, val_acc: 0.96000\n",
      "Epoch [9560/10000], loss: 0.12964 acc: 0.98667 val_loss: 0.13937, val_acc: 0.96000\n",
      "Epoch [9570/10000], loss: 0.12958 acc: 0.98667 val_loss: 0.13932, val_acc: 0.96000\n",
      "Epoch [9580/10000], loss: 0.12952 acc: 0.98667 val_loss: 0.13927, val_acc: 0.96000\n",
      "Epoch [9590/10000], loss: 0.12946 acc: 0.98667 val_loss: 0.13922, val_acc: 0.96000\n",
      "Epoch [9600/10000], loss: 0.12940 acc: 0.98667 val_loss: 0.13917, val_acc: 0.96000\n",
      "Epoch [9610/10000], loss: 0.12933 acc: 0.98667 val_loss: 0.13912, val_acc: 0.96000\n",
      "Epoch [9620/10000], loss: 0.12927 acc: 0.98667 val_loss: 0.13907, val_acc: 0.96000\n",
      "Epoch [9630/10000], loss: 0.12921 acc: 0.98667 val_loss: 0.13901, val_acc: 0.96000\n",
      "Epoch [9640/10000], loss: 0.12915 acc: 0.98667 val_loss: 0.13896, val_acc: 0.96000\n",
      "Epoch [9650/10000], loss: 0.12909 acc: 0.98667 val_loss: 0.13891, val_acc: 0.96000\n",
      "Epoch [9660/10000], loss: 0.12903 acc: 0.98667 val_loss: 0.13886, val_acc: 0.96000\n",
      "Epoch [9670/10000], loss: 0.12897 acc: 0.98667 val_loss: 0.13881, val_acc: 0.96000\n",
      "Epoch [9680/10000], loss: 0.12891 acc: 0.98667 val_loss: 0.13876, val_acc: 0.96000\n",
      "Epoch [9690/10000], loss: 0.12885 acc: 0.98667 val_loss: 0.13871, val_acc: 0.96000\n",
      "Epoch [9700/10000], loss: 0.12879 acc: 0.98667 val_loss: 0.13866, val_acc: 0.96000\n",
      "Epoch [9710/10000], loss: 0.12873 acc: 0.98667 val_loss: 0.13861, val_acc: 0.96000\n",
      "Epoch [9720/10000], loss: 0.12867 acc: 0.98667 val_loss: 0.13856, val_acc: 0.96000\n",
      "Epoch [9730/10000], loss: 0.12861 acc: 0.98667 val_loss: 0.13851, val_acc: 0.96000\n",
      "Epoch [9740/10000], loss: 0.12855 acc: 0.98667 val_loss: 0.13846, val_acc: 0.96000\n",
      "Epoch [9750/10000], loss: 0.12849 acc: 0.98667 val_loss: 0.13841, val_acc: 0.96000\n",
      "Epoch [9760/10000], loss: 0.12843 acc: 0.98667 val_loss: 0.13836, val_acc: 0.96000\n",
      "Epoch [9770/10000], loss: 0.12837 acc: 0.98667 val_loss: 0.13831, val_acc: 0.96000\n",
      "Epoch [9780/10000], loss: 0.12831 acc: 0.98667 val_loss: 0.13826, val_acc: 0.96000\n",
      "Epoch [9790/10000], loss: 0.12825 acc: 0.98667 val_loss: 0.13821, val_acc: 0.96000\n",
      "Epoch [9800/10000], loss: 0.12819 acc: 0.98667 val_loss: 0.13816, val_acc: 0.96000\n",
      "Epoch [9810/10000], loss: 0.12813 acc: 0.98667 val_loss: 0.13811, val_acc: 0.96000\n",
      "Epoch [9820/10000], loss: 0.12808 acc: 0.98667 val_loss: 0.13806, val_acc: 0.96000\n",
      "Epoch [9830/10000], loss: 0.12802 acc: 0.98667 val_loss: 0.13801, val_acc: 0.96000\n",
      "Epoch [9840/10000], loss: 0.12796 acc: 0.98667 val_loss: 0.13796, val_acc: 0.96000\n",
      "Epoch [9850/10000], loss: 0.12790 acc: 0.98667 val_loss: 0.13791, val_acc: 0.96000\n",
      "Epoch [9860/10000], loss: 0.12784 acc: 0.98667 val_loss: 0.13786, val_acc: 0.96000\n",
      "Epoch [9870/10000], loss: 0.12778 acc: 0.98667 val_loss: 0.13782, val_acc: 0.96000\n",
      "Epoch [9880/10000], loss: 0.12772 acc: 0.98667 val_loss: 0.13777, val_acc: 0.96000\n",
      "Epoch [9890/10000], loss: 0.12767 acc: 0.98667 val_loss: 0.13772, val_acc: 0.96000\n",
      "Epoch [9900/10000], loss: 0.12761 acc: 0.98667 val_loss: 0.13767, val_acc: 0.96000\n",
      "Epoch [9910/10000], loss: 0.12755 acc: 0.98667 val_loss: 0.13762, val_acc: 0.96000\n",
      "Epoch [9920/10000], loss: 0.12749 acc: 0.98667 val_loss: 0.13757, val_acc: 0.96000\n",
      "Epoch [9930/10000], loss: 0.12743 acc: 0.98667 val_loss: 0.13752, val_acc: 0.96000\n",
      "Epoch [9940/10000], loss: 0.12738 acc: 0.98667 val_loss: 0.13748, val_acc: 0.96000\n",
      "Epoch [9950/10000], loss: 0.12732 acc: 0.98667 val_loss: 0.13743, val_acc: 0.96000\n",
      "Epoch [9960/10000], loss: 0.12726 acc: 0.98667 val_loss: 0.13738, val_acc: 0.96000\n",
      "Epoch [9970/10000], loss: 0.12720 acc: 0.98667 val_loss: 0.13733, val_acc: 0.96000\n",
      "Epoch [9980/10000], loss: 0.12715 acc: 0.98667 val_loss: 0.13728, val_acc: 0.96000\n",
      "Epoch [9990/10000], loss: 0.12709 acc: 0.98667 val_loss: 0.13724, val_acc: 0.96000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 훈련 페이즈\n",
    "    \n",
    "    # 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # 여기서 로그 함수를 적용함\n",
    "    outputs2 = torch.log(outputs)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs2, labels)\n",
    "\n",
    "    # 경사 계산\n",
    "    loss.backward()\n",
    "    \n",
    "    # 파라미터 수정\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    train_loss = loss.item()\n",
    "    train_acc = (predicted == labels).sum()  / len(labels)\n",
    "\n",
    "    # 예측 페이즈\n",
    "\n",
    "    # 예측 계산\n",
    "    outputs_test = net(inputs_test)\n",
    "        \n",
    "    # 여기서 로그 함수를 적용함\n",
    "    outputs2_test = torch.log(outputs_test)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss_test = criterion(outputs2_test, labels_test)\n",
    "\n",
    "    # 예측 라벨 산출\n",
    "    predicted_test = torch.max(outputs_test, 1)[1]\n",
    "\n",
    "    # 손실과 정확도 계산\n",
    "    val_loss =  loss_test.item()\n",
    "    val_acc =  (predicted_test == labels_test).sum() / len(labels_test)\n",
    "    \n",
    "    if ( epoch % 10 == 0):\n",
    "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "        item = np.array([epoch , train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기상태 : 손실 : 1.09158  정확도 : 0.26667\n",
      "최종상태 : 손실 : 0.13724  정확도 : 0.96000\n"
     ]
    }
   ],
   "source": [
    "# 손실과 정확도 확인\n",
    "\n",
    "print(f'초기상태 : 손실 : {history[0,3]:.5f}  정확도 : {history[0,4]:.5f}' )\n",
    "print(f'최종상태 : 손실 : {history[-1,3]:.5f}  정확도 : {history[-1,4]:.5f}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0059 0.9056 0.0885]\n",
      " [0.0069 0.9792 0.0139]\n",
      " [0.9452 0.0548 0.    ]\n",
      " [0.     0.0404 0.9596]\n",
      " [0.0001 0.1743 0.8256]]\n"
     ]
    }
   ],
   "source": [
    "# 패턴 3 모델의 출력값\n",
    "w = outputs[:5,:].data.numpy()\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu_py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
