{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 OpenCV를 이용한 객체 검출,  동영상 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 객체 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"fig\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소벨 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# src = cv2.imread(\"./fig/bamboo.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "src = cv2.imread(Path(folder, \"bamboo.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "# kernel\n",
    "\n",
    "\n",
    "dst = cv2.filter2D(src, -1, kernel)\n",
    "\n",
    "cv2.imshow(\"dst\", src)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, \"bamboo.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "# src = cv2.imread(\"./fig/plates.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]], np.float32)\n",
    "# print(kernel)\n",
    "# print(kernel.T)\n",
    "\n",
    "dst1 = cv2.filter2D(src, -1, kernel)\n",
    "dst2 = cv2.filter2D(src, -1, kernel.T)\n",
    "\n",
    "cv2.imshow(\"bamboo\", src)\n",
    "cv2.imshow(\"dst1\", dst1)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sobel filter\n",
    "# cv2.Sobel(src, ddepth, dx, dy, dst, ksize, scale, delt, borderType) -> dst\n",
    "# src : 입력영상\n",
    "# ddepth : 출력영상의 데이터 타입 (-1)\n",
    "# dx : x 방향 미분차수\n",
    "# dy : x 방향 미분차수\n",
    "# dst : 출력영상\n",
    "# ksize : 커널의 크기\n",
    "# scale : 연산결과에 추가적으로 곱할 값\n",
    "# delta : 연산결과에 추가적으로 더할 값\n",
    "# borderType : 가장자리 픽셀확장 방식\n",
    "\n",
    "# magnitude(x, y, magnitude) -> magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = cv2.imread(\"./fig/son.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "src = cv2.imread(Path(folder, \"son.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "dx = cv2.Sobel(src, cv2.CV_32F, 1, 0)\n",
    "dy = cv2.Sobel(src, cv2.CV_32F, 0, 1)\n",
    "\n",
    "mag = cv2.magnitude(dx, dy)\n",
    "mag = np.clip(mag,  0, 255).astype(np.uint8)\n",
    "\n",
    "ret, dst = cv2.threshold(mag, 150, 255, cv2.THRESH_BINARY)\n",
    "background = np.zeros((mag.shape[0], mag.shape[1]), np.uint8)\n",
    "background[mag > 150] = 255\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "# cv2.imshow(\"dx\", dx)\n",
    "# cv2.imshow(\"dy\", dy)\n",
    "cv2.imshow(\"mag\", mag)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.imshow(\"background\", background)\n",
    "\n",
    "\n",
    "# plt.imshow(mag, cmap = \"gray\")\n",
    "# plt.show()\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny 에지필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Canny edge\n",
    "# Canny(image, threshold1, threshold2, edges, apertureSize, L2gradient) -> edges\n",
    "# image : 입력 영상\n",
    "# threshold1: 에지결정 하한값\n",
    "# threshold1: 에지결정 상한값\n",
    "# edges: None\n",
    "# apertureSize: 커널사이즈\n",
    "# L2gradient: gradient 크기 계산, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, \"son.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "dst = cv2.Canny(src, 150, 180)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough 변환: 직선검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 직선 검출, 곡선 검출; 허프 변환 (Hough transform)\n",
    "# HoughLinesP(image, rho, theta, threshold, lines, minLineLength, maxLineGap) -> lines\n",
    "# image: 입력 에지영상\n",
    "# rho: 축적배열에서 rho의 간격\n",
    "# theta: 축적배열에서 theta의 간격\n",
    "# threshold: 직선판단할 임계값\n",
    "# lines: 선분의 끝좌표 (x1, y1, x2, y2)\n",
    "# srn = None, stn = None\n",
    "# minLineLength: 검출한 선분의 최소 길이\n",
    "# maxLineGap: 직선으로 간주할 최대 에지 점 간격 (끝어진 점을 연결할 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread(\"./fig/checkerboard.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread(Path(folder, \"checkerboard.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "edge = cv2.Canny(img, 100, 200)\n",
    "# ret, edge = cv2.threshold(edge, )\n",
    "\n",
    "lines = cv2.HoughLinesP(edge, 1, np.pi/360, 100, minLineLength = 10, maxLineGap = 30)\n",
    "print(lines.shape[0]) # 라인갯수\n",
    "\n",
    "dst = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i in range(lines.shape[0]):\n",
    "    pt1 = (lines[i][0][0], lines[i][0][1])\n",
    "    pt2 = (lines[i][0][2], lines[i][0][3])\n",
    "    cv2.line(dst, pt1, pt2, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('edge', edge)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough 변환: 곡선검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) -> circles\n",
    "# image: 입력영상\n",
    "# method: cv2.HOUGH_GRADIENT,\n",
    "# dp: 입력영상에 대한 실제 영상처리 배율, 1,  2 설정\n",
    "# minDist: 검출된 원들간의 최소거리\n",
    "# circles: 원좌표 (cx, cy, r), shape = (1, N, 3), dtype = np.float32\n",
    "# param1: Canny edge max 값\n",
    "# param2: 축척배열에서 원검출 임계값\n",
    "# minRadius: 원 크기의 최소값\n",
    "# maxRadius: 원 크기의 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "## Hough transform, 원 검출\n",
    "\n",
    "# src = cv2.imread(\"./fig/plates.png\")\n",
    "src = cv2.imread(Path(folder, \"plates.png\"))\n",
    "\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "# src_gray =  255 - src_gray\n",
    "circles = cv2.HoughCircles(src_gray, cv2.HOUGH_GRADIENT, 1, \n",
    "                           50, param1=200, param2= 100, minRadius=50, maxRadius=150)\n",
    "\n",
    "print(circles.shape[1])\n",
    "\n",
    "for i in range(circles.shape[1]):\n",
    "    cx, cy, radius = circles[0][i]\n",
    "    cv2.circle(src, (int(cx), int(cy)), int(radius), (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow(\"src-gray\", src_gray)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블링 (labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 레이블링 (labeling)\n",
    "\n",
    "# connectedComponentsWithStats(image[, labels[, stats[, centroids[, connectivity[, ltype]]]]]) -> retval, labels, stats, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0    512    512 217198]\n",
      "count =  2\n"
     ]
    }
   ],
   "source": [
    "# src = cv2.imread(\"./fig/symbols.png\")\n",
    "src = cv2.imread(Path(folder, \"symbols.png\"))\n",
    "\n",
    "# src = cv2.GaussianBlur(src, (0, 0), 1)\n",
    "\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(src_gray, 100, 255, cv2.THRESH_BINARY)\n",
    "# mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, None)\n",
    "\n",
    "\n",
    "cnts, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "print(stats[1])\n",
    "\n",
    "for i in range(1, cnts):\n",
    "    (x, y, w, h, area) = stats[i]\n",
    "\n",
    "    if area <= 50:\n",
    "        continue\n",
    "\n",
    "    cv2.rectangle(src, (x, y, w, h), (0, 0, 255), 2)\n",
    "\n",
    "print(\"count = \", cnts)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "# cv2.imshow(\"gray\", src_gray)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 외곽선 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 외곽선 검출\n",
    "# findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> contours, hierarchy\n",
    "    # image: 입력 영상. non-zero 픽셀을 객체로 간주함.\n",
    "    # mode: 외곽선 검출 모드. cv2.RETR_로 시작하는 상수. \n",
    "    #     (cv2.RETR_EXTERNAL, cv2.RETR_LIST,cv2.RETR_CCOMP, cv2.RETR_TREE)\n",
    "    # method: 외곽선 근사화 방법. cv2.CHAIN_APPROX_로 시작하는 상수.\n",
    "    # contour: 검출된 외곽선 좌표. numpy.ndarray로 구성된 리스트. \n",
    "    # contours[i].shape=(K, 1, 2). contours[i].dtype=numpy.int32.\n",
    "    # hierarchy: 외곽선 계층 정보. numpy.ndarray. shape=(1, N, 4). dtype=numpy.int32.\n",
    "    # hierarchy[0, i, 0] ~ hierarchy[0, i, 3]이 순서대로 next, prev, child, parent\n",
    "    # 외곽선 인덱스를 가리킴. 해당 외곽선이 없으면 -1.\n",
    "    # offset: 좌표 값 이동 옵셋. 기본값은 (0, 0).\n",
    "    \n",
    "# drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = cv2.imread(\"./fig/shape.png\")\n",
    "src = cv2.imread(Path(folder, \"shape.png\"))\n",
    "\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(src_gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "contours, hierachy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "for i in range(len(contours)):\n",
    "    cv2.drawContours(src, contours, i, (0, 0, 255), 1)\n",
    "    cv2.putText(src, str(i), contours[i][0][0], cv2.FONT_HERSHEY_COMPLEX, 1,\n",
    "                (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_gray', src_gray)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기하학적 모멘트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기하학적 모멘트 (Hu 불변 모멘트)\n",
    "# obj = cv2.imread(\"./fig/spades.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# src = cv2.imread(\"./fig/symbols.png\", cv2.IMREAD_GRAYSCALE)\n",
    "obj = cv2.imread(Path(folder, \"spades.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "src = cv2.imread(Path(folder, \"symbols.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "\n",
    "_, obj_bin = cv2.threshold(obj, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "obj_contours, _ = cv2.findContours(obj_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "obj_pts = obj_contours[0]\n",
    "_, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "src_contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for pts in src_contours:\n",
    "    if cv2.contourArea(pts) < 1000:\n",
    "        continue\n",
    "    rc = cv2.boundingRect(pts)\n",
    "    cv2.rectangle(dst, rc, (255, 0, 0), 1)\n",
    "    dist = cv2.matchShapes(obj_pts, pts, cv2.CONTOURS_MATCH_I3, 0)\n",
    "    cv2.putText(dst, str(round(dist, 3)), (rc[0], rc[1] - 3), cv2.FONT_HERSHEY_COMPLEX, 0.8,\n",
    "                (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    if dist < 0.1:\n",
    "        cv2.rectangle(dst, rc, (0, 0, 255), 2)\n",
    "        cv2.putText(dst, str(round(dist, 3)), (rc[0], rc[1] - 3), cv2.FONT_HERSHEY_COMPLEX, 0.8,\n",
    "                (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "cv2.imshow(\"obj\", obj)\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "# cv2.imshow(\"obj_bin\", obj_bin)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동영상 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동영상 객체 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.VideoCapture(index/filename, apiPreference=None) -> retval\n",
    "# index: camera_id or filename\n",
    "# apiPreference=None\n",
    "\n",
    "# cv2.VideoWriter(filename, fourcc, fps, framesize, isColor=None) -> retval\n",
    "# filename: 저장할 이름\n",
    "# fourcc: cv2.VideoWriter_fourcc(*'DIVX') 를 사용\n",
    "# fps: 초당 프레임 수 e.g. 30\n",
    "# frameSize: 프레임 크기 e.g., [640, 480])\n",
    "# isColor: Color 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cap = cv2.VideoCapture(\"./fig/PETS2000.avi\")\n",
    "cap = cv2.VideoCapture(Path(folder, \"PETS2000.avi\"))\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Video open failed\")\n",
    "    sys.exit()\n",
    "\n",
    "ret, background = cap.read()\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray_G = cv2.GaussianBlur(background_gray, (0, 0), 1.) \n",
    "# cv2.imshow(\"background\", background)\n",
    "# cv2.waitKey()\n",
    "while True:\n",
    "    ret, frame = cap.read() # fps: frame per second\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray_G = cv2.GaussianBlur(frame_gray, (0, 0), 1.)\n",
    "    diff_G = cv2.absdiff(frame_gray_G, background_gray_G)\n",
    "    ret_g, mask_g = cv2.threshold(diff_G, 50, 255, cv2.THRESH_BINARY)\n",
    "    cnts, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_g)\n",
    "    for i in range(1, cnts):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area <= 200:\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"diff\", diff_G)\n",
    "    cv2.imshow(\"mask_g\", mask_g)\n",
    "\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이동 평균 배경 차분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulateWeighted(src, dst, alpha, mask) -> dst\n",
    "# src: 입력영상\n",
    "# dis: 출력영상 (32bit, 64bit)\n",
    "# alpha : 축적가중치\n",
    "# mask: 마스트 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이동 평균 배경 차분\n",
    "cap = cv2.VideoCapture(Path(folder, \"PETS2000.avi\"))\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Video open failed\")\n",
    "    sys.exit()\n",
    "ret, back = cap.read()\n",
    "back = cv2.cvtColor(back, cv2.COLOR_BGR2GRAY)\n",
    "back = cv2.GaussianBlur(back, (0, 0), 1.)\n",
    "fback = back.astype(np.float32)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"frame is None\")\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (0, 0), 1)\n",
    "    cv2.accumulateWeighted(frame_gray, fback, 0.01)\n",
    "    back = fback.astype(np.uint8)\n",
    "    diff = cv2.absdiff(frame_gray, back)\n",
    "    ret, mask = cv2.threshold(diff, 50, 255, cv2.THRESH_BINARY)\n",
    "    cnts, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "    for i in range(1, cnts):\n",
    "        x, y, w, h, area = stats[i]\n",
    "        if area < 100:\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    cv2.imshow(\"mask\",mask)\n",
    "    cv2.imshow(\"back\",back)\n",
    "    \n",
    "    if cv2.waitKey(20) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webcam 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame width: 640\n",
      "Frame height: 480\n"
     ]
    }
   ],
   "source": [
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "# cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "# cap = cv2.VideoCapture('raining.mp4')\n",
    "\n",
    "if not cap.isOpened(): #True or Falose\n",
    "    print(\"Camera open failed\")\n",
    "    cap.release()\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# 카메라 프레임 크기 출력\n",
    "print('Frame width:', int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "print('Frame height:', int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        \n",
    "        break\n",
    "\n",
    "    edge = cv2.Canny(frame, 50, 150)       \n",
    "    # inversed = ~frame  # 반전\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('frame1', edge)\n",
    "#     cv2.imshow('inversed', inversed)\n",
    "\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동영상 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.VideoWriter(filename, fourcc, fps, framesize, isColor=None) -> retval\n",
    "# filename: 저장할 이름\n",
    "# fourcc: cv2.VideoWriter_fourcc(*'DIVX') 를 사용\n",
    "# fps: 초당 프레임 수 e.g. 30\n",
    "# frameSize: 프레임 크기 e.g., [640, 480])\n",
    "# isColor: Color 영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Camera open failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "# cap.get(cv2.CAP_PROP_FRAME_WIDTH) -> float type 반환\n",
    "w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS) # Frame per second\n",
    "fps = 30\n",
    "\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX') \n",
    "# fourcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X') # *'DIVX' \n",
    "\n",
    "\n",
    "delay = round(1000 / fps) #frame 간 시간 간격, ms 단위\n",
    "\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (w, h), \n",
    "                      isColor = True)\n",
    "\n",
    "if not out.isOpened():\n",
    "    print('File open failed!')\n",
    "    cap.release()\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "#     inversed = ~frame\n",
    "#     edge = cv2.Canny(frame, 50, 150)\n",
    "#     edge_color = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    out.write(frame) #소리는 capture가 안됨\n",
    "#     out.write(inversed)\n",
    "#     out.write(edge_color)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "#     cv2.imshow('inversed', inversed)\n",
    "#     cv2.imshow('edge', edge)\n",
    "\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카툰 필터 카메라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카툰 필터 카메라\n",
    "import sys \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def cartoon_filter(img):\n",
    "    h, w = img.shape[:2]\n",
    "#     img2 = cv2.resize(img, (w//2, h//2))\n",
    "\n",
    "    blr = cv2.bilateralFilter(img, -1, 20, 7)\n",
    "    edge = 255 - cv2.Canny(img, 80, 120)\n",
    "    edge = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    dst = cv2.bitwise_and(blr, edge)\n",
    "    dst = cv2.resize(dst, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "def pencil_sketch(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blr = cv2.GaussianBlur(gray, (0, 0), 3)\n",
    "    dst = cv2.divide(gray, blr, scale=255)\n",
    "    return dst\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "cam_mode = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if cam_mode == 1:\n",
    "        frame = cartoon_filter(frame)\n",
    "    elif cam_mode == 2:\n",
    "        frame = pencil_sketch(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord(' '):\n",
    "        cam_mode += 1\n",
    "        if cam_mode == 3:\n",
    "            cam_mode = 0\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu_py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
